# 프롬프트
> 전이학습이 뭔지 알려줘

전이학습(Transfer Learning)은 “이미 다른 작업에 써먹어 본 모델·지식”을 새로운, 하지만 관련 있는 작업에 가져와 재활용하는 머신러닝/딥러닝 기법이다. 쉽게 말해, 큰 데이터로 미리 잘 학습된 모델을 가져와 내 문제에 맞게 조금만 다시 학습시키는 방식이다.​

핵심 개념
한 작업(소스 작업)에서 학습된 지식·패턴을, 다른 작업(타깃 작업)으로 옮겨와 학습 속도와 성능을 높이는 것이 목표다.​

완전히 처음부터 학습시키는 것보다 필요한 데이터·연산량이 크게 줄어들기 때문에, 특히 데이터가 적은 도메인에서 많이 사용된다.​

대표적인 예시
이미지: ImageNet으로 학습된 ResNet, VGG 같은 모델의 가중치를 가져와, 마지막 몇 개 레이어만 갈아끼우거나 미세 조정해서 “강아지 vs 고양이 분류기” 같은 내 도메인 문제에 사용하는 경우.​

텍스트: 대규모 말뭉치로 사전학습된 BERT, GPT 류 모델을 가져와, 감성분석·질문응답·분류 등 특정 태스크 데이터로 파인튜닝하는 경우.​

구조적으로 어떻게 쓰는가
Feature extractor로 사용: 앞단 레이어(일반적인 패턴 추출 부분)는 고정(freeze)하고, 뒷단 분류기 레이어만 새로 학습.​

풀 파인튜닝: 전체 또는 상당수 레이어의 가중치를 초기값으로 쓰되, 타깃 데이터로 다시 학습시켜 세밀하게 조정.​

언제 특히 유용한가
내 태스크 데이터셋이 작거나 라벨링 비용이 큰 경우(의료 영상, 특수 도메인 텍스트 등).​

기본적인 시각·언어 패턴은 일반 도메인과 비슷하지만, 마지막 의사결정 기준만 도메인 특화가 필요한 상황에서 효과가 크다.​

개발자 관점 요약
수식으로 보면 “pretrained model의 weight를 초기값(좋은 prior)으로 쓰는 supervised learning”이라고 볼 수 있다.​

실무에서는 “사전학습된 백본 + 내 데이터로 파인튜닝” 패턴이 전이학습의 전형적인 사용법이다