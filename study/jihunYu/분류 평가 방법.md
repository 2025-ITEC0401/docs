# 프롬프트
> 분류를 평가하는 방법이 뭐가 있는지 알려줘

## 분류 (Classification) 평가 지표
분류는 정해진 카테고리 중 하나로 데이터를 판별하는 작업입니다. 주로 **오차 행렬(Confusion Matrix)**에 기반한 지표들이 사용됩니다.

정확도 (Accuracy): 가장 직관적인 지표. 전체 샘플 중 모델이 올바르게 예측한 샘플의 비율입니다. 하지만 데이터 클래스가 불균형할 경우(예: 99%가 정상, 1%가 불량) 모델의 성능을 왜곡할 수 있어 주의해야 합니다.

정밀도 (Precision): 모델이 '양성(Positive)'이라고 예측한 것들 중, 실제로 양성이었던 것의 비율입니다. 스팸 메일 분류에서 모델이 '스팸'으로 예측한 메일이 실제로도 스팸일 확률을 나타냅니다. FP(False Positive)를 낮추는 것이 중요할 때 사용됩니다.

재현율 (Recall) / 민감도 (Sensitivity): 실제 양성인 데이터 중에서 모델이 양성이라고 예측한 비율입니다. 암 진단 모델에서 실제 암 환자를 놓치지 않고 '암'이라고 진단해내는 능력을 나타냅니다. FN(False Negative)를 낮추는 것이 중요할 때 사용됩니다.

F1 점수 (F1 Score): 정밀도와 재현율의 조화평균. 두 지표가 한쪽으로 치우치지 않고 모두 높은 값을 가질 때 F1 점수도 높아집니다. 클래스 불균형이 심할 때 정확도 대신 모델의 성능을 정확하게 평가하기 좋습니다.

AUC (Area Under the Curve): ROC 곡선 아래의 면적을 의미하며, 1에 가까울수록 모델의 성능이 좋음을 나타냅니다. ROC 곡선은 모델의 판별 임계값이 변할 때 재현율(TPR)과 위양성률(FPR)이 어떻게 변하는지를 보여주는 그래프로, 이진 분류 모델의 종합적인 성능을 평가하는 데 널리 사용됩니다.