Q1. 텍스트 데이터로 학습된 LLM(GPT, Llama 등)이 어떻게 전혀 다른 성격의 시계열 데이터를 이해하고 예측할 수 있는가?

A: '보편적 패턴 인식 능력' 때문입니다. 언어 모델이 학습한 문법적 구조나 순차적 패턴(상승, 하강, 주기성 등)은 시계열 데이터의 추세나 계절성과 수학적으로 유사성을 가집니다. aLLM4TS와 같은 연구는 **시계열 데이터를 LLM이 이해할 수 있는 토큰 공간으로 투영(Projection)**하거나, LLM의 일부 파라미터만 미세 조정(Fine-tuning)하여 언어 모델의 지식을 시계열 도메인으로 **재프로그래밍(Reprogramming)**하는 원리를 사용합니다.