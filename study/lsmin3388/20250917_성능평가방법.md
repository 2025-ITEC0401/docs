### **성능 평가 프레임워크 제안**

다변량 시계열 데이터 공통 임베딩 기법의 성능 평가 프레임워크는 크게 4가지 축으로 구성됩니다. 

1.  **내재적 평가 (Intrinsic Evaluation)**: 임베딩 자체가 데이터를 얼마나 잘 표현하는가?
2.  **외재적 평가 (Extrinsic Evaluation)**: 임베딩이 실제 문제(Downstream Tasks) 해결에 얼마나 유용한가?
3.  **일반화 및 효율성 평가**: 새로운 데이터나 적은 데이터 환경에서 얼마나 잘 작동하는가?
4.  **강건성 평가**: 불완전하고 노이즈 섞인 데이터에 얼마나 잘 견디는가?

---

### ## 1. 내재적 평가: 임베딩 공간의 질적 분석 (Task 1, 5 연계)

임베딩의 가장 근본적인 성능은 **데이터의 의미 있는 특징들을 얼마나 잘 압축하여 표현하는지**에 있습니다. 이는 주로 시각화를 통해 정성적으로 평가합니다.

* **평가 방법**:
    1.  학습된 임베딩 `z`를 **PCA, UMAP, t-SNE**와 같은 차원 축소 기법을 사용해 2D 또는 3D 공간에 시각화합니다.
    2.  시계열 데이터의 **알려진 레이블(ex: 정상/고장 상태, 특정 이벤트 구간)**이 있다면, 해당 레이블에 따라 포인트들을 다른 색상으로 표시합니다.

* **확인 사항**:
    * **군집 형성**: 같은 클래스(레이블)의 데이터 포인트들이 임베딩 공간에서 뚜렷하게 군집을 형성하는가?
    * **분리도**: 다른 클래스의 군집들이 서로 잘 분리되어 있는가?
    * **의미론적 구조**: 데이터의 특정 상태 변화(ex: 정상 → 비정상 전환)가 임베딩 공간에서 점진적이고 연속적인 경로로 나타나는가?

* **기대 결과**: "본 연구에서 제안하는 임베딩은 데이터의 상태 정보를 보존하여, 유사한 상태의 데이터는 가깝게, 다른 상태의 데이터는 멀게 배치하는 우수한 표현력을 가짐을 시각적으로 확인했다." 와 같은 결론을 도출할 수 있습니다.
    

---

### ## 2. 외재적 평가: 멀티태스크 헤드를 통한 활용성 검증 (Task 2 연계)

임베딩의 진정한 가치는 **다양한 후속 과제(Downstream Tasks)에 얼마나 효과적으로 재사용될 수 있는지**로 증명됩니다. 임베딩 모델(인코더)은 고정(`freeze`)하고, 그 위에 간단한 헤드(Head)만 추가하여 성능을 측정합니다.

* **평가 방법**:
    * **공통 설정**: 사전 학습된 임베딩 인코더는 동결합니다. 각 Task 별로 **가벼운 신경망 헤드**(ex: 1~2개의 Linear Layer)만 부착하여 학습 및 평가를 진행합니다.
    * **비교 대상 (Baseline)**:
        1.  **End-to-End 모델**: 각 Task를 처음부터 끝까지 학습하는 전통적인 모델 (ex: LSTM 기반 분류기)
        2.  **기존 임베딩 기법**: 다른 시계열 임베딩 연구(ex: T-Loss, TS2Vec)를 적용한 결과

| **Downstream Task** | **헤드 구성 예시** | **주요 성능 지표 (Metrics)** | **평가 목표** |
| :--- | :--- | :--- | :--- |
| **분류 (Classification)** | `Linear -> Softmax` | **Accuracy, F1-Score (Macro/Micro), AUC** | 상태 진단, 이벤트 탐지 등 분류 문제 해결 능력 |
| **이상 탐지 (Anomaly Detection)** | `Autoencoder` 또는 `OC-SVM` | **Precision, Recall, F1-Score, AUROC, AUPRC** | 정상 패턴에서 벗어나는 이상치를 탐지하는 능력 |
| **예측 (Forecasting)** | `Linear Layer` | **MAE (Mean Absolute Error), RMSE (Root MSE)** | 임베딩이 미래 값 예측에 필요한 정보를 포함하는지 확인 (참고용) |
| **군집화 (Clustering)** | `K-Means`, `DBSCAN` 등 | **NMI, ARI (레이블 있을 시), Silhouette Score** | 레이블 없이도 데이터의 내재적 구조를 잘 그룹화하는지 확인 |

---

### ## 3. 일반화 및 데이터 효율성 평가 (Task 3 연계) 📊

좋은 임베딩은 **처음 보는 데이터(Domain)에도 잘 적응**해야 하며, **적은 양의 데이터만으로도 빠르게 학습**할 수 있어야 합니다.

* **평가 방법**:
    1.  **도메인 전이 (Domain Transfer)**:
        * **시나리오**: 소스 도메인(ex: 설비 A 데이터)으로 임베딩을 학습한 후, 타겟 도메인(ex: 설비 B 데이터)에서는 **헤드만 학습**합니다.
        * **성능 비교**: 타겟 도메인 데이터 전체로 처음부터 학습한 End-to-End 모델의 성능과 비교하여 성능 저하가 얼마나 적은지 측정합니다.
    2.  **퓨샷 러닝 (Few-shot Learning)**:
        * **시나리오**: 타겟 도메인 데이터의 일부(**1%, 5%, 10%**)만 사용하여 헤드 혹은 전체 모델을 미세 조정(fine-tuning)합니다.
        * **결과 제시**: 데이터 양(x축)에 따른 성능(y축) 변화를 **학습 곡선 그래프**로 시각화합니다.
        * **기대 결과**: 제안하는 모델이 훨씬 적은 데이터로도 높은 성능에 빠르게 도달하는 것을 보여줍니다.

---

### ## 4. 강건성(Robustness) 평가 (Task 4 연계) 🛡️

실제 산업 현장의 데이터는 불규칙하고 노이즈가 많습니다. 이러한 **데이터의 비정형성(Heterogeneity)에 대한 강인함**을 증명하는 것은 매우 중요합니다.

* **평가 방법**:
    * 테스트 데이터셋에 의도적으로 **왜곡(corruption)을 주입**한 '미니 벤치마크'를 구성합니다.
    * 왜곡의 강도를 점차 높여가며(ex: 10%, 30%, 50%) 각 Task에서의 **성능 저하 추이**를 관찰하고 그래프로 시각화합니다.

* **왜곡 시나리오**:
    * **결측 (Missing Values)**: 데이터의 일부를 무작위로 제거합니다.
    * **노이즈 (Noise)**: 가우시안 노이즈 등을 추가합니다.
    * **가변 주기 (Irregular Sampling)**: 데이터의 샘플링 주기를 불규칙하게 만듭니다.

* **기대 결과**: "제안하는 임베딩 기법은 데이터의 결측률이 50%에 달하는 열악한 환경에서도 안정적인 성능을 유지하여, 실제 산업 환경에서의 적용 가능성이 높음을 입증했다." 와 같은 결론을 제시할 수 있습니다.

### **결과 종합 및 제시 (Task 5 연계)**

위의 모든 실험 결과를 효과적으로 정리하고 시각화하여 연구의 기여도를 명확히 전달해야 합니다.

* **대시보드/리포트 구성**:
    * **종합 성능 표**: 모든 Task, 모든 데이터셋(도메인), 모든 비교 모델의 핵심 지표를 하나의 표로 정리합니다.
    * **핵심 결과 그래프**:
        * 퓨샷 러닝 성능 곡선 (데이터 효율성)
        * 강건성 평가 그래프 (왜곡 수준에 따른 성능 변화)
    * **임베딩 시각화**: 가장 대표적인 데이터셋의 UMAP/t-SNE 시각화 결과를 포함하여 정성적 우수성을 보여줍니다.