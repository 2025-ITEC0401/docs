# Multi-task Learning

## Prompts (Powered by Claude)

### Question)
```
Multi-task Learning의 개념과 장점에 대해 설명해주세요.
단일 태스크 학습과 비교했을 때 어떤 이점이 있나요?
```

### Answer)
Multi-task Learning(MTL)은 여러 개의 관련된 태스크를 동시에 학습하는 머신러닝 기법입니다. 하나의 모델이 여러 태스크를 함께 학습함으로써 태스크 간의 공통된 표현(representation)을 공유하고, 이를 통해 각 태스크의 성능을 향상시킵니다.

**주요 장점:**

1. **일반화 성능 향상**: 여러 태스크를 동시에 학습하면서 모델이 더 일반적인 특징을 학습하게 되어 과적합을 방지하고 일반화 성능이 향상됩니다.

2. **데이터 효율성**: 관련된 태스크들이 서로의 학습 신호를 활용할 수 있어, 각 태스크가 적은 데이터로도 더 나은 성능을 낼 수 있습니다.

3. **암묵적 정규화**: 여러 태스크의 손실 함수를 동시에 최적화하는 과정이 정규화 효과를 내어 모델의 강건성을 높입니다.

4. **계산 효율성**: 하나의 모델로 여러 태스크를 처리할 수 있어 여러 개별 모델을 운영하는 것보다 메모리와 계산 자원을 절약할 수 있습니다.

---

### Question)
```
Multi-task Learning에서 Hard Parameter Sharing과 Soft Parameter Sharing의
차이점은 무엇이며, 각각 어떤 상황에서 적합한가요?
```

### Answer)
Hard Parameter Sharing과 Soft Parameter Sharing은 멀티태스크 학습에서 태스크 간 정보를 공유하는 두 가지 주요 아키텍처 패턴입니다.

**Hard Parameter Sharing:**
- 모든 태스크가 하나의 공통된 hidden layer를 공유하고, 마지막 출력 layer만 각 태스크마다 분리됩니다.
- 구조가 간단하고 파라미터 수가 적어 과적합 위험이 낮습니다.
- 계산 효율적이며 메모리 사용량이 적습니다.

```
Input → [Shared Hidden Layers] → Task 1 Output
                                → Task 2 Output
                                → Task 3 Output
```

**Soft Parameter Sharing:**
- 각 태스크가 자신만의 모델과 파라미터를 가지지만, 태스크 간 파라미터가 유사해지도록 정규화합니다.
- 태스크별 파라미터가 완전히 다르게 학습되는 것을 제약하면서도 각 태스크의 특성을 더 잘 반영할 수 있습니다.
- L2 정규화나 trace norm 등을 사용하여 파라미터 간 거리를 제한합니다.

```
Input → [Task 1 Model] → Task 1 Output
      → [Task 2 Model] → Task 2 Output  (with parameter similarity constraints)
      → [Task 3 Model] → Task 3 Output
```

**적합한 상황:**
- **Hard Parameter Sharing**: 태스크들이 밀접하게 관련되어 있고, 공통된 특징이 많을 때 효과적입니다. 예: 동일한 도메인에서의 여러 예측 문제
- **Soft Parameter Sharing**: 태스크들이 어느 정도 관련은 있지만 각각의 고유한 특성이 중요할 때 적합합니다. 더 유연한 학습이 가능하지만 계산 비용이 높습니다.

---

### Question)
```
시계열 데이터에서 예측(Forecasting)과 분류(Classification)를
동시에 학습하는 멀티태스크 접근법의 장점과 구현 방법을 설명해주세요.
```

### Answer)
시계열 데이터에서 예측과 분류를 동시에 학습하는 멀티태스크 접근법은 두 태스크가 시간적 패턴을 공유한다는 점을 활용합니다.

**장점:**

1. **공통 시간적 표현 학습**: 예측과 분류 모두 시계열의 temporal pattern을 이해해야 하므로, 공유 인코더를 통해 더 풍부한 시간적 표현을 학습할 수 있습니다.

2. **상호 보완적 학습**:
   - 분류 태스크는 전역적인 패턴과 특징을 학습하는데 도움을 줍니다.
   - 예측 태스크는 세밀한 시간적 동역학을 학습하는데 기여합니다.

3. **레이블 효율성**: 예측을 위한 연속적인 값과 분류를 위한 범주형 레이블이 서로 다른 정보를 제공하여, 제한된 데이터에서도 더 나은 성능을 얻을 수 있습니다.

**구현 방법:**

```python
# 기본 아키텍처 예시
class TimeSeriesMultiTask(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes, forecast_horizon):
        super().__init__()
        # Shared encoder (Hard Parameter Sharing)
        self.shared_encoder = nn.LSTM(
            input_dim, hidden_dim, num_layers=2, batch_first=True
        )

        # Task-specific heads
        self.forecast_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, forecast_horizon)
        )

        self.classification_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, num_classes)
        )

    def forward(self, x):
        # Shared representation
        encoded, (hidden, cell) = self.shared_encoder(x)

        # Use last hidden state for both tasks
        last_hidden = hidden[-1]

        # Task outputs
        forecast_output = self.forecast_head(last_hidden)
        classification_output = self.classification_head(last_hidden)

        return forecast_output, classification_output

# Loss function
def multi_task_loss(forecast_pred, forecast_true, class_pred, class_true,
                    alpha=0.5, beta=0.5):
    forecast_loss = nn.MSELoss()(forecast_pred, forecast_true)
    classification_loss = nn.CrossEntropyLoss()(class_pred, class_true)

    # Weighted combination
    total_loss = alpha * forecast_loss + beta * classification_loss
    return total_loss
```

**실제 응용 예시:**
- **금융 시계열**: 주가 예측과 동시에 시장 상황(상승/하락/횡보) 분류
- **의료 모니터링**: 환자의 바이탈 사인 예측과 이상 상태 분류
- **에너지 관리**: 전력 소비량 예측과 피크 타임 분류

가중치 alpha와 beta는 각 태스크의 중요도와 학습 난이도에 따라 조정할 수 있으며, 동적으로 조정하는 기법(예: uncertainty weighting)도 활용할 수 있습니다.
