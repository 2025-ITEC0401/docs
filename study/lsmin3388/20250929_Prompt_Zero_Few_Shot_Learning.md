# Zero-shot과 Few-shot Learning

## Prompts (Powered by Claude)

### Question)
```
Zero-shot Learning, Few-shot Learning, Fine-tuning의 차이점을 설명하고,
각각 언제 사용하는 것이 적합한지 구체적인 예시와 함께 설명해주세요.
```

### Answer)
이 세 가지 학습 방법은 모델이 새로운 작업을 수행하는 방식에서 차이가 있습니다.

**Zero-shot Learning**
- 모델이 학습 단계에서 본 적 없는 작업을 추가 학습 없이 수행
- 사전 학습된 지식과 자연어 지시만으로 작업 수행
- 예시: "이 문장의 감정을 분석해줘"라는 지시만으로 감정 분석 수행
- 장점: 추가 데이터나 학습 불필요, 빠른 적용
- 단점: 성능이 제한적, 도메인 특화 지식 부족

**Few-shot Learning**
- 소량의 예시(1~10개)를 제공하여 모델이 패턴을 학습하도록 함
- 모델의 가중치는 변경하지 않고 컨텍스트 내에서 학습
- 예시: 3개의 고객 리뷰와 감정 라벨을 보여주고 새로운 리뷰 분류
- 장점: 적은 데이터로 성능 향상, 빠른 적용
- 단점: 컨텍스트 길이 제한, zero-shot보다는 많은 예시 필요

**Fine-tuning**
- 대량의 작업별 데이터로 모델의 가중치를 업데이트
- 수백~수천 개 이상의 예시로 모델을 특정 작업에 최적화
- 예시: 의료 문서 분류를 위해 10,000개의 라벨링된 문서로 학습
- 장점: 최고의 성능, 도메인 특화 가능
- 단점: 많은 데이터 필요, 시간과 컴퓨팅 비용 높음

**선택 기준**
- Zero-shot: 데이터가 없거나 빠른 프로토타이핑이 필요할 때
- Few-shot: 소량의 데이터만 있고 빠른 성능 개선이 필요할 때
- Fine-tuning: 충분한 데이터와 리소스가 있고 최고 성능이 필요할 때

---

### Question)
```
시계열 예측에서 Few-shot Learning이 왜 중요한가요?
전통적인 시계열 모델과 비교했을 때 어떤 장점이 있나요?
```

### Answer)
시계열 예측에서 Few-shot Learning은 특히 중요한 의미를 가집니다.

**시계열에서 Few-shot Learning의 중요성**

1. **데이터 희소성 문제 해결**
   - 새로운 센서나 장비: 과거 데이터가 부족한 상황
   - 희귀 이벤트: 고장, 이상 상황 등 충분한 데이터 수집 어려움
   - 신규 제품/서비스: 출시 초기 단계에서 데이터 부족
   - Few-shot Learning은 이러한 상황에서도 예측 가능

2. **도메인 전이 능력**
   - 한 시계열에서 학습한 패턴을 다른 시계열에 적용
   - 예: A 공장의 설비 데이터로 학습 후 B 공장 설비에 적용
   - 전통적 모델은 각 도메인마다 처음부터 재학습 필요

3. **빠른 적응성**
   - 시장 변화, 시즌성 변화 등에 신속하게 대응
   - 소량의 새로운 데이터로 패턴 학습
   - 예: 갑작스러운 경제 위기 시 소비 패턴 변화 예측

**전통적인 시계열 모델과의 비교**

| 측면 | 전통적 모델 (ARIMA, LSTM 등) | Few-shot Learning |
|------|------------------------------|-------------------|
| 데이터 요구량 | 수백~수천 개 데이터포인트 필요 | 5~20개 샘플로도 학습 가능 |
| 새로운 시계열 적응 | 처음부터 재학습 필요 | 소량 예시로 빠른 적응 |
| 학습 시간 | 각 시계열마다 긴 학습 시간 | 사전 학습 후 빠른 적응 |
| 일반화 능력 | 특정 시계열에만 특화 | 다양한 시계열 패턴 학습 |
| Cold Start 문제 | 해결 어려움 | 효과적으로 처리 |

**실제 응용 사례**
- 제조업: 신규 생산 라인의 불량률 예측
- 금융: 신규 상장 기업의 주가 예측
- IoT: 새로 설치된 센서의 이상 탐지
- 소매: 신제품의 수요 예측

---

### Question)
```
Few-shot Learning 모델의 데이터 효율성을 평가하는 방법에는 어떤 것들이 있나요?
평가 메트릭과 실험 설계 방법을 설명해주세요.
```

### Answer)
Few-shot Learning의 핵심은 데이터 효율성입니다. 다음과 같은 방법으로 평가할 수 있습니다.

**1. 평가 메트릭**

**성능 기반 메트릭**
- **N-shot Accuracy**: N개 샘플로 학습 후 테스트 정확도
  - 1-shot, 5-shot, 10-shot 등 다양한 N값에 대해 측정
- **Learning Curve**: 샘플 수에 따른 성능 변화 곡선
  - 기울기가 가파를수록 데이터 효율적
- **Performance Ratio**: (Few-shot 성능) / (Full training 성능)
  - 적은 데이터로 얼마나 최대 성능에 근접하는지 측정

**효율성 메트릭**
- **Sample Efficiency**: 특정 성능에 도달하는데 필요한 최소 샘플 수
- **Data-to-Performance Ratio**: 단위 샘플당 성능 향상도
- **Transfer Efficiency**: 다른 도메인 적용 시 필요한 샘플 수

**2. 실험 설계 방법**

**Episode-based Training (에피소드 기반 학습)**
```
각 에피소드:
1. Support Set 샘플링: N개의 학습 샘플 선택
2. Query Set 샘플링: 테스트할 샘플 선택
3. Support Set으로 학습 → Query Set으로 평가
4. 수백~수천 개 에피소드 반복
```

**N-way K-shot 설정**
- N-way: 분류할 클래스 수
- K-shot: 각 클래스당 샘플 수
- 예: 5-way 1-shot = 5개 클래스, 각 1개씩 샘플

**Cross-domain Evaluation**
```
1. Source Domain에서 사전 학습
2. Target Domain에서 Few-shot 평가
3. 도메인 간 격차가 클수록 어려운 시나리오
```

**3. 실험 프로토콜 예시**

**시계열 Few-shot 평가 설계**
```
설정:
- 100개 시계열 데이터셋 준비
- 70개: 사전 학습용
- 15개: 검증용
- 15개: Few-shot 테스트용

실험:
각 테스트 시계열에 대해:
  for K in [1, 5, 10, 20, 50]:
    - K개 샘플로 학습 (Support Set)
    - 나머지로 평가 (Query Set)
    - 성능 기록 (MAE, RMSE 등)

결과 분석:
- K에 따른 성능 곡선 그래프
- 베이스라인(Zero-shot, Full training) 비교
- 통계적 유의성 검정 (t-test 등)
```

**4. 비교 베이스라인**

평가 시 다음과 비교하여 데이터 효율성 입증:
- **Zero-shot**: 예시 없이 수행
- **Full Supervision**: 전체 데이터로 학습한 모델
- **전통적 방법**: ARIMA, Prophet 등 (시계열의 경우)
- **Transfer Learning**: Fine-tuning 기반 방법

**5. 통계적 검증**

- **다중 시드 실험**: 5~10개 랜덤 시드로 반복
- **신뢰구간 계산**: 평균 ± 표준편차 보고
- **통계 검정**: 베이스라인 대비 유의미한 개선 검증
- **Ablation Study**: 모델 구성요소별 기여도 분석

이러한 체계적인 평가를 통해 Few-shot Learning 모델이 실제로 데이터 효율적인지 객관적으로 검증할 수 있습니다.
