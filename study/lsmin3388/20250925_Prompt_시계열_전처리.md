# 시계열 데이터 전처리

## Prompts (Powered by Claude)

### Question)
```
시계열 데이터에서 사용되는 정규화 방법인 Min-Max Scaling, Z-score Normalization, Robust Scaling의 차이점과 각각 어떤 상황에서 사용하는 것이 적절한지 설명해주세요.
```

### Answer)
시계열 데이터의 정규화는 모델 학습의 효율성과 성능에 큰 영향을 미칩니다. 세 가지 주요 정규화 방법의 특징은 다음과 같습니다:

**1. Min-Max Scaling**
- 데이터를 [0, 1] 또는 [-1, 1] 범위로 변환
- 공식: `(X - X_min) / (X_max - X_min)`
- 장점: 직관적이고 계산이 간단함
- 단점: 이상치(outlier)에 민감하여 대부분의 데이터가 좁은 범위에 몰릴 수 있음
- 적용 상황: 이상치가 없고 데이터 분포가 균일한 경우, 신경망 입력에 적합

**2. Z-score Normalization (Standardization)**
- 평균 0, 표준편차 1로 변환
- 공식: `(X - μ) / σ`
- 장점: 데이터의 분포를 유지하면서 스케일 조정
- 단점: 이상치가 평균과 표준편차에 영향을 줄 수 있음
- 적용 상황: 정규분포를 따르는 데이터, 선형 모델이나 거리 기반 알고리즘 사용 시

**3. Robust Scaling**
- 중앙값(median)과 IQR(Interquartile Range)을 사용
- 공식: `(X - median) / IQR`
- 장점: 이상치에 매우 강건함
- 단점: 정규분포가 아닌 데이터에서도 사용 가능하지만, 계산이 상대적으로 복잡
- 적용 상황: 이상치가 많은 실제 센서 데이터, 금융 시계열 데이터

시계열 예측 모델에서는 일반적으로 Z-score Normalization을 많이 사용하지만, 센서 데이터나 실시간 스트리밍 데이터처럼 이상치가 빈번한 경우 Robust Scaling을 고려해야 합니다.

---

### Question)
```
시계열 데이터에서 결측치(missing values)가 발생했을 때, 어떤 처리 방법들이 있으며 각 방법의 장단점은 무엇인가요? 특히 시간 순서를 고려한 방법들을 중심으로 설명해주세요.
```

### Answer)
시계열 데이터의 결측치 처리는 시간적 의존성을 고려해야 하므로 일반적인 데이터와 다른 접근이 필요합니다.

**1. 삭제(Deletion)**
- 결측치가 있는 행/구간을 제거
- 장점: 간단하고 빠른 처리
- 단점: 데이터 손실, 시간 연속성 파괴, 긴 시계열에서 많은 정보 손실 가능
- 적용: 결측치 비율이 매우 낮을 때(<5%)

**2. Forward Fill (ffill) / Backward Fill (bfill)**
- Forward Fill: 이전 값으로 채우기
- Backward Fill: 다음 값으로 채우기
- 장점: 구현이 간단, 시간 순서 유지
- 단점: 결측 구간이 길면 부정확, 추세나 변동성 왜곡 가능
- 적용: 짧은 결측 구간, 값이 급격히 변하지 않는 데이터

**3. 선형 보간(Linear Interpolation)**
- 전후 값 사이를 선형적으로 채움
- 장점: 부드러운 전환, 추세 유지
- 단점: 비선형 패턴 포착 불가
- 적용: 추세가 명확하고 변동성이 낮은 데이터

**4. 시계열 특화 보간**
- Spline Interpolation: 곡선 보간으로 더 자연스러운 패턴
- Polynomial Interpolation: 고차 다항식 사용
- 장점: 복잡한 패턴 포착 가능
- 단점: 과적합 위험, 계산 비용
- 적용: 주기성이나 비선형 패턴이 강한 데이터

**5. 통계적 방법**
- Moving Average: 이동 평균으로 채우기
- Seasonal Decomposition: 계절성 분해 후 보간
- 장점: 시계열 특성(추세, 계절성) 반영
- 단점: 복잡도 증가, 파라미터 튜닝 필요
- 적용: 명확한 계절성/주기성이 있는 데이터

**6. 모델 기반 예측**
- ARIMA, LSTM 등으로 결측치 예측
- 장점: 가장 정교한 추정 가능
- 단점: 계산 비용 높음, 과적합 위험
- 적용: 결측 구간이 길고 데이터가 충분할 때

실무에서는 결측 구간의 길이와 데이터 특성에 따라 방법을 조합하여 사용합니다. 예를 들어, 짧은 구간은 선형 보간, 긴 구간은 모델 기반 예측을 사용하는 하이브리드 접근이 효과적입니다.

---

### Question)
```
시계열 딥러닝 모델 학습을 위한 리샘플링(Resampling)과 윈도우 슬라이딩(Window Sliding) 기법에 대해 설명해주세요. 각 기법의 목적과 구현 방법, 그리고 윈도우 크기와 스트라이드를 결정하는 기준은 무엇인가요?
```

### Answer)
리샘플링과 윈도우 슬라이딩은 시계열 데이터를 딥러닝 모델에 적합한 형태로 변환하는 핵심 전처리 기법입니다.

**리샘플링 (Resampling)**

리샘플링은 시계열 데이터의 시간 해상도를 변경하는 작업입니다.

- **업샘플링(Upsampling)**: 낮은 빈도 → 높은 빈도 (예: 일간 → 시간별)
  - 보간법 사용 필요 (선형, 스플라인 등)
  - 데이터 포인트 증가로 학습 데이터 확보

- **다운샘플링(Downsampling)**: 높은 빈도 → 낮은 빈도 (예: 분 단위 → 시간별)
  - 집계 함수 사용 (mean, sum, last 등)
  - 노이즈 감소, 계산량 절감
  - 장기 추세 파악에 유리

```python
# Pandas 예시
df_hourly = df.resample('H').mean()  # 시간별 평균
df_daily = df.resample('D').agg({'value': 'mean', 'volume': 'sum'})
```

**윈도우 슬라이딩 (Window Sliding)**

고정 크기의 윈도우를 이동하며 입력-출력 쌍을 생성하는 기법입니다.

- **윈도우 크기(Window Size)**: 입력으로 사용할 과거 시점의 수
- **스트라이드(Stride)**: 윈도우 이동 간격
- **예측 구간(Horizon)**: 예측할 미래 시점의 수

```python
# 예시: 윈도우 크기 24, 스트라이드 1
# [t0, t1, ..., t23] → t24 예측
# [t1, t2, ..., t24] → t25 예측
```

**윈도우 크기 결정 기준**

1. **도메인 지식 활용**
   - 주식: 과거 20-60일 (1-3개월)
   - 에너지 소비: 24-168시간 (1일-1주일)
   - 센서 데이터: 수 초-수 분

2. **데이터 주기성**
   - 일간 패턴: 24시간 이상
   - 주간 패턴: 7일 이상
   - 계절성: 해당 주기의 배수

3. **모델 복잡도와의 균형**
   - 너무 길면: 계산 비용 증가, 과적합 위험
   - 너무 짧으면: 패턴 포착 부족, 과소적합

**스트라이드 결정 기준**

1. **Stride = 1 (완전 중첩)**
   - 장점: 최대한 많은 학습 샘플 생성
   - 단점: 높은 상관관계로 과적합 위험
   - 적용: 데이터가 부족한 경우

2. **Stride = Window Size (중첩 없음)**
   - 장점: 독립적인 샘플, 과적합 방지
   - 단점: 샘플 수 감소
   - 적용: 데이터가 충분한 경우

3. **Stride = Window Size / 2 (50% 중첩)**
   - 균형잡힌 접근법
   - 실무에서 많이 사용

**실전 예시**

```python
def create_sliding_windows(data, window_size=24, stride=1, horizon=1):
    X, y = [], []
    for i in range(0, len(data) - window_size - horizon + 1, stride):
        X.append(data[i:i + window_size])
        y.append(data[i + window_size:i + window_size + horizon])
    return np.array(X), np.array(y)

# 24시간 데이터로 1시간 후 예측
X_train, y_train = create_sliding_windows(train_data,
                                          window_size=24,
                                          stride=6,  # 6시간마다
                                          horizon=1)
```

**권장사항**
- 초기에는 여러 윈도우 크기를 실험 (예: 12, 24, 48, 168시간)
- 교차 검증으로 최적 조합 탐색
- 학습 시간과 성능의 트레이드오프 고려
- 멀티 스케일 접근: 여러 윈도우 크기를 동시에 사용하는 앙상블 모델도 효과적
