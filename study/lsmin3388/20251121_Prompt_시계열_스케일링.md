# 시계열 데이터 스케일링 학습 자료

## Prompts

### Question)
```
시계열 데이터에서 스케일링(Normalization/Standardization)이 왜 중요한가요? 주요 스케일링 방법들을 비교해주세요.
```

### Answer)
**스케일링의 중요성:**

1. **수렴 속도 향상**: 특성 간 스케일 차이로 인한 학습 불균형 방지
2. **Gradient 안정화**: 큰 값으로 인한 gradient exploding 방지
3. **공정한 특성 기여**: 모든 특성이 동등하게 학습에 기여
4. **Distance 기반 알고리즘**: K-means, KNN 등에서 필수

**주요 스케일링 방법:**

**1. Min-Max Scaling (Normalization)**
```python
from sklearn.preprocessing import MinMaxScaler

# [0, 1] 범위로 스케일링
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# 수식: X_scaled = (X - X_min) / (X_max - X_min)
```

**2. Standard Scaling (Z-score)**
```python
from sklearn.preprocessing import StandardScaler

# 평균 0, 표준편차 1로 스케일링
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 수식: X_scaled = (X - mean) / std
```

**3. Robust Scaling**
```python
from sklearn.preprocessing import RobustScaler

# 중앙값과 IQR 기반, 이상치에 강건
scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)

# 수식: X_scaled = (X - median) / IQR
```

**비교:**

| 방법 | 범위 | 이상치 민감도 | 권장 상황 |
|------|------|-------------|----------|
| Min-Max | [0, 1] | 높음 | 이미지, 고정 범위 |
| Standard | 무제한 | 중간 | 가우시안 분포 |
| Robust | 무제한 | 낮음 | 이상치 존재 |

---

### Question)
```
시계열 데이터를 스케일링할 때 주의해야 할 점(Data Leakage)은 무엇인가요? 올바른 스케일링 순서는 어떻게 되나요?
```

### Answer)
**Data Leakage 문제:**

테스트 데이터의 정보가 학습 과정에 유출되는 현상입니다.

**잘못된 예시:**
```python
# WRONG: 전체 데이터로 스케일러 학습
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # 전체 데이터 사용

X_train = X_scaled[:split_idx]
X_test = X_scaled[split_idx:]
# 테스트 데이터의 통계가 이미 포함됨!
```

**올바른 스케일링 순서:**
```python
# CORRECT: 훈련 데이터로만 스케일러 학습
X_train, X_test = X[:split_idx], X[split_idx:]

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # fit + transform
X_test_scaled = scaler.transform(X_test)         # transform만
```

**시계열에서 추가 고려사항:**

```python
# 시간 순서 유지
def scale_time_series_properly(X, train_size=0.8):
    split_idx = int(len(X) * train_size)

    X_train = X[:split_idx]
    X_test = X[split_idx:]

    scaler = StandardScaler()

    # Rolling 방식으로 스케일링 (더 현실적)
    X_train_scaled = scaler.fit_transform(X_train)

    # 배포 환경 시뮬레이션
    X_test_scaled = scaler.transform(X_test)

    return X_train_scaled, X_test_scaled, scaler
```

**Cross-Validation에서 스케일링:**
```python
from sklearn.pipeline import Pipeline
from sklearn.model_selection import TimeSeriesSplit

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', MyModel())
])

tscv = TimeSeriesSplit(n_splits=5)
# Pipeline 내에서 각 fold마다 올바르게 스케일링됨
cross_val_score(pipeline, X, y, cv=tscv)
```

---

### Question)
```
다변량 시계열에서 각 변수(채널)별로 스케일링해야 하나요, 아니면 전체를 함께 스케일링해야 하나요?
```

### Answer)
**변수별(채널별) 스케일링 - 일반적으로 권장**

각 변수가 서로 다른 단위와 범위를 가질 때 적합합니다.

```python
# 변수별 독립 스케일링
def scale_per_channel(X):
    # X shape: (samples, timesteps, channels)
    n_channels = X.shape[2]
    scalers = []

    X_scaled = np.zeros_like(X)

    for c in range(n_channels):
        scaler = StandardScaler()
        # 각 채널의 모든 시점 데이터로 학습
        channel_data = X[:, :, c].reshape(-1, 1)
        scaler.fit(channel_data)

        for i in range(len(X)):
            X_scaled[i, :, c] = scaler.transform(
                X[i, :, c].reshape(-1, 1)
            ).flatten()

        scalers.append(scaler)

    return X_scaled, scalers
```

**적합한 경우:**
- 온도(°C), 습도(%), 전력(kW) 등 다른 단위
- 변수 간 스케일 차이가 큰 경우
- 대부분의 다변량 시계열

**전체 스케일링**

모든 변수가 같은 단위이거나, 변수 간 상대적 크기가 의미 있을 때 사용합니다.

```python
# 전체 함께 스케일링
def scale_global(X):
    original_shape = X.shape
    X_flat = X.reshape(-1, 1)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_flat)

    return X_scaled.reshape(original_shape), scaler
```

**적합한 경우:**
- 모든 변수가 같은 단위 (예: 여러 센서의 온도)
- 변수 간 크기 비교가 중요한 경우

**샘플별 스케일링 (Instance Normalization)**

각 샘플(시퀀스)을 독립적으로 정규화합니다.

```python
# 샘플별 스케일링
def scale_per_sample(X):
    X_scaled = np.zeros_like(X)

    for i in range(len(X)):
        mean = X[i].mean()
        std = X[i].std()
        X_scaled[i] = (X[i] - mean) / (std + 1e-8)

    return X_scaled
```

**적합한 경우:**
- 절대값보다 패턴이 중요한 경우
- 시계열 분류, 클러스터링

**권장 선택:**

| 상황 | 스케일링 방식 |
|------|-------------|
| 다른 단위의 변수들 | 변수별 |
| 같은 단위의 변수들 | 전체 또는 변수별 |
| 패턴 기반 분류 | 샘플별 |
| 이상 탐지 | 변수별 |
