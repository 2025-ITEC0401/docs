# 시계열 Data Augmentation

## Prompts (Powered by Claude)

### Question)
```
시계열 데이터의 Data Augmentation 기법에는 어떤 것들이 있나요?
특히 Jittering, Scaling, Time Warping, Window Slicing 기법에 대해 설명해주세요.
```

### Answer)
시계열 데이터의 Data Augmentation은 제한된 데이터로부터 더 많은 학습 샘플을 생성하여 모델의 일반화 성능을 향상시키는 중요한 기법입니다. 주요 기법들은 다음과 같습니다:

**1. Jittering (노이즈 추가)**
- 시계열 데이터에 작은 랜덤 노이즈를 추가하는 기법입니다.
- 구현: `x_aug = x + noise`, 여기서 noise는 평균 0, 표준편차 σ의 가우시안 노이즈
- 효과: 센서 노이즈나 측정 오차에 대한 robustness를 향상시킵니다.
- 예시: 주가 데이터에 ±0.5% 범위의 노이즈 추가

**2. Scaling (크기 조정)**
- 시계열 데이터의 진폭(amplitude)을 스케일링하는 기법입니다.
- 구현: `x_aug = x * scale_factor`, scale_factor는 보통 0.8~1.2 범위
- 효과: 다양한 규모의 데이터 변동에 대한 불변성을 학습합니다.
- 예시: 센서 감도 차이나 측정 단위 변화에 대응

**3. Time Warping (시간 왜곡)**
- 시계열의 시간 축을 비선형적으로 늘리거나 압축하는 기법입니다.
- 구현: DTW(Dynamic Time Warping) 알고리즘이나 smooth curve distortion 사용
- 효과: 같은 패턴이지만 다른 속도로 발생하는 현상을 학습합니다.
- 예시: 사람마다 다른 걸음 속도, 계절별 수요 변화 속도 차이

**4. Window Slicing (윈도우 슬라이싱)**
- 긴 시계열에서 다양한 길이와 위치의 부분 시퀀스를 추출하는 기법입니다.
- 구현: Sliding window를 이용해 `x[i:i+window_size]` 형태로 추출
- 효과: 다양한 시간 범위의 패턴을 학습하고 데이터 양을 크게 증가시킵니다.
- 예시: 24시간 데이터에서 1시간, 3시간, 6시간 윈도우를 다양한 시작점에서 추출

이러한 기법들은 단독으로 사용하거나 조합하여 사용할 수 있으며, 데이터의 특성과 태스크에 따라 적절히 선택해야 합니다.

---

### Question)
```
시계열 데이터 증강 시 주의해야 할 점은 무엇인가요?
특히 데이터의 의미가 훼손되는 문제를 어떻게 방지할 수 있나요?
```

### Answer)
시계열 데이터 증강 시 가장 중요한 것은 **원본 데이터의 본질적 특성과 의미를 보존**하는 것입니다. 부적절한 증강은 오히려 모델 성능을 저하시킬 수 있습니다.

**주요 주의사항:**

**1. 도메인 지식 고려**
- 시계열의 물리적/비즈니스적 의미를 이해해야 합니다.
- 예시: 주가는 음수가 될 수 없으므로 scaling 범위를 신중히 설정
- 예시: 심전도 신호는 특정 패턴(P, QRS, T파)의 상대적 위치가 중요하므로 과도한 time warping은 금물

**2. 레이블 일관성 유지**
- 증강 후에도 원본과 동일한 레이블이 유지되어야 합니다.
- 잘못된 예: 정상 패턴에 과도한 노이즈를 추가하여 이상 패턴처럼 보이게 만드는 경우
- 해결책: 클래스별 임계값을 설정하고, 증강 후 검증 단계 추가

**3. 시간적 인과관계 보존**
- 시계열의 순서와 인과관계를 유지해야 합니다.
- 잘못된 예: 시간 순서를 무작위로 섞는 것 (permutation)은 대부분의 경우 부적절
- 해결책: 순서를 유지하는 증강 기법(rotation, magnitude warping) 사용

**4. 통계적 특성 유지**
- 평균, 분산, 주기성 등 중요한 통계적 특성을 유지해야 합니다.
- 검증 방법: 증강 전후의 통계량을 비교하고 허용 범위 내인지 확인
- 예시: 계절성이 있는 데이터의 경우 주기를 보존하는 증강 적용

**5. 적절한 증강 강도 설정**
- 과도한 증강은 의미 훼손, 부족한 증강은 효과 미미
- 실험적 접근: 검증 세트에서 성능을 모니터링하며 하이퍼파라미터 조정
- 점진적 증강: 약한 증강부터 시작해서 강도를 점차 증가

**의미 훼손 방지 전략:**

1. **검증 메커니즘 구축**: 증강된 데이터의 품질을 자동으로 체크하는 rule-based validator 구현
2. **제약 조건 설정**: 물리적 제약(온도 범위, 속도 한계 등)을 코드에 명시
3. **전문가 검토**: 중요한 도메인의 경우 일부 증강 샘플을 전문가가 검토
4. **A/B 테스팅**: 증강 적용 전후의 모델 성능을 비교 평가
5. **보수적 접근**: 불확실한 경우 증강 강도를 낮게 설정

---

### Question)
```
AutoAugment나 LLM 기반 등 학습 기반 시계열 데이터 증강 방법에 대해 설명해주세요.
이러한 방법들의 장단점은 무엇인가요?
```

### Answer)
최근에는 데이터로부터 최적의 증강 전략을 자동으로 학습하는 기법들이 발전하고 있습니다. 전통적인 수동 증강 기법의 한계를 극복하고자 하는 접근입니다.

**1. AutoAugment 기반 방법**

**개념:**
- 강화학습을 사용하여 최적의 증강 정책(policy)을 탐색합니다.
- 다양한 증강 기법의 조합과 강도를 자동으로 선택합니다.

**시계열 적용 예시:**
- TSAugment: 시계열 특화 AutoAugment로, 증강 연산의 순서와 확률을 학습
- RandAugment: 증강 강도와 개수만 조절하여 탐색 공간을 단순화

**장점:**
- 도메인별 최적 증강 전략을 데이터 기반으로 발견
- 수동 튜닝보다 효율적이고 객관적
- 다양한 태스크에 일반화 가능

**단점:**
- 계산 비용이 매우 높음 (탐색에 수백~수천 GPU 시간 필요)
- 작은 데이터셋에서는 과적합 위험
- 탐색된 정책의 해석이 어려움

**2. GAN/VAE 기반 생성 모델**

**개념:**
- 생성 모델로 실제와 유사한 새로운 시계열 샘플을 생성합니다.
- TimeGAN, C-RNN-GAN 등이 대표적입니다.

**장점:**
- 실제 데이터 분포를 학습하여 현실적인 샘플 생성
- 복잡한 패턴과 의존성을 포착 가능
- 조건부 생성으로 특정 특성의 데이터 생성 가능

**단점:**
- 학습이 불안정하고 모드 붕괴(mode collapse) 위험
- 많은 학습 데이터가 필요
- 생성 품질 검증이 어려움

**3. LLM 기반 증강**

**개념:**
- 대규모 언어 모델(GPT, Claude 등)을 활용한 시계열 데이터 증강입니다.
- 텍스트로 인코딩된 시계열을 LLM으로 변형하거나, 메타데이터를 이용해 새로운 샘플 생성을 가이드합니다.

**접근 방법:**
- **Prompt-based**: 시계열을 텍스트로 변환 후 LLM에 증강 요청
  - 예: "다음 시계열 데이터에 계절성을 유지하면서 노이즈를 추가해줘: [데이터]"
- **Foundation Model Fine-tuning**: 시계열 foundation model(TimeGPT, LLMTime)을 특정 도메인에 파인튜닝
- **Hybrid**: LLM으로 증강 전략을 생성하고, 전통적 방법으로 실행

**장점:**
- 사전 학습된 지식 활용 가능
- 자연어로 증강 제약 조건 명시 가능
- 다양한 도메인에 빠르게 적응

**단점:**
- 정확한 수치적 제어가 어려움
- 시계열의 미세한 패턴 보존이 불확실
- API 비용 또는 대규모 모델 실행 비용
- 재현성(reproducibility) 문제

**4. 메타러닝 기반 증강**

**개념:**
- Few-shot learning 상황에서 메타러닝으로 효과적인 증강을 학습합니다.
- MAML(Model-Agnostic Meta-Learning)과 증강을 결합한 접근입니다.

**장점:**
- 적은 데이터로도 빠르게 적응
- 새로운 태스크에 대한 일반화 능력

**단점:**
- 구현 복잡도가 높음
- 메타학습 단계에서 다양한 태스크 필요

**선택 가이드:**

- **작은 데이터셋 (<1000 샘플)**: 전통적 증강 + 신중한 하이퍼파라미터 튜닝
- **중간 크기 (1000-10000)**: RandAugment 또는 간단한 학습 기반 방법
- **큰 데이터셋 (>10000)**: GAN/VAE 기반 생성 또는 AutoAugment
- **도메인 지식이 중요한 경우**: LLM 기반 (제약 조건을 자연어로 명시 가능)
- **실시간 적용 필요**: 전통적 증강 (추론 속도가 빠름)

학습 기반 증강은 강력하지만, 계산 비용과 복잡도를 고려하여 프로젝트의 제약 조건에 맞게 선택해야 합니다.
