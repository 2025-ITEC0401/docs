# 시계열 클러스터링

## Prompts (Powered by Claude)

### Question)
```
시계열 데이터 클러스터링을 위해 K-Means, Hierarchical Clustering, DBSCAN 중 어떤 방법을 선택해야 할까요? 각 방법의 장단점과 적합한 상황을 설명해주세요.
```

### Answer)
시계열 데이터 클러스터링에서 세 가지 방법은 각각 다른 특성과 장단점을 가지고 있습니다.

**K-Means 클러스터링**
- 장점:
  - 계산 효율성이 높아 대용량 데이터셋에 적합
  - 구현이 간단하고 해석이 용이
  - 클러스터 개수를 명확히 지정 가능
- 단점:
  - 클러스터 개수(k)를 사전에 지정해야 함
  - 구형 클러스터를 가정하므로 복잡한 형태의 클러스터 탐지 어려움
  - 이상치에 민감
- 적합한 상황: 클러스터 개수를 대략 알고 있고, 대용량 데이터를 빠르게 처리해야 할 때

**Hierarchical Clustering (계층적 클러스터링)**
- 장점:
  - 덴드로그램을 통해 클러스터 구조를 시각적으로 파악 가능
  - 클러스터 개수를 사전에 지정할 필요 없음
  - 다양한 거리 메트릭과 연결 방법 선택 가능
- 단점:
  - 계산 복잡도가 높아 대용량 데이터에 부적합 (O(n²) 이상)
  - 한번 병합/분할된 클러스터는 수정 불가능
- 적합한 상황: 데이터의 계층 구조를 파악하고 싶거나, 중소규모 데이터셋을 분석할 때

**DBSCAN (Density-Based Spatial Clustering)**
- 장점:
  - 클러스터 개수를 사전에 지정할 필요 없음
  - 임의 형태의 클러스터 탐지 가능
  - 이상치를 자동으로 식별하고 제거
- 단점:
  - 파라미터(epsilon, minPts) 설정이 결과에 큰 영향을 미침
  - 밀도가 다른 클러스터가 혼재할 때 성능 저하
  - 고차원 데이터에서 성능이 떨어질 수 있음
- 적합한 상황: 클러스터 개수를 모르고, 이상치가 많거나 불규칙한 형태의 클러스터가 예상될 때

---

### Question)
```
DTW(Dynamic Time Warping) 기반 클러스터링이 무엇이며, 일반적인 유클리디안 거리 기반 클러스터링과 비교했을 때 어떤 장점이 있나요? 시계열 데이터에서 DTW를 사용하는 이유를 설명해주세요.
```

### Answer)
DTW(Dynamic Time Warping)는 두 시계열 간의 유사도를 측정하는 거리 메트릭으로, 시간축 상의 왜곡을 허용하여 패턴을 비교합니다.

**DTW의 작동 원리**
DTW는 두 시계열의 각 점들 사이의 최적 정렬(alignment)을 찾아 거리를 계산합니다. 이를 통해 시간적으로 약간 어긋나 있거나 속도가 다른 유사한 패턴을 동일한 것으로 인식할 수 있습니다.

**유클리디안 거리 대비 장점**

1. **시간적 왜곡 처리**: 유클리디안 거리는 같은 인덱스의 점들만 비교하지만, DTW는 시간축의 이동, 압축, 확장을 허용합니다.
   - 예: 같은 패턴이지만 한 시계열이 더 빠르거나 느리게 진행되는 경우

2. **위상 차이(Phase Shift) 대응**: 패턴이 시간적으로 앞뒤로 이동해도 유사성을 감지할 수 있습니다.
   - 예: 계절성 패턴이 몇 주 차이로 발생하는 경우

3. **길이가 다른 시계열 비교**: 서로 다른 길이의 시계열도 비교 가능합니다.

**DTW 기반 클러스터링이 유용한 경우**
- 음성 인식, 제스처 인식 등 속도 변화가 있는 데이터
- 생체 신호(ECG, EEG) 분석에서 개인차로 인한 시간 차이가 있는 경우
- 금융 시계열에서 유사한 추세를 보이지만 시점이 다른 패턴 탐지

**단점 및 고려사항**
- 계산 복잡도가 O(n²)로 높아 대용량 데이터에서는 느림
- FastDTW, PrunedDTW 등의 최적화 방법 사용 필요
- Sakoe-Chiba band, Itakura parallelogram 등의 제약을 두어 계산량 감소 가능

---

### Question)
```
시계열 클러스터링 결과를 평가하는 지표인 NMI, ARI, Silhouette Score에 대해 설명해주세요. 각 지표는 언제 사용하며, 어떻게 해석하나요?
```

### Answer)
시계열 클러스터링의 품질을 평가하는 세 가지 주요 지표를 소개합니다.

**1. NMI (Normalized Mutual Information)**

- **정의**: 정보 이론 기반의 지표로, 클러스터링 결과와 실제 레이블 간의 상호 정보량을 측정합니다.
- **범위**: 0 ~ 1 (1에 가까울수록 좋음)
- **특징**:
  - 정규화되어 클러스터 개수에 영향을 덜 받음
  - 클러스터 크기의 불균형에도 강건
  - 실제 레이블(ground truth)이 필요
- **해석**:
  - NMI = 1: 완벽한 클러스터링
  - NMI = 0: 무작위 클러스터링과 동일
- **사용 시기**: 정답 레이블이 있는 지도 학습 평가 상황

**2. ARI (Adjusted Rand Index)**

- **정의**: 클러스터링 결과와 실제 레이블 간의 일치도를 측정하며, 우연에 의한 일치를 보정합니다.
- **범위**: -1 ~ 1 (1에 가까울수록 좋음, 0은 무작위 수준)
- **특징**:
  - 우연에 의한 일치를 보정(adjusted)하여 더 엄격한 평가
  - 클러스터 개수나 샘플 수에 독립적
  - 실제 레이블이 필요
- **해석**:
  - ARI = 1: 완벽한 클러스터링
  - ARI = 0: 무작위 클러스터링
  - ARI < 0: 무작위보다 나쁜 클러스터링
- **사용 시기**: 정답 레이블이 있으며, 우연에 의한 일치를 배제하고 싶을 때

**3. Silhouette Score (실루엣 점수)**

- **정의**: 각 샘플이 자신의 클러스터에 얼마나 잘 속해 있는지, 그리고 다른 클러스터와 얼마나 잘 분리되어 있는지를 측정합니다.
- **범위**: -1 ~ 1 (1에 가까울수록 좋음)
- **계산**: S = (b - a) / max(a, b)
  - a: 같은 클러스터 내 다른 샘플들과의 평균 거리
  - b: 가장 가까운 다른 클러스터까지의 평균 거리
- **특징**:
  - 실제 레이블이 없어도 사용 가능 (비지도 평가)
  - 클러스터의 밀집도와 분리도를 동시에 고려
  - 각 샘플별로 계산하여 전체 평균을 구함
- **해석**:
  - S ≈ 1: 샘플이 올바른 클러스터에 잘 배정됨
  - S ≈ 0: 샘플이 클러스터 경계에 위치
  - S < 0: 샘플이 잘못된 클러스터에 배정되었을 가능성
- **사용 시기**: 정답 레이블이 없는 비지도 학습 상황, 최적 클러스터 개수 결정

**선택 가이드**
- 정답 레이블 있음: NMI와 ARI를 함께 사용 (ARI가 더 엄격)
- 정답 레이블 없음: Silhouette Score 사용
- 클러스터 개수 결정: Elbow method와 함께 Silhouette Score 활용
- 시계열 특성 고려: DTW 거리 기반의 Silhouette Score도 고려

**주의사항**
- 하나의 지표만으로 판단하지 말고 여러 지표를 종합적으로 고려
- 도메인 지식과 시각화를 통한 정성적 평가도 병행
- 시계열 데이터의 경우 거리 메트릭(유클리디안 vs DTW)에 따라 결과가 달라질 수 있음
