# 교차 검증(Cross Validation) 학습 자료

## Prompts

### Question)
```
K-Fold 교차 검증이란 무엇이고, 왜 사용하나요? 일반적인 train/test split과 비교해서 장단점은 무엇인가요?
```

### Answer)
**K-Fold 교차 검증 개념**

데이터를 K개의 동일한 크기의 폴드로 나누고, 각 폴드를 한 번씩 검증 세트로 사용하여 총 K번 학습/평가를 수행하는 기법입니다.

**동작 방식:**
1. 데이터를 K개 폴드로 분할
2. 1번 폴드를 검증용, 나머지 K-1개를 학습용으로 사용
3. 다음 폴드를 검증용으로 변경하여 반복
4. K개의 성능 점수를 평균하여 최종 성능 산출

**사용 이유:**
- 모든 데이터가 학습과 검증에 한 번씩 사용됨
- 더 신뢰성 있는 성능 추정
- 데이터가 적을 때 특히 유용

**비교: K-Fold vs 단순 Split**

| 특성 | Train/Test Split | K-Fold CV |
|------|-----------------|-----------|
| 계산 비용 | 낮음 | K배 높음 |
| 성능 추정 분산 | 높음 | 낮음 |
| 데이터 활용도 | 낮음 | 높음 |
| 구현 복잡도 | 단순 | 복잡 |

```python
from sklearn.model_selection import KFold, cross_val_score

kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 교차 검증 수행
scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')
print(f"평균 정확도: {scores.mean():.4f} ± {scores.std():.4f}")
```

---

### Question)
```
시계열 데이터에서는 왜 일반적인 K-Fold를 사용하면 안 되나요? Time Series Split은 어떻게 다른가요?
```

### Answer)
**시계열에서 일반 K-Fold의 문제점:**

1. **데이터 누수(Data Leakage)**: 미래 데이터로 학습하고 과거를 예측하는 상황 발생
2. **시간적 의존성 무시**: 시계열의 자기상관(autocorrelation) 특성 무시
3. **비현실적인 평가**: 실제 배포 상황과 맞지 않음

**Time Series Split (시계열 교차 검증)**

```
Fold 1: [Train: ----] [Valid: --]
Fold 2: [Train: ------] [Valid: --]
Fold 3: [Train: --------] [Valid: --]
Fold 4: [Train: ----------] [Valid: --]
```

- 항상 과거 데이터로 학습, 미래 데이터로 검증
- 시간 순서 유지
- 점진적으로 학습 데이터 증가

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

for train_idx, valid_idx in tscv.split(X):
    X_train, X_valid = X[train_idx], X[valid_idx]
    y_train, y_valid = y[train_idx], y[valid_idx]

    model.fit(X_train, y_train)
    score = model.score(X_valid, y_valid)
```

**추가 고려사항:**
- Gap 설정: 학습과 검증 사이에 간격을 두어 정보 누수 방지
- 슬라이딩 윈도우: 학습 데이터 크기 고정
- Purging: 겹치는 정보가 있는 샘플 제거

---

### Question)
```
Stratified K-Fold와 Group K-Fold는 각각 언제 사용하나요?
```

### Answer)
**Stratified K-Fold**

클래스 비율을 각 폴드에서 동일하게 유지하는 교차 검증 방법입니다.

**사용 상황:**
- 클래스 불균형 데이터
- 분류 문제
- 각 폴드가 전체 데이터 분포를 대표해야 할 때

```python
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, valid_idx in skf.split(X, y):
    # 각 폴드에서 y의 클래스 비율이 동일
    pass
```

**Group K-Fold**

같은 그룹의 샘플들이 학습과 검증 세트에 동시에 포함되지 않도록 분할합니다.

**사용 상황:**
- 같은 환자의 여러 측정값
- 같은 사용자의 여러 기록
- 동일 출처의 데이터가 누수되면 안 될 때

```python
from sklearn.model_selection import GroupKFold

groups = patient_ids  # 환자 ID 배열
gkf = GroupKFold(n_splits=5)

for train_idx, valid_idx in gkf.split(X, y, groups):
    # 같은 환자의 데이터가 train/valid에 나뉘지 않음
    pass
```

**선택 가이드:**

| 상황 | 권장 방법 |
|------|----------|
| 클래스 불균형 | Stratified K-Fold |
| 그룹 단위 데이터 | Group K-Fold |
| 시계열 데이터 | Time Series Split |
| 일반적인 경우 | K-Fold |
| 불균형 + 그룹 | StratifiedGroupKFold |
