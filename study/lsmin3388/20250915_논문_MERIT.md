### **MERIT 논문 완전 정복 (상세 정리판)**

이 논문은 **MERIT**이라는 새로운 프레임워크에 대한 내용임. 시계열 데이터(주가, 심전도, 센서 값 등)를 AI가 '스스로 학습(unsupervised learning)'하게 하는 기술인데, 기존 방식의 문제점을 해결하기 위해 LLM(대규모 언어 모델)을 아주 똑똑하게 활용한 게 핵심.

#### **1. 시작하게 된 계기: 기존 방식의 문제점과 LLM의 한계**

* **기존 방식의 문제점**: 원래 이런 학습을 시킬 때, 원본 데이터를 약간씩 비틀거나 변형(이걸 '증강'이라고 함)해서 학습 자료의 양을 뻥튀기하는 방식을 많이 썼음. 근데 이게 시계열 데이터에서는 문제가 좀 있었음. 무작위로 데이터를 바꾸다 보니, 데이터가 가진 원래의 중요한 의미(패턴, 특징적인 피크 등)를 훼손할 수 있다는 거임. 예를 들어, 심전도 데이터의 특징적인 뾰족한 부분을 뭉개버리면 학습이 제대로 될 리가 없음.

* **그럼 LLM을 쓰면 되지 않나? -> 이것도 문제가 있었음**:
    * LLM은 천재 같지만, 사실 숫자 데이터 자체에 대한 이해도는 좀 떨어짐. 그래서 시계열 데이터를 바로 주고 "이거랑 비슷한 거 만들어봐" 하면 잘 못 만듦.
    * 심지어 다음 토큰을 예측하는 원리 때문에 아예 형식에 안 맞는 이상한 결과를 뱉을 수도 있다고 함.
    * 특히 데이터에 대한 사전 정보가 없는 제로샷(zero-shot) 환경에서는 복잡한 시계열 데이터의 의미를 파악하거나 특징을 뽑아내는 능력이 부족했음.

* **해결책 제안**: 이런 문제들 때문에, LLM을 제대로 활용하려면 그냥 쓰는 게 아니라 **'문맥 검색(contextual search)'**과 **'잘 설계된 지침(prompt)'**이 필수적이라는 결론에 도달함. 그래서 이 모든 문제를 해결하기 위해 MERIT라는 새로운 프레임워크를 제안하게 된 거임.

#### **2. 관련 연구들**

* **시계열 표현 학습**: 그동안 많은 연구가 있었지만, 대부분 데이터 특성을 고려하지 않고 고정된 증강 전략을 쓰거나 , 증강 과정에서 데이터의 의미가 손상될 수 있는 한계가 있었음.
* **다중 에이전트 시스템(MAS)**: 여러 명의 에이전트(AI)가 서로 협력하거나 경쟁하면서 공동의 목표를 달성하는 시스템임. 최근 머신러닝 분야에서 주목받고 있는데 , MERIT도 바로 이 개념을 도입해서 3명의 전문 LLM 에이전트가 협력해서 문제를 해결하는 방식을 채택함.

#### **3. 그래서 MERIT가 정확히 뭔데? (핵심 방법론)**

MERIT의 핵심은 **검색, 증강, 검토** 3가지 역할을 맡은 LLM 에이전트 3인방의 완벽한 팀플레이임. 이 에이전트들이 순환 구조로 계속 소통하면서 최적의 학습 데이터를 생성함.

**1) 검색 에이전트 (Retrieval Agent): 정보 탐색 전문가**

* **역할**: LLM이 숫자 데이터를 바로 이해하기 어려우니, 학습의 길잡이가 될 만한 '맥락(Context)'을 찾아주는 역할임.
* **작동 방식**:
    1.  **후보 선별**: 현재 데이터와 통계적으로 유사한 데이터들을 일단 거칠게 쭉 뽑음. 모든 데이터를 비싼 LLM에 물어보면 비효율적이니까, 1차로 걸러내는 과정.
    2.  **LLM 정제**: 1차로 뽑은 후보들 중에서, LLM에게 "의미적으로 가장 관련 있는 데이터를 골라주고, 왜 그렇게 생각하는지 이유도 알려줘"라고 요청해서 최종 참조 데이터를 선택함.

**2) 증강 에이전트 (Augmentation Agent): 데이터 생성 전문가**

* **역할**: 검색 에이전트가 찾아준 참조 데이터를 바탕으로, 현재 데이터에 가장 적절한 '증강(변형) 전략'을 선택하는 역할임.
* **작동 방식**: '지터링', '스케일링', '마스킹' 등 여러 증강 전략 라이브러리에서 , LLM이 데이터 특성을 분석해 "이 데이터에는 이 방식이 제일 좋겠다!"라고 최적의 전략을 자동으로 골라줌. 무작위 선택이 아닌, 데이터 맞춤형 전략이라는 점에서 기존 방식과 차별화됨.

**3) 검토 에이전트 (Review Agent): 품질 관리 전문가**

* **역할**: A.K.A 품질관리팀(QC). 증강된 결과물이 정말 괜찮은지, 원본의 의미를 훼손하지 않았는지 최종 검토함. LLM의 환각(Hallucination) 같은 문제로 인해 생성될 수 있는 저품질 데이터를 걸러내는 아주 중요한 역할임.
* **작동 방식**:
    * **품질 평가**: LLM이 원본과 증강 데이터를 비교하며 "이거 Correct(정상)이야, Error(오류)야?"라고 판정함.
    * **피드백**: '정상' 판정을 받은 고품질 데이터만 **'메모리 뱅크'**에 저장해서 최종 학습에 사용함. '오류' 판정을 받으면 가차 없이 버리고, 필요하면 검색 단계로 되돌아가기도 함. 이를 통해 학습 데이터의 신뢰성을 크게 높임.

**4) 최종 학습 (Representation Learning)**

* 이렇게 에이전트들이 협업해서 모은 고품질의 데이터들(검토를 통과한 증강 데이터 + 검색된 유사 데이터)을 '긍정적 뷰(positive views)'로 삼아 **대비 학습(Contrastive Learning)**을 진행함.
* 학습 목표는 간단함. "원본 데이터와 이 긍정적 뷰들은 최대한 가깝게, 다른 아무 데이터와는 최대한 멀게" 만들어서, 데이터의 핵심 특징을 잘 나타내는 표현(representation)을 학습하는 거임.