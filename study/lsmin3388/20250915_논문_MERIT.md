### **MERIT 논문 완전 정복 (상세 정리판)**

이 논문은 **MERIT**이라는 새로운 프레임워크에 대한 내용임. 시계열 데이터(주가, 심전도, 센서 값 등)를 AI가 '스스로 학습(unsupervised learning)'하게 하는 기술인데, 기존 방식의 문제점을 해결하기 위해 LLM(대규모 언어 모델)을 아주 똑똑하게 활용한 게 핵심.

#### **1. 시작하게 된 계기: 기존 방식의 문제점과 LLM의 한계**

* **기존 방식의 문제점**: 원래 이런 학습을 시킬 때, 원본 데이터를 약간씩 비틀거나 변형(이걸 '증강'이라고 함)해서 학습 자료의 양을 뻥튀기하는 방식을 많이 썼음. 근데 이게 시계열 데이터에서는 문제가 좀 있었음. 무작위로 데이터를 바꾸다 보니, 데이터가 가진 원래의 중요한 의미(패턴, 특징적인 피크 등)를 훼손할 수 있다는 거임. 예를 들어, 심전도 데이터의 특징적인 뾰족한 부분을 뭉개버리면 학습이 제대로 될 리가 없음.

* **그럼 LLM을 쓰면 되지 않나? -> 이것도 문제가 있었음**:
    * LLM은 천재 같지만, 사실 숫자 데이터 자체에 대한 이해도는 좀 떨어짐. 그래서 시계열 데이터를 바로 주고 "이거랑 비슷한 거 만들어봐" 하면 잘 못 만듦.
    * 심지어 다음 토큰을 예측하는 원리 때문에 아예 형식에 안 맞는 이상한 결과를 뱉을 수도 있다고 함.
    * 특히 데이터에 대한 사전 정보가 없는 제로샷(zero-shot) 환경에서는 복잡한 시계열 데이터의 의미를 파악하거나 특징을 뽑아내는 능력이 부족했음.

* **해결책 제안**: 이런 문제들 때문에, LLM을 제대로 활용하려면 그냥 쓰는 게 아니라 **'문맥 검색(contextual search)'**과 **'잘 설계된 지침(prompt)'**이 필수적이라는 결론에 도달함. 그래서 이 모든 문제를 해결하기 위해 MERIT라는 새로운 프레임워크를 제안하게 된 거임.