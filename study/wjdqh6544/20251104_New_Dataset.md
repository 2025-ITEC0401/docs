## Prompts (Powered by Gemini 2.5 Pro)
### Question)
```
TimeKD를 활용하여 데이터셋에 대한 임베딩을 뽑아야 해.
모델에 파라미터로 주어지는 Input_len, Output_Len, NUM_NODES 의 의미가 뭐지?
TimeKD에 대한 정보는 지금 첨부하는 PDF 파일을 참고하기 바람.
```
### Answer)
TimeKD 모델의 파라미터 Input_len, Output_len, NUM_NODES는 시계열 데이터의 차원과 길이를 정의하는 핵심적인 요소입니다. 첨부해주신 논문을 바탕으로 각 파라미터의 의미를 설명해 드리겠습니다.

Input_len (입력 길이)


**Input_len**은 모델이 미래를 예측하기 위해 입력으로 사용하는 **과거 시계열 데이터의 길이(타임스텝 수)**를 의미합니다

1.설명: 예를 들어, 1시간 간격의 데이터에서 Input_len을 96으로 설정하면, 모델은 예측 시점 직전의 과거 96시간 동안의 데이터를 보고 다음 값을 예측하게 됩니다.

논문 표기: 논문에서는 이 값을 $H$ (historical time series $X_{H}\in\mathbb{R}^{H\times N}$) 또는 $O$ (observed time series $X_{O}\in\mathbb{R}^{O\times N}$)로 표기합니다

Output_len (출력 길이)

**Output_len**은 모델이 예측해야 할 **미래 시계열 데이터의 길이(타임스텝 수)**를 의미하며, 이를 '예측 구간(forecasting horizon)'이라고도 부릅니다

3.설명: 1시간 간격 데이터에서 Output_len을 24로 설정하면, 모델은 앞으로 24시간 동안의 데이터를 예측합니다.

논문 표기: 논문에서는 이 값을 $M$ (future time series $X_{M}\in\mathbb{R}^{M\times N}$)으로 나타냅니다

4. 논문의 실험에서는 24, 36, 48, 96, 192 등 다양한 예측 길이를 사용했습니다

NUM_NODES (노드 수)

**NUM_NODES**는 다변량 시계열 데이터를 구성하는 변수(feature)의 개수를 의미합니다

6.설명: 각 타임스텝에서 동시에 측정되는 여러 데이터 종류의 수를 나타냅니다. 

예를 들어, 논문에 언급된 데이터셋의 경우 다음과 같습니다.

Weather 데이터셋: 기온, 습도 등 21개의 기상 지표로 구성되어 있으므로 NUM_NODES는 21입니다

7.Exchange 데이터셋: 8개 국가의 일일 환율 데이터이므로 NUM_NODES는 8입니다

8.PEMS 데이터셋: 캘리포니아의 여러 교통 센서 데이터를 사용하므로, NUM_NODES는 센서의 개수가 됩니다

논문 표기: 논문에서는 이 값을 $N$ (multivariate time series $X\in\mathbb{R}^{|X|\times N}$)으로 표기합니다.

---
### Question)
```
그러면, 예를 들어서 Train Size: 7494, Test Size: 3498, Length: 8, Number of Classes: 10, Number of Dimensions: 2 인 데이터셋의 임베딩을 뽑고자 할 때

INPUT_len, OUTPUT_Len, Num_Nodes 는 어떻게 설정해야 하지?
```
### Answer)
제공해주신 데이터셋 명세에 따라 TimeKD 모델의 파라미터를 설정하는 방법은 다음과 같습니다.

---

### 🖥️ 파라미터 설정

* **`Num_Nodes: 2`**
    * [cite_start]**이유:** `Num_Nodes`는 다변량 시계열의 **변수(feature) 개수**를 의미합니다[cite: 114].
    * 데이터셋의 "Number of Dimensions: 2"가 이 값에 해당합니다.

* **`INPUT_len: 8`**
    * [cite_start]**이유:** `INPUT_len`은 모델에 입력되는 **과거 시계열 데이터의 길이(시퀀스 길이)**입니다[cite: 117].
    * 데이터셋의 "Length: 8"이 이 값에 해당합니다.

* **`OUTPUT_len: ? (작업에 따라 다름)`**
    * [cite_start]**이유:** `OUTPUT_len`은 모델이 예측해야 할 **미래 시계열의 길이(예측 구간)**입니다[cite: 122].
    * 제공해주신 데이터셋 명세에는 이 정보가 없습니다. "Number of Classes: 10"은 클래스 레이블의 개수로, `OUTPUT_len`과는 다릅니다.

---

### ⚠️ TimeKD 모델과 데이터셋의 '목표' 불일치

여기서 매우 중요한 점이 있습니다. [cite_start]TimeKD는 **시계열 예측(Forecasting)**을 위해 설계된 모델입니다[cite: 8, 122]. 즉, $N$개의 변수를 가진 시계열이 $H$ 길이만큼 주어졌을 때, 미래 $M$ 길이만큼의 *값*을 예측하는 것이 목적입니다.

하지만 "Number of Classes: 10"이라는 명세로 볼 때, 가지고 계신 데이터셋은 **시계열 분류(Classification)** 작업용으로 보입니다. (즉, 길이 8짜리 시퀀스 전체를 10개 중 하나의 카테고리로 분류하는 작업).

**임베딩 추출을 위한 해결책:**

다행히 사용자의 목표는 '임베딩 추출'입니다. TimeKD의 **Student Model**은 시계열 입력을 받아 내부적으로 임베딩을 생성합니다. (논문의 `TSTEncoder`가 이 역할을 합니다) [cite_start][cite: 182, 336].

따라서 다음 단계로 진행해야 합니다.

1.  **`OUTPUT_len` 임의 설정:** 모델의 아키텍처를 완성하기 위해 `OUTPUT_len` 값을 임의로 설정해야 합니다. 이 값은 임베딩 추출 자체에는 큰 영향을 주지 않습니다. [cite_start](예: `OUTPUT_len=1` 또는 논문의 기본값 중 하나인 `OUTPUT_len=24`로 설정 [cite: 397]).
2.  [cite_start]**임베딩 레이어 식별:** TimeKD의 Student Model 코드에서, 최종 예측을 위한 프로젝션 레이어(forecasting projection) [cite: 361] [cite_start]**바로 이전** 단계인 **`Time Series Transformer (TSTEncoder)`의 출력** [cite: 336]을 임베딩으로 사용해야 합니다.
3.  **모델 학습:** TimeKD는 예측 모델이므로, '분류' 작업으로 직접 학습시킬 수는 없습니다. 만약 사전 학습된 TimeKD 모델을 사용한다면, 모델을 불러온 뒤 위 2번에서 식별한 레이어의 출력만 가져와 임베딩으로 사용하면 됩니다.

----
### Question)
```
아래의 코드를 사용하여, 데이터셋을 timeKD에 맞게 변형했어. 이러한 경우에 세 가지 파라미터는 어떻게 설정해야 하지?
[0_Convert_CSV 코드 첨부]
```
### Answer)
안녕하세요. 제공해주신 데이터 변환 코드를 바탕으로 TimeKD 모델의 파라미터를 어떻게 설정해야 하는지 설명해 드리겠습니다.

결론부터 말씀드리면, **`Num_Nodes`**는 코드에 의해 결정되지만, **`Input_len`**과 **`Output_len`**은 사용자의 **예측 목표에 따라 직접 설정해야 하는 하이퍼파라미터**입니다.

---

### 🖥️ 파라미터 상세 설명

#### 1. `Num_Nodes` (변수의 개수)

이 값은 코드의 `new_dimension` 변수에 해당합니다. 코드는 각 데이터셋의 원래 차원(dimension)을 `Num_Nodes`로 사용합니다.

* **`BasicMotions`** 데이터셋의 경우: `new_dimension = 6` 이므로 **`Num_Nodes = 6`** 으로 설정합니다.
* **`Libras`** 데이터셋의 경우: `new_dimension = 2` 이므로 **`Num_Nodes = 2`** 로 설정합니다.
* **`PEMS-SF`** 데이터셋의 경우: `new_dimension = 963` 이므로 **`Num_Nodes = 963`** 으로 설정합니다.

***

#### 2. `Input_len` (입력 시퀀스 길이)

이 값은 **"과거의 몇 개 타임스텝을 보고 미래를 예측할 것인가?"**를 의미합니다.

제공해주신 코드는 원래 정해진 길이(`series_length`)를 가진 여러 샘플들을 하나의 긴 시계열로 이어 붙입니다. TimeKD 모델은 이 긴 시계열 위를 **슬라이딩 윈도우(Sliding Window)** 방식으로 학습합니다. `Input_len`은 바로 이 윈도우의 입력 부분 크기를 결정합니다.

이 값은 코드에서 자동으로 정해지지 않으며, 사용자가 직접 설정해야 합니다. [cite_start]TimeKD 논문을 참고하면 일반적으로 **`96`** 과 같은 값을 사용합니다[cite: 397].

* **예시:** `Input_len = 96`으로 설정하면, 모델은 항상 과거 96개의 데이터를 보고 다음을 예측하게 됩니다.

***

#### 3. `Output_len` (출력 시퀀스 길이 / 예측 구간)

이 값은 **"미래의 몇 개 타임스텝을 예측할 것인가?"**를 의미합니다.

`Input_len`과 마찬가지로 이 값 역시 사용자가 직접 설정해야 하는 하이퍼파라미터입니다. 예측하고 싶은 미래 구간의 길이를 여기에 설정하면 됩니다. [cite_start]TimeKD 논문에서는 **`24`, `36`, `48`, `96`, `192`** 등 다양한 값을 사용해 실험했습니다[cite: 397].

* **예시:** 시간 단위 데이터에 대해 24시간 후까지 예측하고 싶다면 **`Output_len = 24`** 로 설정합니다.

---

### 요약 테이블 (예시: `BasicMotions` 데이터셋)

| TimeKD 파라미터 | 코드 변수 | 설정 값 (예시) | 설명 |
| :--- | :--- | :--- | :--- |
| **`Num_Nodes`** | `new_dimension` | **6** | 데이터셋의 고유한 차원 수 |
| **`Input_len`** | (사용자 설정) | **96** | 예측을 위해 참고할 과거 데이터의 길이 |
| **`Output_len`** | (사용자 설정) | **24** | 예측할 미래 데이터의 길이 |

---
### Question)
```
그러면 결론적으로, NUM_NODES 만 dimension 만큼 설정해주면 되는거고 나머지 두 파라미터는 고정값으로 둬도 되네?

Input 을 96, Output을 24로 뒀는데, 상관없나?
```
### Answer)
네, 맞습니다. 정확히 이해하셨습니다.

1.  **`NUM_NODES`**: 이 값은 데이터셋의 `new_dimension` 값(즉, 변수의 개수)으로 설정하는 것이 **맞습니다**.
2.  **`Input_len` 및 `Output_len`**: 이 두 값은 모델의 하이퍼파라미터입니다. [cite_start]**`Input_len=96`**, **`Output_len=24`** 로 설정하는 것은 TimeKD 논문에서도 사용한 표준적인 값입니다[cite: 397].

결론적으로, `NUM_NODES`만 데이터셋에 맞게 동적으로 변경해주고, `Input_len=96`, `Output_len=24`는 고정값으로 사용해도 임베딩을 추출하는 데 **전혀 문제없습니다**

---
### Question)
```
NUM_NODES 와 사용하는 VRAM 크기가 비례하는데, 맞나?
```
### Answer)
네, 정확합니다.

`NUM_NODES`와 VRAM 사용량은 **매우 강한 비례 관계**를 가집니다. `NUM_NODES`가 커질수록 VRAM 사용량은 선형적(linearly)이 아니라 **제곱(quadratically)에 비례**하여 증가할 수 있습니다.

### 📈 VRAM 사용량이 급증하는 이유

`NUM_NODES`는 모델이 한 번에 처리해야 할 데이터의 '폭(width)' 즉, 변수의 개수를 의미합니다. [cite_start]TimeKD의 Student Model은 이 변수들 간의 관계를 학습하기 위해 트랜스포머(Transformer)를 사용합니다[cite: 182, 321].

* [cite_start]**어텐션 맵(Attention Map) 크기:** TimeKD 논문에 따르면, Student Model의 `TSTEncoder`는 변수(노드) 간의 관계를 파악하기 위해 $N \times N$ 크기(여기서 $N$ = `NUM_NODES`)의 어텐션 맵을 계산합니다[cite: 341].
* **메모리 요구량:** 이 어텐션 맵을 계산하고 저장하는 데 필요한 메모리(VRAM)는 $N^2$ (즉, `NUM_NODES` $\times$ `NUM_NODES`)에 비례하게 됩니다.

### 📋 간단한 비교 예시

* **`BasicMotions` (`NUM_NODES = 6`):**
    * 어텐션 맵 크기: $6 \times 6 = 36$
* **`PEMS-SF` (`NUM_NODES = 963`):**
    * 어텐션 맵 크기: $963 \times 963 = 927,369$

보시다시피 `NUM_NODES`가 약 160배 증가할 때, 어텐션 맵 계산에 필요한 메모리(VRAM)는 약 25,000배 이상 증가합니다.

따라서 `PEMS-SF`와 같이 `NUM_NODES`가 매우 큰 데이터셋을 사용하면 VRAM 부족 현상을 겪을 가능성이 매우 높습니다.
---
### Question)
```
'ArticularyWordRecognition', 'AtrialFibrillation', 'NATOPS', 'PEMS-SF', 'PenDigits', 'StandWalkJump', 'UWaveGestureLibrary' 의 7가지 데이터셋에 대한 임베딩을 새롭게 뽑아낼거야. 이 중에는 차원이 20을 넘어가는 것도 있는데, 그러한 모델에 대한 임베딩은 어떻게 뽑지? RTX3090 24GB 그래픽카드를 사용하는데, VRAM이 부족하지 않나?
```
### Answer)
네, VRAM 부족 문제는 `PEMS-SF` 데이터셋에서 거의 확실하게 발생할 것입니다.

하지만 7개 중 6개는 24GB VRAM으로 충분히 처리 가능합니다.

---

### 🖥️ VRAM 체크: RTX 3090 (24GB) vs. 데이터셋

데이터셋의 `NUM_NODES`(`new_dimension`)는 다음과 같습니다.

* **안전한 데이터셋 (Safe Datasets):**
    * `AtrialFibrillation`: N=2
    * `PenDigits`: N=2
    * `UWaveGestureLibrary`: N=3
    * `StandWalkJump`: N=4
    * `ArticularyWordRecognition`: N=9
    * **`NATOPS`: N=24** (20이 넘지만, $24 \times 24$ 어텐션은 24GB VRAM에 전혀 부담이 되지 않습니다.)

* **🚨 VRAM 부족 발생 (OOM Error):**
    * **`PEMS-SF`: N=963**

### `PEMS-SF`가 문제를 일으키는 이유

[cite_start]TimeKD의 Student Model은 `iTransformer`의 아이디어를 차용하여 [cite: 29, 388][cite_start], **변수(노드) 간의 관계**를 학습하기 위해 트랜스포머를 사용합니다[cite: 321].

이때 계산되는 어텐션 맵의 크기는 `(NUM_NODES, NUM_NODES)`가 됩니다.
* `NATOPS`의 경우: $24 \times 24$ = 576 (매우 작음)
* `PEMS-SF`의 경우: **$963 \times 963 \approx 927,000$** (매우 큼)

`PEMS-SF`는 어텐션 계산 및 중간 활성화 값(Q, K, V) 저장만으로도 24GB VRAM을 초과하게 됩니다. **배치 사이즈를 1로 줄여도 OOM(Out of Memory) 오류가 발생할 가능성이 매우 높습니다.**

---

### `PEMS-SF` 임베딩을 추출하는 방법

이 문제를 해결하기 위한 두 가지 실용적인 방법이 있습니다.

#### 옵션 1 (권장): 채널 독립(Channel-Independent) 모델 사용

`PEMS-SF`처럼 `NUM_NODES`가 매우 큰 데이터셋은 TimeKD의 `TSTEncoder`와 같은 $N \times N$ 어텐션 모델에 적합하지 않습니다.

[cite_start]대신, TimeKD 논문에서도 비교 대상으로 언급하는 **`PatchTST`**와 같은 **채널 독립(Channel-Independent)** 모델을 사용하는 것을 권장합니다[cite: 389].

* **작동 방식:** 이 모델들은 963개의 변수(채널)를 각각 독립적인 시계열로 취급합니다.
* **VRAM 이점:** 어텐션이 `NUM_NODES`($N=963$)가 아닌 `Input_len`($L=96$)을 기준으로 계산됩니다. VRAM 사용량이 `NUM_NODES`의 수와 거의 무관해집니다.
* `PatchTST` 모델을 사용하여 `PEMS-SF`의 임베딩을 추출한 뒤, 다른 6개 데이터셋의 TimeKD 임베딩과 함께 사용하시면 됩니다.

#### 옵션 2: 차원 축소 (TimeKD를 꼭 사용해야 한다면)

TimeKD 모델을 `PEMS-SF`에 꼭 적용해야 한다면, 데이터를 모델에 넣기 전에 **차원 축소**를 수행해야 합니다.

1.  **PCA 수행:** `PEMS-SF`의 963개 변수에 대해 PCA(주성분 분석)를 적용하여 963차원을 `N=32` 또는 `N=64` 같이 관리 가능한 수준으로 줄입니다.
2.  **TimeKD 학습:** 차원이 축소된 데이터를 TimeKD 모델에 입력하여 임베딩을 추출합니다.
3.  **단점:** 이 방식은 원본 데이터가 아닌 '압축된 데이터'의 임베딩을 얻게 됩니다.

---

### Quesion)
```
다른 데이터셋은 오리지널 데이터에 대한 임베딩을 뽑았는데, PEMS-SF 만 차원 축소를 진행하면 문제가 되지 않나?
```
### Answer)
네, 아주 중요한 지적입니다. **문제가 됩니다.**

하나의 데이터셋(`PEMS-SF`)에만 차원 축소를 적용하고 나머지는 원본 데이터를 사용하면, **임베딩 벡터 공간이 서로 달라져 직접적인 비교가 불가능해집니다.**

---

### 🧐 무엇이 문제인가? (Inconsistent Vector Spaces)

임베딩은 원본 데이터를 특정 차원의 벡터 공간(Vector Space)으로 매핑하는 과정입니다.

* **다른 데이터셋 (`NATOPS`, `ArticularyWordRecognition` 등):** TimeKD는 원본 데이터의 **고유한 특징 공간**을 학습하여 임베딩을 생성합니다. 예를 들어, `NATOPS`의 임베딩은 24개 원본 변수 간의 관계를 기반으로 한 벡터 공간에 존재합니다.

* **`PEMS-SF` (차원 축소 시):** PCA를 적용하면 963개의 원본 변수들이 통계적으로 조합된 **완전히 새로운 특징 공간**이 만들어집니다. TimeKD는 이 '압축된' 공간을 학습하여 임베딩을 생성하게 됩니다.

결과적으로, `NATOPS` 임베딩과 `PEMS-SF` 임베딩은 서로 다른 의미를 가진 축으로 구성된, 완전히 다른 벡터 공간에 존재하게 됩니다. 이는 사과를 '색깔과 무게'로, 오렌지를 '당도와 산도'로 설명한 뒤 두 과일을 비교하려는 것과 같습니다. 기준이 달라 직접 비교할 수 없습니다.

### ⚙️ 해결 방안

일관성을 유지하고 모든 데이터셋의 임베딩을 동일한 조건에서 비교하기 위한 방법은 다음과 같습니다.

#### 1. (가장 이상적) 모든 데이터셋에 동일한 차원 축소 적용

가장 방법론적으로 올바른 접근입니다. 모든 임베딩을 동일한 차원의 벡터 공간에 두어 직접 비교가 가능하게 만듭니다.

1.  **모든 데이터셋을 불러옵니다.**
2.  **동일한 목표 차원(Target Dimension)을 설정합니다.** (예: `n_components=32`)
3.  **각 데이터셋에 PCA를 적용하여 목표 차원으로 축소합니다.**
4.  차원이 축소된 데이터들을 TimeKD 모델에 입력하여 임베딩을 추출합니다.

* **장점:** 모든 임베딩이 동일한 32차원 공간에 존재하므로, 군집화(Clustering)나 유사도 비교 같은 후속 작업에서 신뢰도가 높습니다.
* **단점:** `AtrialFibrillation`(2차원)처럼 원래 차원이 매우 낮은 데이터셋의 정보가 왜곡될 수 있습니다.

#### 2. (현실적) 모델을 분리하여 사용

VRAM 문제를 해결하면서 원본 데이터의 특성을 최대한 보존하는 방법입니다.

1.  **저차원 데이터셋:** `PEMS-SF`를 제외한 6개 데이터셋은 이전 계획대로 **TimeKD**를 사용하여 원본 데이터로부터 임베딩을 추출합니다.
2.  **고차원 데이터셋 (`PEMS-SF`):** VRAM 사용량이 `NUM_NODES`에 영향을 받지 않는 **채널 독립(Channel-Independent) 모델** (예: `PatchTST`)을 사용하여 임베딩을 추출합니다.

* **장점:** 모든 데이터셋에 대해 원본 데이터의 임베딩을 얻을 수 있습니다.
* **주의점:** 이 경우에도 TimeKD가 만든 임베딩과 PatchTST가 만든 임베딩은 서로 다른 모델 아키텍처에서 나왔기 때문에 **벡터 공간이 다릅니다.** 따라서 `PEMS-SF` 임베딩은 다른 데이터셋의 임베딩과 섞어서 분석하면 안 되고, **독립적으로 분석**해야 합니다.

### 결론

어떤 방법을 선택할지는 최종 목표에 따라 다릅니다.

* **모든 데이터셋의 임베딩을 한데 모아 비교/분석하고 싶다면** 👉 **해결 방안 1번**을 사용해야 합니다.
* **각 데이터셋별로 임베딩의 특성을 독립적으로 분석하고 싶다면** 👉 **해결 방안 2번**이 더 효율적입니다.
---
### Question)
```
모든 데이터셋에 동일한 차원 축소를 적용한다고 할 때,

2, 6 등 원본의 차원이 작은 경우도 있는데, 그러한 경우는 차원축소를 진행할 수 없지 않나?
```
### Answer)
네, 맞습니다. 아주 날카로운 지적이십니다.

말씀하신 대로, 원본 차원이 2나 6인 데이터셋에 32차원으로 PCA를 적용해 차원을 *늘리는* 것은 불가능합니다. PCA는 기존 N개의 차원을 조합하여 N개 (또는 그 이하)의 새로운 축을 찾는 기술이지, 없던 정보를 만들어 차원을 늘리는 기술이 아닙니다.

이전의 "1번 해결 방안"은 모든 데이터셋의 임베딩을 **'비교 가능한 동일한 공간'**에 두는 것이 목표였습니다. 이 목표를 달성하기 위한 더 정확한 방법은 다음과 같습니다.

### ⚙️ 수정된 해결 방안: PCA와 패딩(Padding)의 조합

VRAM이 감당 가능한 **'최대 목표 차원(Target Dimension)'**을 하나 정합니다. (예: `PEMS-SF`를 줄여야 하므로 `N=32`로 설정)

1.  **원본 차원 > 목표 차원 (예: `PEMS-SF`)**
    * `Original_Dim = 963`
    * PCA를 적용하여 **차원을 축소**합니다. (963 $\rightarrow$ 32)
    * TimeKD의 `NUM_NODES`는 32가 됩니다.

2.  **원본 차원 $\le$ 목표 차원 (예: `NATOPS`, `AtrialFibrillation`)**
    * `Original_Dim = 24`, `9`, `6`, `4`, `3`, `2`
    * PCA를 적용하지 않습니다.
    * 대신, 데이터의 빈 공간을 0으로 채우는 **패딩(Padding)**을 적용하여 **차원을 강제로 늘립니다.**
    * 예: `NATOPS`(N=24)는 8개의 0으로 채워진 열을 추가하여 `N=32`로 만듭니다.
    * 예: `AtrialFibrillation`(N=2)는 30개의 0으로 채워진 열을 추가하여 `N=32`로 만듭니다.
    * TimeKD의 `NUM_NODES`는 32가 됩니다.

### 📊 요약

| 데이터셋 | 원본 차원 (N) | 목표 차원 | 적용할 기법 | 최종 `NUM_NODES` |
| :--- | :--- | :--- | :--- | :--- |
| `PEMS-SF` | 963 | 32 | **PCA (축소)** | 32 |
| `NATOPS` | 24 | 32 | **Padding (확장)** | 32 |
| `ArticularyWord...` | 9 | 32 | **Padding (확장)** | 32 |
| `StandWalkJump` | 4 | 32 | **Padding (확장)** | 32 |
| `UWaveGesture...` | 3 | 32 | **Padding (확장)** | 32 |
| `AtrialFibrillation` | 2 | 32 | **Padding (확장)** | 32 |
| `PenDigits` | 2 | 32 | **Padding (확장)** | 32 |

### 결론

이 방식을 사용하면, **모든 데이터셋이 TimeKD 모델에 `NUM_NODES=32`라는 동일한 입력 차원**으로 들어가게 됩니다.

모델 아키텍처가 완전히 동일해지므로, 결과로 나오는 임베딩들은 **모두 동일한 차원의 벡터 공간**에 존재하게 되어 직접적인 비교와 분석이 가능해집니다.