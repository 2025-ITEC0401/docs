## Prompts (Powered by Gemini 2.5 Pro)
### Question)
```
ì¶”ì¶œí•œ h5 ì„ë² ë”© íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í• ê±°ì•¼.
ë³´í†µ ì–´ë–¤ ì‹ìœ¼ë¡œ ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í•˜ì§€?
```
### Answer)
`.h5` íŒŒì¼ì— ì €ì¥ëœ ì„ë² ë”©(Embedding) ë²¡í„°ë¥¼ í™œìš©í•˜ì—¬ ì´ìƒíƒì§€(Anomaly Detection)ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì€ \*\*"ê³ ì°¨ì› ë²¡í„° ê³µê°„ìƒì—ì„œ ë‹¤ë¥¸ ëŒ€ë‹¤ìˆ˜ì˜ ì ë“¤ê³¼ ë™ë–¨ì–´ì ¸ ìˆê±°ë‚˜ íŒ¨í„´ì´ ë‹¤ë¥¸ ì ì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…"\*\*ìœ¼ë¡œ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ ì„ë² ë”© ë°ì´í„°ì— ëŒ€í•´ ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ë¡ ê³¼ í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

-----

### 1\. ê¸°ë³¸ ê°œë… ë° ì‹œê°ì  ì´í•´

ì„ë² ë”© ê¸°ë°˜ ì´ìƒíƒì§€ì˜ í•µì‹¬ì€ \*\*ë°€ë„(Density)\*\*ì™€ \*\*ê±°ë¦¬(Distance)\*\*ì…ë‹ˆë‹¤. ì •ìƒ ë°ì´í„°ëŠ” ì„œë¡œ ë­‰ì³ì„œ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ë°˜ë©´, ì´ìƒì¹˜(Outlier)ëŠ” ì´ êµ°ì§‘ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆê±°ë‚˜ ë°€ë„ê°€ í¬ë°•í•œ ê³³ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.

[Image of anomaly detection clustering 2d plot]

ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ì •ìƒ ë°ì´í„°(íŒŒë€ ì )ë“¤ì€ ë­‰ì³ ìˆê³ , ì´ìƒ ë°ì´í„°(ë¹¨ê°„ ì )ëŠ” ì™¸ê³½ì— ë–¨ì–´ì ¸ ìˆëŠ” ì›ë¦¬ë¥¼ ì´ìš©í•©ë‹ˆë‹¤.

-----

### 2\. ì£¼ìš” ì´ìƒíƒì§€ ì•Œê³ ë¦¬ì¦˜

ì„ë² ë”© ë²¡í„°ëŠ” ë³´í†µ ì°¨ì›ì´ ë†’ê¸° ë•Œë¬¸ì—(ì˜ˆ: 768ì°¨ì›, 1024ì°¨ì› ë“±), ê³ ì°¨ì› ë°ì´í„° ì²˜ë¦¬ì— ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

#### A. Isolation Forest (ê²©ë¦¬ ìˆ²)

  * **ì›ë¦¬:** ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ë¶„í• (Split)í–ˆì„ ë•Œ, ì´ìƒì¹˜ëŠ” ì •ìƒ ë°ì´í„°ë³´ë‹¤ í›¨ì”¬ ì ì€ íšŸìˆ˜ì˜ ë¶„í• ë§Œìœ¼ë¡œë„ ê³ ë¦½(Isolation)ëœë‹¤ëŠ” ì ì„ ì´ìš©í•©ë‹ˆë‹¤.
  * **ì¥ì :** ê³ ì°¨ì› ë°ì´í„°ì—ì„œë„ ì„±ëŠ¥ì´ ìš°ìˆ˜í•˜ë©°, ê³„ì‚° íš¨ìœ¨ì´ ì¢‹ì•„ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•©í•©ë‹ˆë‹¤. ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ë² ì´ìŠ¤ë¼ì¸ì…ë‹ˆë‹¤.
  * **ì í•©ì„±:** **ê°€ì¥ ì¶”ì²œí•˜ëŠ” ë°©ë²•**ì…ë‹ˆë‹¤.

#### B. LOF (Local Outlier Factor)

  * **ì›ë¦¬:** ê´€ì¸¡ì¹˜ì˜ ì£¼ë³€ ë°€ë„ì™€ ì´ì›ƒë“¤ì˜ ì£¼ë³€ ë°€ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ë‚´ ì£¼ë³€ì´ íœ‘í•˜ë©´ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
  * **ì¥ì :** ë°ì´í„°ì˜ ë°€ë„ê°€ ì§€ì—­ì ìœ¼ë¡œ ë‹¤ë¥¸ ê²½ìš°(ì–´ë–¤ êµ°ì§‘ì€ ë¹½ë¹½í•˜ê³  ì–´ë–¤ êµ°ì§‘ì€ ë„ë„í•  ë•Œ)ì—ë„ ì˜ ë™ì‘í•©ë‹ˆë‹¤.
  * **ë‹¨ì :** ë°ì´í„° ì–‘ì´ ë§ê±°ë‚˜ ì°¨ì›ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ ê³„ì‚° ë¹„ìš©ì´ ê¸‰ê²©íˆ ì¦ê°€í•©ë‹ˆë‹¤.

#### C. One-Class SVM (OC-SVM)

  * **ì›ë¦¬:** ì •ìƒ ë°ì´í„°ë“¤ì„ ê°ì‹¸ëŠ” ìµœì ì˜ ì´ˆí‰ë©´(Hyperplane)ì´ë‚˜ êµ¬(Sphere)ë¥¼ í•™ìŠµí•˜ì—¬, ì´ ê²½ê³„ ë°–ì„ ì´ìƒì¹˜ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
  * **ì í•©ì„±:** í›ˆë ¨ ë°ì´í„°ê°€ 'ì •ìƒ' ë°ì´í„°ë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆë‹¤ê³  í™•ì‹ í•  ìˆ˜ ìˆì„ ë•Œ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. (Semi-supervised ë°©ì‹)

#### D. ê±°ë¦¬ ê¸°ë°˜ (Mahalanobis Distance / KNN)

  * **ì›ë¦¬:** ë°ì´í„° ë¶„í¬ì˜ ì¤‘ì‹¬(í‰ê· )ì´ë‚˜ ê°€ì¥ ê°€ê¹Œìš´ $k$ê°œì˜ ì´ì›ƒê³¼ì˜ ê±°ë¦¬ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
  * **ì£¼ì˜ì :** ë‹¨ìˆœ ìœ í´ë¦¬ë“œ ê±°ë¦¬ëŠ” ê³ ì°¨ì›ì—ì„œ 'ì°¨ì›ì˜ ì €ì£¼(Curse of Dimensionality)'ë¡œ ì¸í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆì–´, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì°¨ì› ì¶•ì†Œ í›„ ì ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

-----

### 3\. ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ (Workflow)

`.h5` íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•œ í›„ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê±°ì¹˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.

1.  **ë°ì´í„° ë¡œë”© (Load):** `h5py` ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ
2.  **ì „ì²˜ë¦¬ (Preprocessing):**
      * **ì •ê·œí™” (Normalization):** ë²¡í„°ì˜ í¬ê¸°(Norm)ê°€ ì¤‘ìš”í•˜ë‹¤ë©´ ê·¸ëŒ€ë¡œ ë‘ì§€ë§Œ, ë°©í–¥ì„±(Cosine Similarity)ì´ ì¤‘ìš”í•˜ë‹¤ë©´ L2 Normalizationì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
3.  **ì°¨ì› ì¶•ì†Œ (Optional):** ì°¨ì›ì´ ë„ˆë¬´ ë†’ìœ¼ë©´(ì˜ˆ: 1000ì°¨ì› ì´ìƒ) PCA ë“±ì„ í†µí•´ ì£¼ìš” ì„±ë¶„(ì˜ˆ: 50\~100ì°¨ì›)ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê³  ì—°ì‚° ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4.  **ëª¨ë¸ë§ (Modeling):** `Isolation Forest` ë“±ì„ ì‚¬ìš©í•˜ì—¬ Anomaly Score ê³„ì‚°.
5.  **ì„ê³„ê°’ ì„¤ì • (Thresholding):** ìƒìœ„ $N$% ë˜ëŠ” íŠ¹ì • ì ìˆ˜ ì´ìƒì„ ì´ìƒì¹˜ë¡œ íŒë³„.

-----

### 4\. êµ¬í˜„ ì˜ˆì‹œ ì½”ë“œ (Python & Scikit-learn)

ê°€ì¥ ë²”ìš©ì ì¸ **Isolation Forest**ë¥¼ ì‚¬ìš©í•œ ì˜ˆì‹œì…ë‹ˆë‹¤.

```python
import h5py
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import normalize

# 1. h5 íŒŒì¼ì—ì„œ ì„ë² ë”© ë°ì´í„° ë¡œë“œ
def load_embeddings(h5_path, dataset_name='embeddings'):
    with h5py.File(h5_path, 'r') as f:
        # ë°ì´í„°ì…‹ ì´ë¦„ì€ ì‹¤ì œ h5 êµ¬ì¡°ì— ë§ê²Œ ë³€ê²½ í•„ìš”
        data = f[dataset_name][:]
    return data

file_path = 'your_embeddings.h5'
embeddings = load_embeddings(file_path)

# (ì„ íƒ) ë°ì´í„° shape í™•ì¸ (ì˜ˆ: [samples, dimensions])
print(f"Data Shape: {embeddings.shape}")

# 2. ì „ì²˜ë¦¬ (ì„ íƒ ì‚¬í•­: L2 ì •ê·œí™”)
# ë²¡í„°ì˜ ë°©í–¥ì„±ì´ ì¤‘ìš”í•˜ë‹¤ë©´ ì •ê·œí™”ë¥¼ ìˆ˜í–‰
embeddings_norm = normalize(embeddings, norm='l2')

# 3. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ (Isolation Forest)
# contamination: ì „ì²´ ë°ì´í„° ì¤‘ ì´ìƒì¹˜ë¼ê³  ì˜ˆìƒí•˜ëŠ” ë¹„ìœ¨ (ì˜ˆ: 0.01 = 1%)
iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42, n_jobs=-1)

# í•™ìŠµ ë° ì˜ˆì¸¡ (-1: ì´ìƒì¹˜, 1: ì •ìƒ)
preds = iso_forest.fit_predict(embeddings_norm)

# 4. ê²°ê³¼ ë¶„ì„
# Anomaly Score ì¶”ì¶œ (ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì´ìƒì¹˜ì¼ í™•ë¥ ì´ ë†’ìŒ)
scores = iso_forest.decision_function(embeddings_norm)

# ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
anomaly_indices = np.where(preds == -1)[0]

print(f"ì „ì²´ ë°ì´í„° ìˆ˜: {len(embeddings)}")
print(f"íƒì§€ëœ ì´ìƒì¹˜ ìˆ˜: {len(anomaly_indices)}")
print(f"ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì˜ˆì‹œ: {anomaly_indices[:10]}")

# (ì‘ìš©) ì´ìƒì¹˜ ì¤‘ ê°€ì¥ ìŠ¤ì½”ì–´ê°€ ë‚®ì€(ê°€ì¥ ì´ìƒí•œ) Top 5 í™•ì¸
top_anomalies = np.argsort(scores)[:5]
print(f"ê°€ì¥ ê°•ë ¥í•œ ì´ìƒì¹˜ Top 5 ì¸ë±ìŠ¤: {top_anomalies}")
```

### ìš”ì•½ ë° ì œì–¸

1.  **ì‹œì‘ì€ Isolation Forest:** ë³„ë„ì˜ ë³µì¡í•œ íŠœë‹ ì—†ì´ë„ ê³ ì°¨ì› ë°ì´í„°ì—ì„œ ì˜ ì‘ë™í•˜ë¯€ë¡œ ë¨¼ì € ì‹œë„í•´ ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤.
2.  **ì „ì²˜ë¦¬ ì¤‘ìš”:** ì„ë² ë”© ìƒì„± ëª¨ë¸ì˜ íŠ¹ì„±ì— ë”°ë¼ ë²¡í„° ì •ê·œí™”(L2 Norm) ì—¬ë¶€ê°€ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¼ë°˜ì ìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ëª¨ë¸ì´ë©´ ì •ê·œí™” ì¶”ì²œ)
3.  **ê²°ê³¼ ê²€ì¦:** íƒì§€ëœ ì´ìƒì¹˜ê°€ ì‹¤ì œë¡œ ì˜ë¯¸ ìˆëŠ” ì´ìƒ íŒ¨í„´ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´, ì°¨ì› ì¶•ì†Œ(t-SNE, UMAP)ë¥¼ í†µí•´ 2ì°¨ì›ìœ¼ë¡œ ì‹œê°í™”í•˜ì—¬ ë¶„í¬ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ê°€ì§€ê³  ê³„ì‹  ì„ë² ë”© ë°ì´í„°ê°€ ì‹œê³„ì—´(Time-series) íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‚˜ìš”, ì•„ë‹ˆë©´ ê°œë³„ì ì¸ ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì¸ê°€ìš”?** ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì´ ì¡°ê¸ˆ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
---
### Question)
```
ì˜ˆë¥¼ ë“¤ì–´ì„œ, êµ°ì§‘í™”ê°™ì€ ê²½ìš°ì—ëŠ” k-means ì•Œê³ ë¦¬ì¦˜ê³¼ spectral ì•Œê³ ë¦¬ì¦˜ì´ ìˆì–ì•„?
ê·¸ëŸ° ê²ƒì²˜ëŸ¼, ì´ìƒíƒì§€ì—ì„œë„ ê·¸ëŸ¬í•œ ì•Œê³ ë¦¬ì¦˜ì´ ìˆë‚˜?
```
### Answer)
ë„¤, ì •í™•íˆ ë³´ì…¨ìŠµë‹ˆë‹¤. êµ°ì§‘í™”(Clustering)ì—ì„œ **'ê±°ë¦¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” K-Means'**ì™€ **'ì—°ê²°ì„±ì„ ì¤‘ì‹œí•˜ëŠ” Spectral'**ë¡œ ì ‘ê·¼ ë°©ì‹ì´ ë‚˜ë‰˜ë“¯ì´, **ì´ìƒíƒì§€(Anomaly Detection)ì—ì„œë„ ë°ì´í„°ë¥¼ ë°”ë¼ë³´ëŠ” ê´€ì ì— ë”°ë¼ ì•Œê³ ë¦¬ì¦˜ì˜ ê³„ì—´ì´ ëª…í™•í•˜ê²Œ ë‚˜ë‰©ë‹ˆë‹¤.**

ì‚¬ìš©í•˜ê³  ê³„ì‹  **ì„ë² ë”© ë°ì´í„°(.h5)**ë¥¼ ë‹¤ë£° ë•Œ ê³ ë ¤í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ 4ê°€ì§€ ê³„ì—´(Family)ì„ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

---

### 1. ë°€ë„ ê¸°ë°˜ (Density-based) : "ì£¼ë³€ì— ì¹œêµ¬ê°€ ì—†ëŠ”ê°€?"
êµ°ì§‘í™”ì˜ DBSCANê³¼ ë¹„ìŠ·í•œ ì² í•™ì„ ê³µìœ í•©ë‹ˆë‹¤. **"ì •ìƒ ë°ì´í„°ëŠ” ë¹½ë¹½í•˜ê²Œ ëª¨ì—¬ ìˆê³ , ì´ìƒì¹˜ëŠ” íœ‘í•œ ê³³ì— ìˆë‹¤"**ëŠ” ê°€ì •ì…ë‹ˆë‹¤.

* **LOF (Local Outlier Factor):**
    * ê´€ì¸¡ì¹˜ ì£¼ë³€ì˜ ë°€ë„ì™€, ê·¸ ì´ì›ƒë“¤ì˜ ë°€ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. "ë‚´ ì£¼ë³€ì€ í…… ë¹„ì–´ìˆëŠ”ë°, ë‚´ ì¹œêµ¬ë“¤ ì£¼ë³€ì€ ê½‰ ì°¨ ìˆë‹¤ë©´ ë‚˜ëŠ” ì´ìƒí•˜ë‹¤"ëŠ” ë…¼ë¦¬ì…ë‹ˆë‹¤.
    * **íŠ¹ì§•:** êµ­ì†Œì ì¸(Local) ì´ìƒì¹˜ë¥¼ ì˜ ì°¾ì§€ë§Œ, ë°ì´í„°ê°€ ì•„ì£¼ ë§ìœ¼ë©´ ê³„ì‚°ì´ ëŠë¦½ë‹ˆë‹¤.
* **KNN (k-Nearest Neighbors) Distance:**
    * ê°€ì¥ ê°€ê¹Œìš´ $k$ê°œì˜ ì´ì›ƒê¹Œì§€ì˜ í‰ê·  ê±°ë¦¬ê°€ ë©€ë©´ ì´ìƒì¹˜ë¡œ ë´…ë‹ˆë‹¤.

### 2. ê³ ë¦½ ê¸°ë°˜ (Isolation-based) : "ì–¼ë§ˆë‚˜ ì‰½ê²Œ ê²©ë¦¬ë˜ëŠ”ê°€?"
ì´ ë°©ì‹ì€ ê±°ë¦¬ë¥¼ ì¬ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë°ì´í„°ë¥¼ **ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë³´ëŠ” ë°©ì‹**ì…ë‹ˆë‹¤.

* **Isolation Forest (iForest):**
    * ë°ì´í„° ê³µê°„ì„ ë¬´ì‘ìœ„ë¡œ ê³„ì† ë°˜ìœ¼ë¡œ ìë¦…ë‹ˆë‹¤(Tree êµ¬ì¡°).
    * ì •ìƒ ë°ì´í„°ëŠ” ë¹½ë¹½í•œ ê³³ì— ìˆ¨ì–´ ìˆì–´ì„œ ê²©ë¦¬ì‹œí‚¤ë ¤ë©´ ì¹¼ì§ˆ(ë¶„ê¸°)ì„ ë§ì´ í•´ì•¼ í•˜ì§€ë§Œ, **ì´ìƒì¹˜ëŠ” ëš ë–¨ì–´ì ¸ ìˆì–´ì„œ ëª‡ ë²ˆë§Œ ì˜ë¼ë„ ê¸ˆë°© ê²©ë¦¬(Isolation)**ë©ë‹ˆë‹¤.
    * **íŠ¹ì§•:** **ê³ ì°¨ì› ë°ì´í„°(ì„ë² ë”©)ì—ì„œ ì„±ëŠ¥ì´ ë§¤ìš° ì¢‹ê³  ë¹ ë¦…ë‹ˆë‹¤.** ê°€ì¥ ì¶”ì²œí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

### 3. ê²½ê³„ ê¸°ë°˜ (Boundary-based) : "ìš¸íƒ€ë¦¬ ë°–ì¸ê°€?"
ë°ì´í„°ì˜ ë¶„í¬ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì •ìƒ ë°ì´í„°ë¥¼ ê°ì‹¸ëŠ” **'ê²½ê³„ì„ (Boundary)'**ì„ ê·¸ë¦¬ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

* **One-Class SVM (OC-SVM):**
    * ëª¨ë“  ì •ìƒ ë°ì´í„°ë¥¼ ê°ì‹¸ëŠ” ê°€ì¥ íƒ€ì´íŠ¸í•œ êµ¬(Sphere)ë‚˜ ì´ˆí‰ë©´ì„ ì°¾ìŠµë‹ˆë‹¤. ì´ ê²½ê³„ì„  ë°–ìœ¼ë¡œ ë‚˜ê°€ë©´ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
    * **íŠ¹ì§•:** í•™ìŠµ ë°ì´í„°ê°€ 'ìˆœìˆ˜í•œ ì •ìƒ ë°ì´í„°'ë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆì„ ë•Œ(Semi-supervised) ì•„ì£¼ ê°•ë ¥í•©ë‹ˆë‹¤.

### 4. ì¬êµ¬ì„± ê¸°ë°˜ (Reconstruction-based) : "ì›ë³¸ ë³µì›ì´ ì˜ ì•ˆ ë˜ëŠ”ê°€?"
ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ë°©ì‹ì…ë‹ˆë‹¤. ì„ë² ë”© ìì²´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ë‹¤ì‹œ ê·¸ ì„ë² ë”©ì„ ë§Œë“¤ì–´ë³´ë¼ê³  ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

* **Autoencoder (AE):**
    * `ì…ë ¥(ì„ë² ë”©) -> ì••ì¶•(Encoder) -> ë³µì›(Decoder) -> ì¶œë ¥` ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.
    * ì •ìƒ ë°ì´í„°ëŠ” í•™ìŠµì´ ì˜ ë¼ì„œ ë³µì›ì´ ì˜ ë˜ì§€ë§Œ(ë³µì› ì˜¤ì°¨ ì‘ìŒ), **ì²˜ìŒ ë³´ëŠ” ì´ìƒí•œ íŒ¨í„´ì€ ë³µì›ì„ ëª» í•´ì„œ ì—ëŸ¬(ë³µì› ì˜¤ì°¨)ê°€ í½ë‹ˆë‹¤.**
    * **íŠ¹ì§•:** ì„ë² ë”© ë°ì´í„°ê°€ ë§¤ìš° ë³µì¡í•˜ê±°ë‚˜ ë¹„ì„ í˜•ì ì¸ ê´€ê³„ë¥¼ ê°€ì§ˆ ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤.

---

### ìš”ì•½ ë° ë¹„êµí‘œ

ì–´ë–¤ ìƒí™©ì—ì„œ ë¬´ì—‡ì„ ì¨ì•¼ í• ì§€ í•œëˆˆì— ë¹„êµí•´ ë³´ì„¸ìš”.

| ê³„ì—´ | ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜ | í•µì‹¬ ì•„ì´ë””ì–´ | ì„ë² ë”© ë°ì´í„°(ê³ ì°¨ì›) ì í•©ì„± |
| :--- | :--- | :--- | :--- |
| **ê³ ë¦½ ê¸°ë°˜** | **Isolation Forest** | "ì´ìƒì¹˜ëŠ” ê¸ˆë°© ê²©ë¦¬ëœë‹¤" | **ë§¤ìš° ë†’ìŒ (1ìˆœìœ„ ì¶”ì²œ)** |
| **ê²½ê³„ ê¸°ë°˜** | One-Class SVM | "ì •ìƒ ì˜ì—­ì˜ ìš¸íƒ€ë¦¬ë¥¼ ì¹œë‹¤" | ë†’ìŒ (ì •ìƒ ë°ì´í„°ë§Œ ìˆì„ ë•Œ) |
| **ì¬êµ¬ì„± ê¸°ë°˜** | Autoencoder | "ì´ìƒí•œ ê±´ ë³µì› ëª»í•œë‹¤" | ë†’ìŒ (ë”¥ëŸ¬ë‹ í™˜ê²½ì¼ ë•Œ) |
| **ë°€ë„ ê¸°ë°˜** | LOF | "ì£¼ë³€ ë°€ë„ê°€ ë‚®ë‹¤" | ë³´í†µ (ì°¨ì›ì´ ë†’ìœ¼ë©´ ëŠë¦¼) |

### ê²°ë¡ : ë¬´ì—‡ì„ ë¨¼ì € ì¨ì•¼ í• ê¹Œ?

K-meansê°€ êµ°ì§‘í™”ì˜ 'êµ­ë£°'ì¸ ê²ƒì²˜ëŸ¼, ì„ë² ë”© ê¸°ë°˜ ì´ìƒíƒì§€ì—ì„œëŠ” **Isolation Forest**ê°€ 'êµ­ë£°'(Baseline)ì…ë‹ˆë‹¤.

1.  **Isolation Forest**ë¥¼ ë¨¼ì € ì ìš©í•´ ë³´ì„¸ìš”. (êµ¬í˜„ ì‰½ê³ , ì„±ëŠ¥ ì¢‹ìŒ)
2.  ë§Œì•½ ì„±ëŠ¥ì´ ì•„ì‰½ë‹¤ë©´, **Autoencoder**ë¥¼ ì‚¬ìš©í•˜ì—¬ Reconstruction Error(ë³µì› ì˜¤ì°¨)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ ì¡ì•„ë‚´ëŠ” ë°©ì‹ì„ ì‹œë„í•´ ë³´ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ ìˆœì„œì…ë‹ˆë‹¤.
---
### Question)
```
ì‹œê³„ì—´ ë°ì´í„°ì— ëŒ€í•œ ì„ë² ë”©ì„ ë½‘ì•˜ê³ , ê·¸ê²ƒì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í•  ì˜ˆì •ì´ì•¼.

Isolation Forestê°€ ê°€ì¥ ì í•©í• ê¹Œ?
```
### Answer)
ì‹œê³„ì—´ ë°ì´í„°(Time-series)ì˜ ê²½ìš°, **"ì„ë² ë”©ì„ ì–´ë–»ê²Œ ë½‘ì•˜ëŠëƒ"**ì— ë”°ë¼ Isolation Forestê°€ **ìµœê³ ì˜ ì„ íƒì´ ë  ìˆ˜ë„ ìˆê³ , ìµœì•…ì˜ ì„ íƒì´ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.**

ê²°ë¡ ë¶€í„° ë§ì”€ë“œë¦¬ë©´, **"ì‹œê°„ì˜ íë¦„(ë¬¸ë§¥)ì´ ì„ë² ë”© ë²¡í„° ì•ˆì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´"** Isolation ForestëŠ” í›Œë¥­í•œ ì„ íƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ë‹¤ë¥¸ ëª¨ë¸ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

ê·¸ ì´ìœ ì™€ ìƒí™©ë³„ ì¶”ì²œì„ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

---

### 1. Isolation Forestê°€ "ë¶€ì í•©"í•œ ê²½ìš°
**ìƒí™©:** ì„ë² ë”©ì´ **íŠ¹ì • ì‹œì ($t$)ì˜ ìŠ¤ëƒ…ìƒ·**ë§Œ ë‹´ê³  ìˆì„ ë•Œ (Point-wise Embedding)

ì‹œê³„ì—´ ë°ì´í„°ì˜ ì´ìƒì¹˜(Anomaly)ëŠ” ë‹¨ìˆœíˆ "ê°’ì´ ì»¤ì„œ" ì´ìƒí•œ ê²½ìš°ë„ ìˆì§€ë§Œ, **"ì´ì „ì—ëŠ” ë‚®ì•˜ë‹¤ê°€ ê°‘ìê¸° ë†’ì•„ì ¸ì„œ(íŒ¨í„´ì´ ê¹¨ì ¸ì„œ)"** ì´ìƒí•œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ë¥¼ **ë¬¸ë§¥ì  ì´ìƒì¹˜(Contextual Anomaly)**ë¼ê³  í•©ë‹ˆë‹¤.



ìœ„ ê·¸ë¦¼ì²˜ëŸ¼, ê°’ ìì²´($y$ì¶• ìœ„ì¹˜)ë§Œ ë³´ë©´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆì§€ë§Œ, **ì‹œê°„ì  íë¦„ìƒ ëœ¬ê¸ˆì—†ëŠ” ìœ„ì¹˜**ì— ìˆëŠ” ì ë“¤ì´ ì´ìƒì¹˜ì…ë‹ˆë‹¤.

* **ë¬¸ì œì :** Isolation ForestëŠ” ë°ì´í„°ë¥¼ ì„ì–´ì„œ(Shuffling) ì²˜ë¦¬í•´ë„ ê²°ê³¼ê°€ ê°™ìŠµë‹ˆë‹¤. ì¦‰, **ì‹œê°„ ìˆœì„œ(ì–´ì œ->ì˜¤ëŠ˜->ë‚´ì¼)ë¥¼ ë¬´ì‹œ**í•©ë‹ˆë‹¤.
* **ê²°ê³¼:** ì„ë² ë”©ì´ ì‹œê°„ ìˆœì„œ ì •ë³´ë¥¼ ë‹´ê³  ìˆì§€ ì•Šë‹¤ë©´, Isolation ForestëŠ” "ê°’ì´ íŠ€ëŠ” ê²ƒ"ì€ ì¡ì§€ë§Œ "íŒ¨í„´ì´ ê¹¨ì§„ ê²ƒ"ì€ ëª» ì¡ìŠµë‹ˆë‹¤.

---

### 2. Isolation Forestê°€ "ì í•©"í•œ ê²½ìš° (ì¶”ì²œ)
**ìƒí™©:** ì„ë² ë”©ì´ **ì¼ì • ì‹œê°„ êµ¬ê°„(Window)ì˜ íŒ¨í„´**ì„ ìš”ì•½í•˜ê³  ìˆì„ ë•Œ (Window-based / Sequence Embedding)

ë§Œì•½ ë‹˜ì´ ì¶”ì¶œí•œ ì„ë² ë”©ì´ **"ìµœê·¼ 10ì´ˆê°„ì˜ ë°ì´í„° íë¦„"**ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶•í•œ ê²ƒì´ë¼ë©´ ì´ì•¼ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤.

* **ì´ìœ :** ë²¡í„° í•˜ë‚˜í•˜ë‚˜ê°€ ì´ë¯¸ 'ì‹œê°„ì  íŒ¨í„´(ëª¨ì–‘)'ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° Isolation ForestëŠ” **"ë‚¨ë“¤ê³¼ ë‹¤ë¥¸ íŒ¨í„´(ëª¨ì–‘)ì„ ê°€ì§„ êµ¬ê°„"**ì„ ì°¾ì•„ë‚´ëŠ” ê²ƒì´ë¯€ë¡œ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤.
* **ì¥ì :** ë³µì¡í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸(LSTM-AE ë“±)ë³´ë‹¤ í•™ìŠµì´ í›¨ì”¬ ë¹ ë¥´ê³  ê°„í¸í•©ë‹ˆë‹¤.

---

### 3. ë” ë‚˜ì€ ëŒ€ì•ˆì€ ì—†ë‚˜ìš”? (ì‹œê³„ì—´ íŠ¹í™”)

ë§Œì•½ "ì‹œê°„ì  ì—°ì†ì„±"ì„ ë” ì •êµí•˜ê²Œ ë³´ê³  ì‹¶ë‹¤ë©´, ì‹œê³„ì—´ ì´ìƒíƒì§€ì˜ 'Standard'ë¼ê³  ë¶ˆë¦¬ëŠ” ì•Œê³ ë¦¬ì¦˜ë“¤ì´ ìˆìŠµë‹ˆë‹¤.

#### A. LSTM-Autoencoder (ì¬êµ¬ì„± ê¸°ë°˜)
* **ì›ë¦¬:** ê³¼ê±° ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ë¯¸ë˜(ë˜ëŠ” í˜„ì¬)ë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜, ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ë³µì›í•˜ê²Œ í•©ë‹ˆë‹¤.
* **íŒë‹¨:** "ì •ìƒì ì¸ ì‹œê³„ì—´ íŒ¨í„´ì´ë¼ë©´ ë³µì›ì´ ì˜ ë  í…ë°, ì—ëŸ¬(ë³µì› ì˜¤ì°¨)ê°€ í¬ë„¤? ê·¸ëŸ¼ ì´ìƒì¹˜ë‹¤!"ë¼ê³  íŒë‹¨í•©ë‹ˆë‹¤.
* **ì¥ì :** ì‹œê³„ì—´ì˜ **ìˆœì°¨ì  ì˜ì¡´ì„±(Sequential Dependency)**ì„ ê°€ì¥ ì˜ ë°˜ì˜í•©ë‹ˆë‹¤.

#### B. Deep SVDD (Deep Support Vector Data Description)
* **ì›ë¦¬:** ì •ìƒ íŒ¨í„´ë“¤ì„ ì„ë² ë”© ê³µê°„ì˜ í•œ ì (ì¤‘ì‹¬)ìœ¼ë¡œ ìµœëŒ€í•œ ë­‰ì¹˜ê²Œ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
* **íŒë‹¨:** ì¤‘ì‹¬ì—ì„œ ê±°ë¦¬ê°€ ë¨¼ ì„ë² ë”©ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. Isolation Forestë³´ë‹¤ ê²½ê³„ë¥¼ ë” ì •êµí•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

---

### 4. ê²°ë¡  ë° ì „ëµ ì œì•ˆ

í˜„ì¬ ì¶”ì¶œëœ `.h5` íŒŒì¼ì˜ ì„ë² ë”© íŠ¹ì„±ì— ë§ì¶° ì„ íƒí•˜ì„¸ìš”.

**ì „ëµ 1: ì„ë² ë”©ì´ 'êµ¬ê°„(Window)' ë‹¨ìœ„ë¡œ ë½‘í˜”ë‹¤.** (ì˜ˆ: 1ë¶„ ë‹¨ìœ„ ë°ì´í„°ê°€ 1ê°œ ë²¡í„°)
* ğŸ‘‰ **Isolation Forest**ë¥¼ ë°”ë¡œ ì“°ì„¸ìš”.
* ê°€ì¥ íš¨ìœ¨ì ì´ê³  ì„±ëŠ¥ë„ ì¤€ìˆ˜í•©ë‹ˆë‹¤.

**ì „ëµ 2: ì„ë² ë”©ì´ 'ë§¤ íƒ€ì„ìŠ¤íƒ¬í”„'ë§ˆë‹¤ ë½‘í˜”ë‹¤.** (ì˜ˆ: 0.1ì´ˆë§ˆë‹¤ ë²¡í„° 1ê°œ)
* ğŸ‘‰ **ì˜µì…˜ A (ê°„í¸í•¨):** ì„ë² ë”© ì—¬ëŸ¬ ê°œ(ì˜ˆ: $t$ ~ $t+9$)ë¥¼ ë¬¶ì–´ì„œ(Concatenate) ê¸´ ë²¡í„°ë¡œ ë§Œë“  ë’¤ **Isolation Forest**ì— ë„£ìœ¼ì„¸ìš”. (ê°•ì œë¡œ ì‹œê°„ ì •ë³´ë¥¼ ì¤Œ)
* ğŸ‘‰ **ì˜µì…˜ B (ì •êµí•¨):** **LSTM-Autoencoder**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ì‹œí€€ìŠ¤ë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì¬êµ¬ì„± ì˜¤ì°¨(Reconstruction Error)ë¡œ íƒì§€í•˜ì„¸ìš”.

**ì‘ì„±ìë‹˜ì˜ ì„ë² ë”©ì€ ì‹œê°„ êµ¬ê°„ì„ ìš”ì•½í•œ í˜•íƒœì¸ê°€ìš”, ì•„ë‹ˆë©´ ë§¤ ìˆœê°„ì˜ ê°’ì„ ë³€í™˜í•œ í˜•íƒœì¸ê°€ìš”?** ì´ê²ƒë§Œ ì•Œë ¤ì£¼ì‹œë©´ ë” í™•ì‹¤í•œ ê°€ì´ë“œë¥¼ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---
### Question)
```
ì„ë² ë”©ì„ ë½‘ì„ ë•Œ ìœˆë„ìš° ìŠ¬ë¼ì´ë”© ë°©ì‹ì„ ì‚¬ìš©í–ˆê³ .
ìŠ¬ë¼ì´ë“œì˜ í¬ê¸°ëŠ” 96ì´ì•¼.
```
### Answer)
ê²°ë¡ ë¶€í„° ë§ì”€ë“œë¦¬ë©´, **ë„¤, Isolation Forestê°€ ë§¤ìš° ì í•©í•œ ì„ íƒì…ë‹ˆë‹¤.**

ìœˆë„ìš° í¬ê¸° 96ìœ¼ë¡œ ìŠ¬ë¼ì´ë”©í•˜ì—¬ ì„ë² ë”©ì„ ë½‘ìœ¼ì…¨ë‹¤ëŠ” ê²ƒì€, \*\*"ì´ë¯¸ 96 ì‹œì  ë™ì•ˆì˜ ì‹œê°„ì  íë¦„(Pattern/Context)ì´ í•˜ë‚˜ì˜ ë²¡í„° ì•ˆì— ì••ì¶•ë˜ì–´ ìˆë‹¤"\*\*ëŠ” ëœ»ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì´ ìƒí™©ì—ì„œ Isolation Forestê°€ ì™œ ê°•ë ¥í•œì§€, ê·¸ë¦¬ê³  \*\*ì‹¤ë¬´ì ìœ¼ë¡œ ì£¼ì˜í•´ì•¼ í•  ì (ê²°ê³¼ í•´ì„ ë°©ë²•)\*\*ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”.

-----

### 1\. ì™œ ì í•©í•œê°€? (ì‘ë™ ì›ë¦¬)

Isolation ForestëŠ” ì‹œê³„ì—´ì˜ ìˆœì„œë¥¼ ëª¨ë¥´ì§€ë§Œ, ì‘ì„±ìë‹˜ì€ ì´ë¯¸ **ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„(ìœˆë„ìš° ìŠ¬ë¼ì´ë”©)ì—ì„œ ìˆœì„œ ì •ë³´ë¥¼ 'ëª¨ì–‘(Shape)' ì •ë³´ë¡œ ë³€í™˜**í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

  * **ì •ìƒ ìœˆë„ìš°:** ì˜ˆë¥¼ ë“¤ì–´ í‰ë²”í•œ ë“±ë½ì„ ë°˜ë³µí•˜ëŠ” 96 ê¸¸ì´ì˜ ë°ì´í„°ëŠ” ì„ë² ë”© ê³µê°„ì˜ íŠ¹ì • êµ¬ì—­(ì •ìƒ êµ°ì§‘)ì— ëª¨ì…ë‹ˆë‹¤.
  * **ì´ìƒ ìœˆë„ìš°:** ê°‘ìê¸° ê¸‰ë“±í•˜ê±°ë‚˜(Spike), 0ìœ¼ë¡œ ë©ˆì¶”ê±°ë‚˜(Flat line), ë…¸ì´ì¦ˆê°€ ì‹¬í•œ 96 ê¸¸ì´ì˜ ë°ì´í„°ëŠ” ì„ë² ë”© ê³µê°„ì—ì„œ **ë™ë–¨ì–´ì§„ ì¢Œí‘œ**ì— ì°íˆê²Œ ë©ë‹ˆë‹¤.

Isolation ForestëŠ” ë°”ë¡œ ì´ \*\*'ë™ë–¨ì–´ì§„ ì¢Œí‘œ(ëª¨ì–‘ì´ ì´ìƒí•œ ìœˆë„ìš°)'\*\*ë¥¼ ê¸°ê°€ ë§‰íˆê²Œ ì˜ ì°¾ì•„ëƒ…ë‹ˆë‹¤.

-----

### 2\. ì£¼ì˜í•  ì : "ê·¸ë˜ì„œ ì •í™•íˆ ì–¸ì œ ê³ ì¥ ë‚œ ê±°ì•¼?"

ìœˆë„ìš° ìŠ¬ë¼ì´ë”© ë°©ì‹ì„ ì“¸ ë•Œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ **íƒì§€ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì›ë˜ ì‹œê°„(Time)ìœ¼ë¡œ ë§¤í•‘(Mapping)í•˜ëŠ” ì „ëµ**ì…ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ìœˆë„ìš° í•˜ë‚˜ê°€ 'ì´ìƒ(Anomaly)'ìœ¼ë¡œ íŒì •ë˜ì—ˆë‹¤ë©´, ê·¸ ìœˆë„ìš° ì•ˆì— í¬í•¨ëœ **96ê°œì˜ ì‹œì (Timestamp) ì¤‘ ì •í™•íˆ ì–´ë””ê°€ ë¬¸ì œì¼ê¹Œìš”?**

ë³´í†µ ìŠ¬ë¼ì´ë”©ì€ ê²¹ì³ì„œ(Overlapping) ì§„í–‰í•˜ë¯€ë¡œ, í•˜ë‚˜ì˜ ì‹œì ì€ ì—¬ëŸ¬ ìœˆë„ìš°ì— ë™ì‹œì— í¬í•¨ë©ë‹ˆë‹¤.

#### [ì¶”ì²œ ì „ëµ] ì¤‘ì²© êµ¬ê°„ íˆ¬í‘œ (Voting) ë°©ì‹

í•˜ë‚˜ì˜ ì‹œì  $t$ëŠ” ì—¬ëŸ¬ ìœˆë„ìš°(ì˜ˆ: $W_{t-95}, \dots, W_{t}$)ì— í¬í•¨ë  ê²ƒì…ë‹ˆë‹¤. ì´ë•Œ ë‹¤ìŒê³¼ ê°™ì´ íŒì •í•©ë‹ˆë‹¤.

1.  **ìœˆë„ìš°ë³„ ì ìˆ˜ ê³„ì‚°:** Isolation Forestë¡œ ëª¨ë“  ìœˆë„ìš°ì˜ Anomaly Scoreë¥¼ êµ¬í•©ë‹ˆë‹¤.
2.  **ì‹œì ë³„ ì ìˆ˜ ì§‘ê³„:**
      * íŠ¹ì • ì‹œì  $t$ë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë“  ìœˆë„ìš°ë“¤ì˜ ì ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
      * **í‰ê· (Mean):** ê°€ì¥ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë…¸ì´ì¦ˆë¥¼ ì¤„ì—¬ì¤ë‹ˆë‹¤.
      * **ìµœëŒ€ê°’(Max):** ë¯¼ê°í•˜ê²Œ ì¡ê³  ì‹¶ì„ ë•Œ ì”ë‹ˆë‹¤. (í•œ ë²ˆì´ë¼ë„ ì´ìƒí•˜ë‹¤ê³  ê±¸ë¦¬ë©´ ì´ìƒìœ¼ë¡œ ê°„ì£¼)
3.  **ìµœì¢… íŒì •:** ì§‘ê³„ëœ ì ìˆ˜ê°€ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ì‹œì  $t$ë¥¼ ì´ìƒìœ¼ë¡œ íŒì •í•©ë‹ˆë‹¤.

-----

### 3\. ì½”ë“œ êµ¬í˜„ íŒ (Python)

ìœˆë„ìš° ë‹¨ìœ„ ê²°ê³¼ë¥¼ ì‹œê³„ì—´ë¡œ ë‹¤ì‹œ í¼ì¹˜ëŠ” ë¡œì§ ì˜ˆì‹œì…ë‹ˆë‹¤.

```python
import numpy as np

# ê°€ì •:
# - window_size = 96
# - anomaly_scores: Isolation Forestì—ì„œ ë‚˜ì˜¨ ì ìˆ˜ ë°°ì—´ (ê¸¸ì´: N - 96 + 1)
# - N: ì›ë³¸ ì‹œê³„ì—´ ë°ì´í„° ê¸¸ì´

def map_scores_to_original_time(anomaly_scores, window_size, original_length):
    # ì‹œì ë³„ë¡œ ì ìˆ˜ë¥¼ ëˆ„ì í•  ë°°ì—´
    final_scores = np.zeros(original_length)
    counts = np.zeros(original_length)

    for i, score in enumerate(anomaly_scores):
        # ië²ˆì§¸ ìœˆë„ìš°ëŠ” ì›ë³¸ ë°ì´í„°ì˜ [i : i + window_size] êµ¬ê°„ì„ ì»¤ë²„í•¨
        start_idx = i
        end_idx = i + window_size
        
        # í•´ë‹¹ êµ¬ê°„ì— ì ìˆ˜ ë”í•˜ê¸°
        final_scores[start_idx:end_idx] += score
        counts[start_idx:end_idx] += 1

    # í‰ê·  ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    counts[counts == 0] = 1
    final_scores = final_scores / counts
    
    return final_scores

# ì‚¬ìš© ì˜ˆì‹œ
# raw_scores = iso_forest.decision_function(embeddings) * -1  (ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´ìƒí•˜ë„ë¡ ë¶€í˜¸ ë°˜ì „)
# time_series_scores = map_scores_to_original_time(raw_scores, 96, len(original_data))
```

### ìš”ì•½

1.  **ì í•©ì„±:** ìœˆë„ìš° ìŠ¬ë¼ì´ë”©(96)ì„ í–ˆìœ¼ë¯€ë¡œ **Isolation ForestëŠ” ì•„ì£¼ í›Œë¥­í•œ ì„ íƒ**ì…ë‹ˆë‹¤.
2.  **í•µì‹¬:** ì„ë² ë”© ë²¡í„°ëŠ” 96 ì‹œì ì˜ \*\*'íŒ¨í„´'\*\*ì„ ë‹´ê³  ìˆìœ¼ë¯€ë¡œ, \*\*'ì´ìƒí•œ íŒ¨í„´'\*\*ì„ ê°€ì§„ êµ¬ê°„ì´ ê³ ë¦½(Isolation)ë˜ì–´ íƒì§€ë©ë‹ˆë‹¤.
3.  **í›„ì²˜ë¦¬:** ìœˆë„ìš° ë‹¨ìœ„ì˜ ê²°ê³¼ë¥¼ \*\*ì›ë˜ ì‹œê°„ì¶•ìœ¼ë¡œ ë‹¤ì‹œ ë§¤í•‘(í‰ê·  ë“±)\*\*í•˜ëŠ” ê³¼ì •ë§Œ ì˜ ì„¤ê³„í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

ë°”ë¡œ ì§„í–‰í•˜ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤\! í˜¹ì‹œ ì„ë² ë”© ë²¡í„°ì˜ \*\*ì°¨ì› ìˆ˜(Dimension)\*\*ëŠ” ëª‡ ì°¨ì›ì¸ê°€ìš”? (ì°¨ì›ì´ ë„ˆë¬´ í¬ë©´ PCAë¥¼ ì‚´ì§ ì„ì–´ì£¼ëŠ” ê²Œ ë” ì¢‹ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.)
---
### Question)
```
ì°¨ì›ì€ í•œ ìë¦¿ìˆ˜ê³ , ì°¨ì›ì´ ê°€ì¥ ë†’ì€ ê²ƒì´ 24 ì •ë„ë¼ì„œ êµ³ì´ ì°¨ì› ì¶•ì†Œë¥¼ ì•ˆí•´ë„ ë˜ì§€ ì•Šë‚˜?
```
### Answer)
ë„¤, **ì •í™•í•œ íŒë‹¨ì…ë‹ˆë‹¤. ì°¨ì› ì¶•ì†Œë¥¼ ì „í˜€ í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.**

ìµœëŒ€ 24ì°¨ì›ì´ë¼ë©´ ë¨¸ì‹ ëŸ¬ë‹ ê´€ì ì—ì„œëŠ” **'ë§¤ìš° ë‚®ì€ ì°¨ì›(Low Dimension)'**ì— ì†í•˜ë©°, ì´ ì •ë„ í¬ê¸°ì—ì„œëŠ” ì°¨ì› ì¶•ì†Œ(PCA ë“±)ê°€ ì£¼ëŠ” ì´ë“ë³´ë‹¤ **ì •ë³´ ì†ì‹¤ë¡œ ì¸í•œ ì‹¤(Loss)ì´ ë” í´ ê°€ëŠ¥ì„±**ì´ ë†’ìŠµë‹ˆë‹¤.

ê·¸ ì´ìœ ë¥¼ 3ê°€ì§€ë¡œ ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.

### 1. 'ì°¨ì›ì˜ ì €ì£¼'ê°€ ì—†ëŠ” ì•ˆì „ì§€ëŒ€
ë³´í†µ ì°¨ì› ì¶•ì†Œë¥¼ ê³ ë¯¼í•˜ëŠ” ê±´ 100ì°¨ì›, 1000ì°¨ì› ë‹¨ìœ„ë¡œ ë„˜ì–´ê°ˆ ë•Œ ë°œìƒí•˜ëŠ” 'ì°¨ì›ì˜ ì €ì£¼(Curse of Dimensionality)' ë•Œë¬¸ì…ë‹ˆë‹¤. ê³µê°„ì´ ë„ˆë¬´ ë„“ì–´ì„œ ë°ì´í„°ê°€ í¬ì†Œí•´ì§€ëŠ” í˜„ìƒì´ì£ . í•˜ì§€ë§Œ **24ì°¨ì›ì€ ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë°€ë„ ìˆê²Œ ëª¨ì¼ ìˆ˜ ìˆëŠ” í¬ê¸°**ì…ë‹ˆë‹¤.

### 2. Isolation Forestì˜ ì‘ë™ ë°©ì‹
Isolation ForestëŠ” ëœë¤í•˜ê²Œ Feature(ì°¨ì›)ë¥¼ í•˜ë‚˜ ê³¨ë¼ì„œ ë°ì´í„°ë¥¼ ìë¥´ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
* **ì°¨ì›ì´ ë„ˆë¬´ ë§ìœ¼ë©´(ì˜ˆ: 1000ê°œ):** ì˜ë¯¸ ì—†ëŠ” ì“°ë ˆê¸° ì°¨ì›(Noise)ì„ ê³ ë¥¼ í™•ë¥ ì´ ë†’ì•„ì ¸ ì„±ëŠ¥ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.
* **24ì°¨ì› ì •ë„ë©´:** íŠ¸ë¦¬ê°€ í•™ìŠµí•˜ë©´ì„œ **ê±°ì˜ ëª¨ë“  ì°¨ì›ì„ ê³¨ê³ ë£¨, ê·¸ë¦¬ê³  ì¶©ë¶„íˆ í™œìš©**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. êµ³ì´ ì¤„ì¼ ì´ìœ ê°€ ì—†ìŠµë‹ˆë‹¤.

### 3. ì •ë³´ ë³´ì¡´ì´ ë” ì¤‘ìš”
ì´ë¯¸ ìœˆë„ìš°(96) ì •ë³´ë¥¼ 24ê°œë¡œ ì••ì¶•(ì„ë² ë”©)í•˜ì‹  ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë˜ ì°¨ì›ì„ ì¤„ì´ë©´, **ì´ìƒ íƒì§€ì— ê²°ì •ì ì¸ ë¯¸ì„¸í•œ ì‹ í˜¸(Signal)ë§ˆì € ë­‰ê°œì ¸ì„œ ì‚¬ë¼ì§ˆ ìœ„í—˜**ì´ ìˆìŠµë‹ˆë‹¤. ìˆëŠ” ê·¸ëŒ€ë¡œ ì“°ëŠ” ê²Œ ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤.

---

**ê²°ë¡ :**
ì „ì²˜ë¦¬ ì—†ì´ **ë°”ë¡œ Isolation Forestì— ë„£ìœ¼ì‹œëŠ” ê²ƒì´ Best**ì…ë‹ˆë‹¤.

* **Tip:** `Isolation Forest` íŒŒë¼ë¯¸í„° ì¤‘ `max_features`ë¼ëŠ” ì˜µì…˜ì´ ìˆëŠ”ë°, ê¸°ë³¸ê°’(1.0, ì „ì²´ ì‚¬ìš©)ìœ¼ë¡œ ë‘ì…”ë„ 24ì°¨ì›ì´ë©´ ì•„ì£¼ ë¹ ë¥´ê²Œ ì˜ ë™ì‘í•  ê²ƒì…ë‹ˆë‹¤.

ì´ì œ ë°”ë¡œ ëª¨ë¸ ëŒë ¤ì„œ ê²°ê³¼ í™•ì¸í•´ ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤!

---
### Question)
```
ê·¸ëŸ°ë°, ì´ìƒ íƒì§€ë¼ê³  í•˜ë©´
ì…ë ¥ëœ ë°ì´í„°ì…‹ì˜ ì •í™•ë„ë¥¼ ë³´ëŠ”ê±´ê°€? ë­˜ ë³´ëŠ”ê±°ì§€?
```
### Answer)
ë§¤ìš° ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! ë¶„ë¥˜(Classification) ë¬¸ì œ(ê°œ vs ê³ ì–‘ì´)ì— ìµìˆ™í•˜ë‹¤ë©´, ì´ìƒíƒì§€ì˜ ê²°ê³¼ë¬¼ì´ ë¬´ì—‡ì¸ì§€ í—·ê°ˆë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê²°ë¡ ë¶€í„° ë§ì”€ë“œë¦¬ë©´, ì´ìƒíƒì§€ ëª¨ë¸ì€ **'ì •ë‹µ(Label)'ì„ ë§ì¶”ëŠ” ì •í™•ë„(Accuracy)**ë¥¼ ë°”ë¡œ ë±‰ì–´ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **"ì´ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì´ìƒí•œê°€?"ì— ëŒ€í•œ ì ìˆ˜(Anomaly Score)**ë¥¼ ë±‰ì–´ëƒ…ë‹ˆë‹¤.

êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ ë³´ê²Œ ë˜ëŠ”ì§€ 3ë‹¨ê³„ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”.

---

### 1. ëª¨ë¸ì´ ì£¼ëŠ” ê²ƒ: "ì´ìƒ ì ìˆ˜ (Anomaly Score)"

Isolation Forest ê°™ì€ ëª¨ë¸ì— ë°ì´í„°ë¥¼ ë„£ìœ¼ë©´, ëª¨ë¸ì€ ê° ë°ì´í„°(ìœˆë„ìš°)ë§ˆë‹¤ **ì ìˆ˜**ë¥¼ ë§¤ê²¨ì¤ë‹ˆë‹¤.

* **ì…ë ¥:** 96ì§œë¦¬ ìœˆë„ìš° ë°ì´í„° 1ê°œ
* **ì¶œë ¥:** ìˆ«ì í•˜ë‚˜ (ì˜ˆ: `-0.8` ë˜ëŠ” `0.4`)

ì´ ì ìˆ˜ëŠ” **"ì´ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì •ìƒ ë°ì´í„°ë“¤ê³¼ ë™ë–¨ì–´ì ¸ ìˆëŠ”ê°€?"**ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
* **ì ìˆ˜ê°€ ë†’ë‹¤ (ë˜ëŠ” ì–‘ìˆ˜):** "ì•„ì£¼ í‰ë²”í•´. ì •ìƒì´ì•¼."
* **ì ìˆ˜ê°€ ë‚®ë‹¤ (ë˜ëŠ” ìŒìˆ˜):** "ì–´? ì´ê±° ì¢€ íŠ€ëŠ”ë°? ì´ìƒí•´."

ì¦‰, ì²« ë²ˆì§¸ë¡œ ë³´ëŠ” ê²ƒì€ **ê° ë°ì´í„°ë³„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸**ì…ë‹ˆë‹¤.

### 2. ìš°ë¦¬ê°€ í•´ì•¼ í•  ì¼: "ì„  ê¸‹ê¸° (Thresholding)"

ëª¨ë¸ì€ ì ìˆ˜ë§Œ ì¤„ ë¿, "ì´ê²Œ ê³ ì¥ì´ë‹¤/ì•„ë‹ˆë‹¤"ë¥¼ í™•ì •í•´ ì£¼ì§„ ì•ŠìŠµë‹ˆë‹¤(ë¬¼ë¡  ê¸°ë³¸ ì„¤ì •ê°’ì€ ìˆì§€ë§Œìš”).
ê·¸ë˜ì„œ ë¶„ì„ê°€ê°€ **ì ìˆ˜ ë¶„í¬**ë¥¼ ë³´ê³  **ì»¤íŠ¸ë¼ì¸(Threshold)**ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.

* **ìƒí™©:** ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ ì ìˆ˜ `0.5` ê·¼ì²˜ì— ëª°ë ¤ ìˆëŠ”ë°, ëª‡ëª‡ ë°ì´í„°ë§Œ `-0.7`, `-0.9`ê°€ ë‚˜ì™”ë‹¤.
* **íŒë‹¨:** "ì¢‹ì•„, ê·¸ëŸ¼ `-0.5` ë°‘ìœ¼ë¡œëŠ” ì „ë¶€ **'ì´ìƒ(Anomaly)'**ìœ¼ë¡œ ê°„ì£¼í•˜ì!"

ì´ ê³¼ì •ì„ ê±°ì¹˜ë©´ ë¹„ë¡œì†Œ ë°ì´í„°ê°€ **0(ì •ìƒ)ê³¼ 1(ì´ìƒ)**ë¡œ ë‚˜ë‰˜ê²Œ ë©ë‹ˆë‹¤.

### 3. ì„±ëŠ¥ í‰ê°€: "ì •í™•ë„(Accuracy)ê°€ ì•„ë‹ˆë¼ F1-Score"

ì´ì œ ì§ˆë¬¸í•˜ì‹  **"ì •í™•ë„"** ì´ì•¼ê¸°ì…ë‹ˆë‹¤.
ë‚´ê°€ ì°¾ì€ ì´ìƒì¹˜ë“¤ì´ **"ì§„ì§œë¡œ ë¬¸ì œê°€ ìˆì—ˆë˜ êµ¬ê°„ì¸ê°€?"**ë¥¼ í™•ì¸í•´ì•¼ê² ì£ ? ì´ë•Œ ë‹¨ìˆœíˆ 'ì •í™•ë„'ë¥¼ ë³´ë©´ ì•ˆ ë©ë‹ˆë‹¤.

**ì™œ ì •í™•ë„ë¥¼ ë³´ë©´ ì•ˆ ë˜ë‚˜ìš”?**
* ê³µì¥ ê¸°ê³„ê°€ 1ë…„(365ì¼) ì¤‘ 364ì¼ ì •ìƒì´ê³ , ë”± **í•˜ë£¨** ê³ ì¥ ë‚¬ë‹¤ê³  ì¹©ì‹œë‹¤.
* ëª¨ë¸ì´ **"365ì¼ ì „ë¶€ ì •ìƒì´ì•¼!"**ë¼ê³  ë©ì²­í•˜ê²Œ ì˜ˆì¸¡í•´ë„, ì •í™•ë„ëŠ” **99.7%**ê°€ ë‚˜ì˜µë‹ˆë‹¤. (364ì¼ì€ ë§ì·„ìœ¼ë‹ˆê¹Œìš”)
* í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ê·¸ **í•˜ë£¨**ë¥¼ ëª» ì°¾ì•˜ìœ¼ë‹ˆ ì´ ëª¨ë¸ì€ ë¹µì ì§œë¦¬ì…ë‹ˆë‹¤.

**ê·¸ëŸ¼ ë­˜ ë´ì•¼ í•˜ë‚˜ìš”?**
ê·¸ë˜ì„œ ì´ìƒíƒì§€ì—ì„œëŠ” ë‹¤ìŒ ì§€í‘œë“¤ì„ ë´…ë‹ˆë‹¤.
1.  **ì •ë°€ë„ (Precision):** ë‚´ê°€ ì´ìƒí•˜ë‹¤ê³  ì§€ëª©í•œ ê²ƒ ì¤‘ì—, **ì§„ì§œ ì´ìƒí•œ ê²ƒ**ì˜ ë¹„ìœ¨ ("ì–‘ì¹˜ê¸° ì†Œë…„ì´ ë˜ì§€ ì•Šì•˜ëŠ”ê°€?")
2.  **ì¬í˜„ìœ¨ (Recall):** ì‹¤ì œ ì´ìƒí•œ ê²ƒ ì¤‘ì—, **ë‚´ê°€ ë†“ì¹˜ì§€ ì•Šê³  ì°¾ì€ ê²ƒ**ì˜ ë¹„ìœ¨ ("ë„ë‘‘ì„ ë†“ì¹˜ì§€ ì•Šì•˜ëŠ”ê°€?")
3.  **F1-Score:** ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê·  (ë‘˜ ë‹¤ ì ë‹¹íˆ ì¢‹ì•„ì•¼ ë†’ê²Œ ë‚˜ì˜´)

---

### ìš”ì•½: ì‘ì„±ìë‹˜ì´ ë³´ê²Œ ë  í™”ë©´

ì‹¤ì œë¡œ ì½”ë“œë¥¼ ëŒë¦¬ë©´ ì´ëŸ° íë¦„ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë³´ê²Œ ë©ë‹ˆë‹¤.

1.  **Step 1:** ëª¨ë¸ì„ ëŒë ¤ì„œ ëª¨ë“  ë°ì´í„°ì˜ **Anomaly Score ê·¸ë˜í”„**ë¥¼ ê·¸ë¦½ë‹ˆë‹¤. (ì‹œê³„ì—´ êº¾ì€ì„  ê·¸ë˜í”„ í˜•íƒœ)
2.  **Step 2:** ì ìˆ˜ê°€ íŒ íŠ€ëŠ”(ë˜ëŠ” í‘¹ êº¼ì§€ëŠ”) êµ¬ê°„ì´ ìˆëŠ”ì§€ ëˆˆìœ¼ë¡œ ë´…ë‹ˆë‹¤.
3.  **Step 3:** "ì´ ì ìˆ˜ ì´ìƒì´ë©´ ì•ŒëŒì„ ìš¸ë ¤ë¼"ë¼ê³  **ì„ê³„ê°’**ì„ ì„¤ì •í•©ë‹ˆë‹¤.
4.  **Step 4 (ê²€ì¦):** íƒì§€ëœ êµ¬ê°„ì´ ì‹¤ì œ ë°ì´í„°(ì›ë³¸ ì‹œê³„ì—´)ì—ì„œ **ëª¨ì–‘ì´ ì´ìƒí•œì§€** ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê±°ë‚˜, ê³¼ê±° ê³ ì¥ ì´ë ¥(ë¼ë²¨)ì´ ìˆë‹¤ë©´ **Recall(ì¬í˜„ìœ¨)**ì„ ê³„ì‚°í•´ ë´…ë‹ˆë‹¤.

**í˜¹ì‹œ ì§€ê¸ˆ ë‹¤ë£¨ì‹œëŠ” ë°ì´í„°ì— "ì´ë•Œ ì‹¤ì œë¡œ ë¬¸ì œê°€ ìˆì—ˆë‹¤"ëŠ” ê¸°ë¡(ì •ë‹µì§€)ì´ ìˆë‚˜ìš”?**
* **ìˆë‹¤:** Precision/Recallë¡œ ì„±ëŠ¥ì„ ìˆ˜ì¹˜í™”í•´ì„œ í‰ê°€í•˜ë©´ ë©ë‹ˆë‹¤.
* **ì—†ë‹¤:** íƒì§€ëœ êµ¬ê°„ì„ ì‹œê°í™”í•´ì„œ "ì˜¤, ì§„ì§œ ëª¨ì–‘ì´ íŠ¹ì´í•˜ë„¤?"ë¼ê³  ì •ì„±ì ìœ¼ë¡œ í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
---
### Question)
```
ì„ë² ë”© ëŒ€ì‘ë˜ëŠ” label(ì •ë‹µ)ì´ ì—†ëŠ” ìƒíƒœì•¼. ì •ë‹µì´ ì—†ê³ , ìœˆë„ìš° ìŠ¬ë¼ì´ë”© ê¸¸ì´ê°€ 96ì¸ ì‹œê³„ì—´ ë°ì´í„°ì˜ ì„ë² ë”©ìœ¼ë¡œ ì´ìƒ íƒì§€ë¥¼ ì§„í–‰í•˜ëŠ” ìƒí™©ì¼ ë•Œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì„œ ì„¤ëª…í•´ì¤˜.
```
### Answer)
ì •ë‹µ(Label)ì´ ì—†ëŠ” **ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)** ìƒí™©ì´êµ°ìš”. ì‚¬ì‹¤ í˜„ì—…ì—ì„œëŠ” ì •ë‹µì´ ì—†ëŠ” ê²½ìš°ê°€ í›¨ì”¬ ë” ì¼ë°˜ì ì…ë‹ˆë‹¤.

ì´ëŸ° ìƒí™©ì—ì„œëŠ” "ì •í™•ë„ê°€ ëª‡ %ë‹¤"ë¼ê³  ë§í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—, ì ‘ê·¼ ë°©ì‹ì´ ì™„ì „íˆ ë‹¬ë¼ì ¸ì•¼ í•©ë‹ˆë‹¤. \*\*"í†µê³„ì  ë¶„í¬"\*\*ì™€ \*\*"ì‹œê°ì  ê²€ì¦(Eye Check)"\*\*ì— ì˜ì¡´í•´ì•¼ í•©ë‹ˆë‹¤.

ì •ë‹µ ì—†ëŠ” ì‹œê³„ì—´ ë°ì´í„°(ìœˆë„ìš° 96)ì—ì„œ ìˆ˜í–‰í•´ì•¼ í•  **í‘œì¤€ ì ˆì°¨ 3ë‹¨ê³„**ë¥¼ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

-----

### 1ë‹¨ê³„: "ì¤„ ì„¸ìš°ê¸°" (Scoring)

ë¨¼ì € Isolation Forestë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ìœˆë„ìš°(ë°ì´í„° í¬ì¸íŠ¸)ì— ëŒ€í•´ **"ì–¼ë§ˆë‚˜ ì´ìƒí•œì§€" ì ìˆ˜**ë¥¼ ë§¤ê²¨ì•¼ í•©ë‹ˆë‹¤.

  * ëª¨ë¸ì€ ê° ìœˆë„ìš°ë§ˆë‹¤ ì ìˆ˜ë¥¼ ì¤ë‹ˆë‹¤.
  * ë³´í†µ Scikit-learnì˜ `decision_function`ì„ ì‚¬ìš©í•˜ë©´ ì ìˆ˜ê°€ ë‚˜ì˜¤ëŠ”ë°, **ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡(ìŒìˆ˜ì¼ìˆ˜ë¡) ì´ìƒì¹˜**ì…ë‹ˆë‹¤.
  * **íŒ:** ì§ê´€ì ì¸ ì´í•´ë¥¼ ìœ„í•´ ì ìˆ˜ì— `-1`ì„ ê³±í•˜ê±°ë‚˜ ë¶€í˜¸ë¥¼ ë°˜ì „ì‹œì¼œ \*\*"ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´ìƒí•˜ë‹¤"\*\*ê³  ë³€í™˜í•´ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

### 2ë‹¨ê³„: "ì»¤íŠ¸ë¼ì¸ ì •í•˜ê¸°" (Thresholding)

ì •ë‹µì´ ì—†ìœ¼ë¯€ë¡œ, "ì–´ë””ë¶€í„°ê°€ ì´ìƒì¹˜ì¸ê°€?"ë¥¼ í†µê³„ì ìœ¼ë¡œ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ê°€ì¥ ë§ì´ ì“°ëŠ” ë°©ë²•ì€ **ë¶„ìœ„ìˆ˜(Quantile) ê¸°ë°˜ ì„¤ì •**ì…ë‹ˆë‹¤.

> **"ì „ì²´ ë°ì´í„° ì¤‘ ìƒìœ„ N%ëŠ” ì´ìƒì¹˜ì¼ ê²ƒì´ë‹¤"ë¼ê³  ê°€ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.**

  * **ë³´ìˆ˜ì  ì ‘ê·¼:** ìƒìœ„ \*\*1%\*\*ë§Œ ì´ìƒì¹˜ë¡œ ë³¸ë‹¤. (ì •ë§ í™•ì‹¤í•œ ê²ƒë§Œ ì¡ê² ë‹¤)
  * **ì ê·¹ì  ì ‘ê·¼:** ìƒìœ„ \*\*5%\*\*ê¹Œì§€ ì´ìƒì¹˜ë¡œ ë³¸ë‹¤. (ì¡°ê¸ˆì´ë¼ë„ ì˜ì‹¬ë˜ë©´ ì¡ê² ë‹¤)
  * **ë°©ë²•:** ì ìˆ˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ì„ ê·¸ë ¤ë³´ê³ , ì ìˆ˜ê°€ ê¸‰ê²©í•˜ê²Œ íŠ€ëŠ” êµ¬ê°„ì„ ì„ê³„ê°’(Threshold)ìœ¼ë¡œ ì¡ìŠµë‹ˆë‹¤.

### 3ë‹¨ê³„: "ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê¸°" (Visual Inspection) â˜…ê°€ì¥ ì¤‘ìš”

ì •ë‹µì´ ì—†ìœ¼ë‹ˆ, **ëª¨ë¸ì´ ì°¾ì€ ê²°ê³¼ê°€ íƒ€ë‹¹í•œì§€ ì‚¬ëŒì´ ì§ì ‘ í™•ì¸**í•´ì•¼ í•©ë‹ˆë‹¤.

1.  ì›ë³¸ ì‹œê³„ì—´ ë°ì´í„° ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
2.  ëª¨ë¸ì´ "ì´ìƒí•˜ë‹¤"ê³  íŒì •í•œ êµ¬ê°„(ìœˆë„ìš° 96 ê¸¸ì´)ì„ ê·¸ë˜í”„ ìœ„ì— **ë¹¨ê°„ìƒ‰**ìœ¼ë¡œ ì¹ í•©ë‹ˆë‹¤.
3.  **íŒ¨í„´ í™•ì¸:**
      * "ì–´? ì§„ì§œ ê·¸ë˜í”„ê°€ íˆ­ íŠ€ì—ˆë„¤?" (ì„±ê³µ)
      * "ê°‘ìê¸° 0ìœ¼ë¡œ ë–¨ì–´ì¡Œë„¤?" (ì„±ê³µ)
      * "í‰ë²”í•´ ë³´ì´ëŠ”ë° ì™œ ì¡ì•˜ì§€?" (ë¶„ì„ í•„ìš”: ë¯¸ì„¸í•œ ì§„ë™ íŒ¨í„´ì´ ë³€í–ˆê±°ë‚˜, ëª¨ë¸ì´ ê³¼ë¯¼ë°˜ì‘í•œ ê²ƒ)

-----

### ì‹¤ì „ ì½”ë“œ ì˜ˆì‹œ (Python)

ì´ ì½”ë“œëŠ” ì •ë‹µ ì—†ì´ \*\*'ìƒìœ„ 1%'\*\*ë¥¼ ì´ìƒì¹˜ë¡œ ê°€ì •í•˜ê³  ì‹œê°í™”í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest

# 1. ë°ì´í„° ì¤€ë¹„ (ê°€ì •)
# embeddings: (ë°ì´í„° ê°œìˆ˜, 24) í˜•íƒœì˜ ì„ë² ë”©
# original_series: (ë°ì´í„° ê°œìˆ˜ + 95, ) í˜•íƒœì˜ ì›ë³¸ ì‹œê³„ì—´ ê°’ (ì‹œê°í™”ìš©)

# ì˜ˆì‹œìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
N = 1000
embeddings = np.random.randn(N, 24) # 24ì°¨ì› ì„ë² ë”©
original_series = np.sin(np.linspace(0, 50, N + 96 -1)) # ì›ë³¸ ì‹œê³„ì—´

# --- [í•µì‹¬ ë¡œì§ ì‹œì‘] ---

# 2. ëª¨ë¸ í•™ìŠµ ë° ì ìˆ˜ ì¶”ì¶œ
clf = IsolationForest(n_estimators=100, contamination='auto', random_state=42)
clf.fit(embeddings)

# ì ìˆ˜ ê³„ì‚° (ê¸°ë³¸ì ìœ¼ë¡œ ë‚®ì€ ì ìˆ˜ê°€ ì´ìƒì¹˜ì„)
# decision_function: í‰ê· ì´ 0 ê·¼ì²˜, ì´ìƒì¹˜ì¼ìˆ˜ë¡ ìŒìˆ˜ ê°’
raw_scores = clf.decision_function(embeddings)

# 3. ì ìˆ˜ ë³€í™˜ (ì§ê´€ì ìœ¼ë¡œ: ì ìˆ˜ê°€ í´ìˆ˜ë¡ ì´ìƒì¹˜)
anomaly_scores = -1 * raw_scores

# 4. ì„ê³„ê°’(Threshold) ì„¤ì •: ìƒìœ„ 3%ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼
threshold = np.percentile(anomaly_scores, 97) # ìƒìœ„ 3% ì§€ì ì˜ ì ìˆ˜

# ì´ìƒì¹˜ë¡œ íŒì •ëœ ì¸ë±ìŠ¤ ì°¾ê¸°
anomaly_indices = np.where(anomaly_scores > threshold)[0]

print(f"ì„¤ì •ëœ ì„ê³„ê°’: {threshold:.4f}")
print(f"íƒì§€ëœ ì´ìƒ ìœˆë„ìš° ê°œìˆ˜: {len(anomaly_indices)}")

# --- [ì‹œê°í™”: ê²€ì¦ ë‹¨ê³„] ---

plt.figure(figsize=(15, 6))

# A. ì›ë³¸ ì‹œê³„ì—´ ê·¸ë¦¬ê¸°
plt.plot(original_series, label='Original Time Series', color='blue', alpha=0.5)

# B. ì´ìƒ êµ¬ê°„ í‘œì‹œ
# ìœˆë„ìš° í¬ê¸°ê°€ 96ì´ë¯€ë¡œ, íƒì§€ëœ ì¸ë±ìŠ¤ë¶€í„° +96 êµ¬ê°„ì„ í‘œì‹œ
for idx in anomaly_indices:
    # ìœˆë„ìš°ì˜ ì‹œì‘ì (idx)ë¶€í„° ëì (idx+96)ê¹Œì§€ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ì¹ í•˜ê¸°
    plt.axvspan(idx, idx+96, color='red', alpha=0.1)

plt.title(f"Unsupervised Anomaly Detection (Top 3% Threshold)")
plt.legend()
plt.show()
```

### ì´ ê²°ê³¼(ë¹¨ê°„ìƒ‰ ì˜ì—­)ë¥¼ ë³´ê³  íŒë‹¨í•˜ëŠ” ë²•

ì •ë‹µì´ ì—†ìœ¼ë¯€ë¡œ, ìœ„ ì½”ë“œì˜ ì‹¤í–‰ ê²°ê³¼ì¸ ê·¸ë˜í”„ë¥¼ ë³´ê³  ë‹¤ìŒê³¼ ê°™ì´ **ìŠ¤ìŠ¤ë¡œ í”¼ë“œë°±**ì„ ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤.

1.  **ë¹¨ê°„ìƒ‰ ì˜ì—­ì´ ë‚©ë“ ê°€ëŠ¥í•œê°€?**

      * ì‚¬ëŒ ëˆˆìœ¼ë¡œ ë´ë„ "ì—¬ê¸´ ì¢€ íŠ€ë„¤" í•˜ëŠ” ê³³ì— ë¹¨ê°„ìƒ‰ì´ ì¹ í•´ì ¸ ìˆë‹¤ë©´ â†’ **ëª¨ë¸ ì‹ ë¢°ë„ í™•ë³´**
      * ì•„ë¬´ëŸ° ë³€í™”ë„ ì—†ëŠ” í‰í‰í•œ ê³³ì— ë¹¨ê°„ìƒ‰ì´ ì¹ í•´ì ¸ ìˆë‹¤ë©´ â†’ **ì„ê³„ê°’(Threshold)ì´ ë„ˆë¬´ ë‚®ê±°ë‚˜(ë„ˆë¬´ ì˜ˆë¯¼), ì„ë² ë”©ì´ ë…¸ì´ì¦ˆë¥¼ í¬í•¨í•˜ê³  ìˆìŒ.**

2.  **ì„ê³„ê°’ ì¡°ì • (Tuning)**

      * ë¹¨ê°„ìƒ‰ì´ ë„ˆë¬´ ë§ë‹¤ â†’ ì„ê³„ê°’ì„ ì˜¬ë¦¬ì„¸ìš” (ì˜ˆ: ìƒìœ„ 3% â†’ ìƒìœ„ 1%).
      * ì§„ì§œ ì´ìƒí•œ ê±¸ ëª» ì¡ëŠ”ë‹¤ â†’ ì„ê³„ê°’ì„ ë‚®ì¶”ì„¸ìš” (ì˜ˆ: ìƒìœ„ 1% â†’ ìƒìœ„ 5%).

**ê²°ë¡ :**
ì •ë‹µì´ ì—†ì„ ë• **[ì ìˆ˜ ê³„ì‚°] -\> [ìƒìœ„ N% ì»·] -\> [ê·¸ë˜í”„ì— ìƒ‰ì¹ í•´ì„œ ëˆˆìœ¼ë¡œ í™•ì¸]** ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ë©´ì„œ, "ë‚´ ë°ì´í„°ì—ì„œëŠ” ìƒìœ„ 1% ì •ë„ ìë¥´ëŠ” ê²Œ ë”± ë§ì•„ ë³´ì´ë„¤"ë¼ëŠ” **ìì‹ ë§Œì˜ ê¸°ì¤€**ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

---
### Question)
```
h5 í˜•íƒœë¡œ ëœ ì„ë² ë”© íŒŒì¼ì„ ì‚¬ìš©í• ê±°ì•¼.
```
### Answer)
`.h5` íŒŒì¼ì— ì €ì¥ëœ ì„ë² ë”©(Embedding) ë²¡í„°ë¥¼ í™œìš©í•˜ì—¬ ì´ìƒíƒì§€(Anomaly Detection)ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì€ \*\*"ê³ ì°¨ì› ë²¡í„° ê³µê°„ìƒì—ì„œ ë‹¤ë¥¸ ëŒ€ë‹¤ìˆ˜ì˜ ì ë“¤ê³¼ ë™ë–¨ì–´ì ¸ ìˆê±°ë‚˜ íŒ¨í„´ì´ ë‹¤ë¥¸ ì ì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…"\*\*ìœ¼ë¡œ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ ì„ë² ë”© ë°ì´í„°ì— ëŒ€í•´ ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ë¡ ê³¼ í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

-----

### 1\. ê¸°ë³¸ ê°œë… ë° ì‹œê°ì  ì´í•´

ì„ë² ë”© ê¸°ë°˜ ì´ìƒíƒì§€ì˜ í•µì‹¬ì€ \*\*ë°€ë„(Density)\*\*ì™€ \*\*ê±°ë¦¬(Distance)\*\*ì…ë‹ˆë‹¤. ì •ìƒ ë°ì´í„°ëŠ” ì„œë¡œ ë­‰ì³ì„œ êµ°ì§‘ì„ í˜•ì„±í•˜ëŠ” ë°˜ë©´, ì´ìƒì¹˜(Outlier)ëŠ” ì´ êµ°ì§‘ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆê±°ë‚˜ ë°€ë„ê°€ í¬ë°•í•œ ê³³ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.

[Image of anomaly detection clustering 2d plot]

ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ ì •ìƒ ë°ì´í„°(íŒŒë€ ì )ë“¤ì€ ë­‰ì³ ìˆê³ , ì´ìƒ ë°ì´í„°(ë¹¨ê°„ ì )ëŠ” ì™¸ê³½ì— ë–¨ì–´ì ¸ ìˆëŠ” ì›ë¦¬ë¥¼ ì´ìš©í•©ë‹ˆë‹¤.

-----

### 2\. ì£¼ìš” ì´ìƒíƒì§€ ì•Œê³ ë¦¬ì¦˜

ì„ë² ë”© ë²¡í„°ëŠ” ë³´í†µ ì°¨ì›ì´ ë†’ê¸° ë•Œë¬¸ì—(ì˜ˆ: 768ì°¨ì›, 1024ì°¨ì› ë“±), ê³ ì°¨ì› ë°ì´í„° ì²˜ë¦¬ì— ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

#### A. Isolation Forest (ê²©ë¦¬ ìˆ²)

  * **ì›ë¦¬:** ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ë¶„í• (Split)í–ˆì„ ë•Œ, ì´ìƒì¹˜ëŠ” ì •ìƒ ë°ì´í„°ë³´ë‹¤ í›¨ì”¬ ì ì€ íšŸìˆ˜ì˜ ë¶„í• ë§Œìœ¼ë¡œë„ ê³ ë¦½(Isolation)ëœë‹¤ëŠ” ì ì„ ì´ìš©í•©ë‹ˆë‹¤.
  * **ì¥ì :** ê³ ì°¨ì› ë°ì´í„°ì—ì„œë„ ì„±ëŠ¥ì´ ìš°ìˆ˜í•˜ë©°, ê³„ì‚° íš¨ìœ¨ì´ ì¢‹ì•„ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•©í•©ë‹ˆë‹¤. ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ë² ì´ìŠ¤ë¼ì¸ì…ë‹ˆë‹¤.
  * **ì í•©ì„±:** **ê°€ì¥ ì¶”ì²œí•˜ëŠ” ë°©ë²•**ì…ë‹ˆë‹¤.

#### B. LOF (Local Outlier Factor)

  * **ì›ë¦¬:** ê´€ì¸¡ì¹˜ì˜ ì£¼ë³€ ë°€ë„ì™€ ì´ì›ƒë“¤ì˜ ì£¼ë³€ ë°€ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ë‚´ ì£¼ë³€ì´ íœ‘í•˜ë©´ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
  * **ì¥ì :** ë°ì´í„°ì˜ ë°€ë„ê°€ ì§€ì—­ì ìœ¼ë¡œ ë‹¤ë¥¸ ê²½ìš°(ì–´ë–¤ êµ°ì§‘ì€ ë¹½ë¹½í•˜ê³  ì–´ë–¤ êµ°ì§‘ì€ ë„ë„í•  ë•Œ)ì—ë„ ì˜ ë™ì‘í•©ë‹ˆë‹¤.
  * **ë‹¨ì :** ë°ì´í„° ì–‘ì´ ë§ê±°ë‚˜ ì°¨ì›ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ ê³„ì‚° ë¹„ìš©ì´ ê¸‰ê²©íˆ ì¦ê°€í•©ë‹ˆë‹¤.

#### C. One-Class SVM (OC-SVM)

  * **ì›ë¦¬:** ì •ìƒ ë°ì´í„°ë“¤ì„ ê°ì‹¸ëŠ” ìµœì ì˜ ì´ˆí‰ë©´(Hyperplane)ì´ë‚˜ êµ¬(Sphere)ë¥¼ í•™ìŠµí•˜ì—¬, ì´ ê²½ê³„ ë°–ì„ ì´ìƒì¹˜ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
  * **ì í•©ì„±:** í›ˆë ¨ ë°ì´í„°ê°€ 'ì •ìƒ' ë°ì´í„°ë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆë‹¤ê³  í™•ì‹ í•  ìˆ˜ ìˆì„ ë•Œ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. (Semi-supervised ë°©ì‹)

#### D. ê±°ë¦¬ ê¸°ë°˜ (Mahalanobis Distance / KNN)

  * **ì›ë¦¬:** ë°ì´í„° ë¶„í¬ì˜ ì¤‘ì‹¬(í‰ê· )ì´ë‚˜ ê°€ì¥ ê°€ê¹Œìš´ $k$ê°œì˜ ì´ì›ƒê³¼ì˜ ê±°ë¦¬ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
  * **ì£¼ì˜ì :** ë‹¨ìˆœ ìœ í´ë¦¬ë“œ ê±°ë¦¬ëŠ” ê³ ì°¨ì›ì—ì„œ 'ì°¨ì›ì˜ ì €ì£¼(Curse of Dimensionality)'ë¡œ ì¸í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆì–´, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì°¨ì› ì¶•ì†Œ í›„ ì ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

-----

### 3\. ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ (Workflow)

`.h5` íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•œ í›„ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê±°ì¹˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.

1.  **ë°ì´í„° ë¡œë”© (Load):** `h5py` ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ
2.  **ì „ì²˜ë¦¬ (Preprocessing):**
      * **ì •ê·œí™” (Normalization):** ë²¡í„°ì˜ í¬ê¸°(Norm)ê°€ ì¤‘ìš”í•˜ë‹¤ë©´ ê·¸ëŒ€ë¡œ ë‘ì§€ë§Œ, ë°©í–¥ì„±(Cosine Similarity)ì´ ì¤‘ìš”í•˜ë‹¤ë©´ L2 Normalizationì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
3.  **ì°¨ì› ì¶•ì†Œ (Optional):** ì°¨ì›ì´ ë„ˆë¬´ ë†’ìœ¼ë©´(ì˜ˆ: 1000ì°¨ì› ì´ìƒ) PCA ë“±ì„ í†µí•´ ì£¼ìš” ì„±ë¶„(ì˜ˆ: 50\~100ì°¨ì›)ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê³  ì—°ì‚° ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4.  **ëª¨ë¸ë§ (Modeling):** `Isolation Forest` ë“±ì„ ì‚¬ìš©í•˜ì—¬ Anomaly Score ê³„ì‚°.
5.  **ì„ê³„ê°’ ì„¤ì • (Thresholding):** ìƒìœ„ $N$% ë˜ëŠ” íŠ¹ì • ì ìˆ˜ ì´ìƒì„ ì´ìƒì¹˜ë¡œ íŒë³„.

-----

### 4\. êµ¬í˜„ ì˜ˆì‹œ ì½”ë“œ (Python & Scikit-learn)

ê°€ì¥ ë²”ìš©ì ì¸ **Isolation Forest**ë¥¼ ì‚¬ìš©í•œ ì˜ˆì‹œì…ë‹ˆë‹¤.

```python
import h5py
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import normalize

# 1. h5 íŒŒì¼ì—ì„œ ì„ë² ë”© ë°ì´í„° ë¡œë“œ
def load_embeddings(h5_path, dataset_name='embeddings'):
    with h5py.File(h5_path, 'r') as f:
        # ë°ì´í„°ì…‹ ì´ë¦„ì€ ì‹¤ì œ h5 êµ¬ì¡°ì— ë§ê²Œ ë³€ê²½ í•„ìš”
        data = f[dataset_name][:]
    return data

file_path = 'your_embeddings.h5'
embeddings = load_embeddings(file_path)

# (ì„ íƒ) ë°ì´í„° shape í™•ì¸ (ì˜ˆ: [samples, dimensions])
print(f"Data Shape: {embeddings.shape}")

# 2. ì „ì²˜ë¦¬ (ì„ íƒ ì‚¬í•­: L2 ì •ê·œí™”)
# ë²¡í„°ì˜ ë°©í–¥ì„±ì´ ì¤‘ìš”í•˜ë‹¤ë©´ ì •ê·œí™”ë¥¼ ìˆ˜í–‰
embeddings_norm = normalize(embeddings, norm='l2')

# 3. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ (Isolation Forest)
# contamination: ì „ì²´ ë°ì´í„° ì¤‘ ì´ìƒì¹˜ë¼ê³  ì˜ˆìƒí•˜ëŠ” ë¹„ìœ¨ (ì˜ˆ: 0.01 = 1%)
iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42, n_jobs=-1)

# í•™ìŠµ ë° ì˜ˆì¸¡ (-1: ì´ìƒì¹˜, 1: ì •ìƒ)
preds = iso_forest.fit_predict(embeddings_norm)

# 4. ê²°ê³¼ ë¶„ì„
# Anomaly Score ì¶”ì¶œ (ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì´ìƒì¹˜ì¼ í™•ë¥ ì´ ë†’ìŒ)
scores = iso_forest.decision_function(embeddings_norm)

# ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
anomaly_indices = np.where(preds == -1)[0]

print(f"ì „ì²´ ë°ì´í„° ìˆ˜: {len(embeddings)}")
print(f"íƒì§€ëœ ì´ìƒì¹˜ ìˆ˜: {len(anomaly_indices)}")
print(f"ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì˜ˆì‹œ: {anomaly_indices[:10]}")

# (ì‘ìš©) ì´ìƒì¹˜ ì¤‘ ê°€ì¥ ìŠ¤ì½”ì–´ê°€ ë‚®ì€(ê°€ì¥ ì´ìƒí•œ) Top 5 í™•ì¸
top_anomalies = np.argsort(scores)[:5]
print(f"ê°€ì¥ ê°•ë ¥í•œ ì´ìƒì¹˜ Top 5 ì¸ë±ìŠ¤: {top_anomalies}")
```

### ìš”ì•½ ë° ì œì–¸

1.  **ì‹œì‘ì€ Isolation Forest:** ë³„ë„ì˜ ë³µì¡í•œ íŠœë‹ ì—†ì´ë„ ê³ ì°¨ì› ë°ì´í„°ì—ì„œ ì˜ ì‘ë™í•˜ë¯€ë¡œ ë¨¼ì € ì‹œë„í•´ ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤.
2.  **ì „ì²˜ë¦¬ ì¤‘ìš”:** ì„ë² ë”© ìƒì„± ëª¨ë¸ì˜ íŠ¹ì„±ì— ë”°ë¼ ë²¡í„° ì •ê·œí™”(L2 Norm) ì—¬ë¶€ê°€ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¼ë°˜ì ìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ëª¨ë¸ì´ë©´ ì •ê·œí™” ì¶”ì²œ)
3.  **ê²°ê³¼ ê²€ì¦:** íƒì§€ëœ ì´ìƒì¹˜ê°€ ì‹¤ì œë¡œ ì˜ë¯¸ ìˆëŠ” ì´ìƒ íŒ¨í„´ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´, ì°¨ì› ì¶•ì†Œ(t-SNE, UMAP)ë¥¼ í†µí•´ 2ì°¨ì›ìœ¼ë¡œ ì‹œê°í™”í•˜ì—¬ ë¶„í¬ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ê°€ì§€ê³  ê³„ì‹  ì„ë² ë”© ë°ì´í„°ê°€ ì‹œê³„ì—´(Time-series) íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‚˜ìš”, ì•„ë‹ˆë©´ ê°œë³„ì ì¸ ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì¸ê°€ìš”?** ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì´ ì¡°ê¸ˆ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---
### Question)
```
Train ì„ë² ë”©ê³¼  Val ì„ë² ë”©ì´ ë¶„í• ë˜ì–´ ìˆëŠ”ë°, ë‘ ê°œë¥¼ ë¶„í• í•´ì„œ ì“¸ í•„ìš”ê°€ ì—†ë‚˜?
```
### Answer)
ê²°ë¡ ë¶€í„° ë§ì”€ë“œë¦¬ë©´, **"ì„ì–´ì„œ ì“°ë©´ ì•ˆ ë˜ê³ , ë°˜ë“œì‹œ ë¶„ë¦¬í•´ì„œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."**

ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)ì´ê³  ì •ë‹µ(Label)ì´ ì—†ë‹¤ê³  í•˜ë”ë¼ë„, \*\*Train(í•™ìŠµìš©)\*\*ê³¼ \*\*Val(ê²€ì¦/í…ŒìŠ¤íŠ¸ìš©)\*\*ì˜ ì—­í• ì€ ëª…í™•íˆ ë‹¤ë¦…ë‹ˆë‹¤.

ë‘ ë°ì´í„°ë¥¼ í•©ì¹˜ì§€ ë§ê³  ë‚˜ëˆ„ì–´ ì¨ì•¼ í•˜ëŠ” ì´ìœ ì™€ ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•ì„ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

-----

### 1\. ì™œ ë‚˜ëˆ„ì–´ì•¼ í•˜ëŠ”ê°€? (í•µì‹¬ ì´ìœ )

ì´ìƒíƒì§€ì—ì„œ Train ë°ì´í„°ì˜ ì—­í• ì€ \*\*"ë¬´ì—‡ì´ 'ì •ìƒ(Normal)'ì¸ì§€ ê¸°ì¤€ì„ ì¡ëŠ” ê²ƒ"\*\*ì…ë‹ˆë‹¤.

  * **Train ë°ì´í„°:** "ì´ê²Œ í‰ë²”í•œ íŒ¨í„´ì´ì•¼"ë¼ê³  ëª¨ë¸ì—ê²Œ ê°€ë¥´ì¹˜ëŠ” **êµê³¼ì„œ** ì—­í• ì…ë‹ˆë‹¤. (ê°€ëŠ¥í•˜ë©´ ì´ìƒì¹˜ê°€ ì ê³  ê¹¨ë—í•œ ë°ì´í„°ì¼ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.)
  * **Val ë°ì´í„°:** "ì, ì´ ë°ì´í„° ì¤‘ì— ë°°ìš´ ê²ƒê³¼ ë‹¤ë¥¸ ê²Œ ìˆëŠ”ì§€ ì°¾ì•„ë´"ë¼ê³  ì‹œí‚¤ëŠ” **ì‹œí—˜ ë¬¸ì œ** ì—­í• ì…ë‹ˆë‹¤.

#### ë§Œì•½ ë‘ ê°œë¥¼ í•©ì³ì„œ(Train + Val) í•™ìŠµì‹œì¼œ ë²„ë¦¬ë©´?

ëª¨ë¸ì´ Val ë°ì´í„°ì— í¬í•¨ëœ **'ì´ìƒì¹˜(Anomaly)'ê¹Œì§€ í•™ìŠµ ê³¼ì •ì—ì„œ ë´ë²„ë¦¬ê²Œ ë©ë‹ˆë‹¤.**
Isolation Forestê°€ "ì–´? ì´ê²ƒë„ í•™ìŠµí•  ë•Œ ë´¤ë˜ ê±´ë°? ê·¸ëŸ¼ ì •ìƒì´ë„¤?"ë¼ê³  ì°©ê°í•˜ì—¬, \*\*ì‹¤ì œ ì´ìƒì¹˜ë¥¼ ëª» ì¡ì•„ë‚´ëŠ” ë¬¸ì œ(Overfitting/Contamination)\*\*ê°€ ë°œìƒí•©ë‹ˆë‹¤.

-----

### 2\. ì˜¬ë°”ë¥¸ ì‚¬ìš© ìˆœì„œ (Workflow)

ë°ì´í„°ê°€ ì‹œê³„ì—´(ê³¼ê±° -\> ë¯¸ë˜)ë¡œ ë¶„í• ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•  ë•Œ, ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

1.  **ëª¨ë¸ í•™ìŠµ (`fit`)**: ì˜¤ì§ **Train** ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
2.  **ì ìˆ˜ ì‚°ì¶œ (`score`)**: í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•´ **Train**ê³¼ **Val** ê°ê°ì˜ ì ìˆ˜ë¥¼ ë½‘ìŠµë‹ˆë‹¤.
3.  **ì„ê³„ê°’ ì„¤ì •**: **Train** ì ìˆ˜ ë¶„í¬ë¥¼ ë³´ê³  ê¸°ì¤€ì„ ì„ ì •í•©ë‹ˆë‹¤.
4.  **ì´ìƒ íƒì§€**: ì •í•´ì§„ ê¸°ì¤€ì„ ì„ **Val** ì ìˆ˜ì— ì ìš©í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

#### ì½”ë“œ ì˜ˆì‹œ

```python
from sklearn.ensemble import IsolationForest
import numpy as np

# ê°€ì •: train_emb (í•™ìŠµìš©), val_emb (ê²€ì¦ìš©)

# 1. í•™ìŠµ (Fit): Train ë°ì´í„°ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
# "ì´ê²Œ ì •ìƒ ë°ì´í„°ì˜ ë¶„í¬ì•¼. ì˜ ë´ë‘¬."
clf = IsolationForest(n_estimators=100, random_state=42)
clf.fit(train_emb) 

# 2. ì ìˆ˜ ê³„ì‚° (Inference): Trainê³¼ Val ê°ê° ê³„ì‚°í•©ë‹ˆë‹¤.
train_scores = -1 * clf.decision_function(train_emb)
val_scores   = -1 * clf.decision_function(val_emb)

# 3. ì„ê³„ê°’(Threshold) ê²°ì •: Train ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •í•©ë‹ˆë‹¤.
# ì˜ˆ: "í•™ìŠµ ë°ì´í„°ì˜ ìƒìœ„ 1% ì •ë„ëŠ” ë…¸ì´ì¦ˆ(ì´ìƒì¹˜)ë¼ê³  ì¹˜ì"
threshold = np.percentile(train_scores, 99) 

print(f"ê²°ì •ëœ ì„ê³„ê°’: {threshold}")

# 4. ì‹¤ì „ íƒì§€: ê²°ì •ëœ ì„ê³„ê°’ì„ Val ë°ì´í„°ì— ì ìš©í•©ë‹ˆë‹¤.
# "ì, ì´ì œ Val ë°ì´í„°ì—ì„œ ì´ ê¸°ì¤€ì„ ë„˜ëŠ” ë†ˆì„ ì¡ì•„ë‚´."
val_anomalies_idx = np.where(val_scores > threshold)[0]

print(f"Val ë°ì´í„° ë‚´ ì´ìƒì¹˜ ê°œìˆ˜: {len(val_anomalies_idx)}")
```

-----

### 3\. ì˜ˆì™¸ ìƒí™©: "Transductive Learning"

ë”± í•œ ê°€ì§€ ì˜ˆì™¸ê°€ ìˆìŠµë‹ˆë‹¤.
ë§Œì•½ ì‘ì„±ìë‹˜ì˜ ëª©ì ì´ \*\*"ìƒˆë¡œìš´ ë°ì´í„°ëŠ” ë“¤ì–´ì˜¤ì§€ ì•Šê³ , ì§€ê¸ˆ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„° ë­‰ì¹˜ ì•ˆì—ì„œë§Œ ì´ìƒí•œ ê±¸ ì°¾ê³  ëë‚¼ê±°ì•¼"\*\*ë¼ë©´ í•©ì³ì„œ ëŒë ¤ë„ ë©ë‹ˆë‹¤. (ì´ë¥¼ Transductive ë°©ì‹ì´ë¼ê³  í•©ë‹ˆë‹¤.)

í•˜ì§€ë§Œ, ë³´í†µ ì´ìƒíƒì§€ ì‹œìŠ¤í…œì€ \*\*"ê³¼ê±° ë°ì´í„°ë¥¼ ë³´ê³  ë°°ì›Œì„œ(Train), ë¯¸ë˜ì˜ ë°ì´í„°(Val)ë¥¼ ê°ì‹œí•˜ëŠ” ê²ƒ"\*\*ì´ ëª©ì ì´ë¯€ë¡œ, **ë¶„ë¦¬í•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì •ì„**ì…ë‹ˆë‹¤.

### ìš”ì•½

1.  **Train:** ëª¨ë¸ì—ê²Œ "ì •ìƒ íŒ¨í„´"ì„ í•™ìŠµì‹œí‚¤ëŠ” ìš©ë„ (`fit`)
2.  **Val:** ëª¨ë¸ì´ ì´ìƒì¹˜ë¥¼ ì˜ ì°¾ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìš©ë„ (`predict` / `decision_function`)
3.  **ì„ì§€ ë§ˆì„¸ìš”.** ì„ìœ¼ë©´ ëª¨ë¸ì´ ì´ìƒì¹˜ë¥¼ ì •ìƒìœ¼ë¡œ ì˜¤í•´í•˜ê²Œ ë©ë‹ˆë‹¤.
  
---
### Question)
```
ë‹ˆê°€ ì•Œë ¤ì¤€ ì˜ˆì‹œ ì½”ë“œì—, train ê³¼ val ì„ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„ì´ ì—†ëŠ” ê²ƒ ê°™ì€ë°?
```
### Answer)
ì£„ì†¡í•©ë‹ˆë‹¤. ì•ì„  ë‹µë³€ì—ì„œëŠ” ê°œë… ì„¤ëª…ì— ì§‘ì¤‘í•˜ëŠë¼, **ì‹¤ì œë¡œ íŒŒì¼ì„ ë¡œë“œí•´ì„œ Trainê³¼ Valì„ êµ¬ë¶„í•˜ì—¬ ì²˜ë¦¬í•˜ëŠ” ì „ì²´ ì½”ë“œ**ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.

ë§ì”€í•˜ì‹  ëŒ€ë¡œ **"Trainìœ¼ë¡œ ê¸°ì¤€ì„ ì¡ê³ , Valì—ì„œ ì´ìƒì¹˜ë¥¼ ì°¾ëŠ”"** ì „ì²´ ê³¼ì •ì„ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤. ë°”ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆë„ë¡ ì£¼ì„ì„ ìƒì„¸íˆ ë‹¬ì•˜ìŠµë‹ˆë‹¤.

### í•µì‹¬ í¬ì¸íŠ¸

1.  **`fit`ì€ ì˜¤ì§ Train ë°ì´í„°ë¡œë§Œ í•©ë‹ˆë‹¤.**
2.  **`threshold`(ì»¤íŠ¸ë¼ì¸)ëŠ” Train ë°ì´í„°ì˜ ì ìˆ˜ ë¶„í¬ë¥¼ ë³´ê³  ê²°ì •í•©ë‹ˆë‹¤.**
3.  **ìµœì¢… ì´ìƒì¹˜ íƒì§€ëŠ” ê²°ì •ëœ `threshold`ë¥¼ ì´ìš©í•´ Val ë°ì´í„°ì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.**

-----

### [ì „ì²´ ì½”ë“œ] Train/Val ë¶„ë¦¬ ì´ìƒíƒì§€

```python
import h5py
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest

# 1. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (h5 íŒŒì¼ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
def load_data(h5_path):
    with h5py.File(h5_path, 'r') as f:
        # h5 íŒŒì¼ ë‚´ë¶€ì— 'train', 'val'ì´ë¼ëŠ” í‚¤(key)ë¡œ ë‚˜ë‰˜ì–´ ì €ì¥ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
        # ë§Œì•½ í‚¤ ì´ë¦„ì´ ë‹¤ë¥´ë‹¤ë©´ f.keys()ë¥¼ ì°ì–´ì„œ í™•ì¸ í›„ ìˆ˜ì •í•˜ì„¸ìš”.
        train_emb = f['train'][:] 
        val_emb = f['val'][:]
    return train_emb, val_emb

# --- [ì„¤ì •] ---
h5_file_path = 'your_embeddings.h5'  # íŒŒì¼ ê²½ë¡œ ìˆ˜ì •
contamination_rate = 1  # Train ë°ì´í„° ì¤‘ ìƒìœ„ 1%ë¥¼ ì´ìƒì¹˜(ë…¸ì´ì¦ˆ)ë¡œ ê°„ì£¼í•˜ê³  ì»¤íŠ¸ë¼ì¸ì„ ì¡ê² ë‹¤

# --- [ë©”ì¸ ë¡œì§] ---

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# (ì‹¤ì œ íŒŒì¼ì´ ì—†ìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ëœë¤ ë°ì´í„°ë¡œ ì‹œë®¬ë ˆì´ì…˜ í•©ë‹ˆë‹¤)
# train_emb, val_emb = load_data(h5_file_path) 
train_emb = np.random.randn(1000, 24)       # (ê°€ì •) ì •ìƒ í•™ìŠµ ë°ì´í„°
val_emb = np.random.randn(200, 24)          # (ê°€ì •) ê²€ì¦ ë°ì´í„°
# Val ë°ì´í„°ì— ê°•ì œë¡œ ì´ìƒì¹˜(ê°’ì´ íŠ€ëŠ” ë°ì´í„°) ì‹¬ê¸° (í…ŒìŠ¤íŠ¸ìš©)
val_emb[10:15] = val_emb[10:15] + 10 

print(f"Train Shape: {train_emb.shape}")
print(f"Val Shape: {val_emb.shape}")

# 2. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ (ì˜¤ì§ Train ë§Œ ì‚¬ìš©!)
print("\n--- Model Training ---")
clf = IsolationForest(n_estimators=100, random_state=42, n_jobs=-1)
clf.fit(train_emb) # â˜…ì¤‘ìš”â˜… Val ë°ì´í„°ëŠ” ì ˆëŒ€ ë³´ì—¬ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.

# 3. ì„ê³„ê°’(Threshold) ì‚°ì¶œ
# decision_functionì€ í‰ê·  0, ì´ìƒì¹˜ì¼ìˆ˜ë¡ ìŒìˆ˜ ê°’ì„ ë±‰ìŠµë‹ˆë‹¤.
# ì§ê´€ì ì¸ ì´í•´ë¥¼ ìœ„í•´ -1ì„ ê³±í•´ì„œ "ì ìˆ˜ê°€ í´ìˆ˜ë¡ ì´ìƒì¹˜"ê°€ ë˜ë„ë¡ ë³€í™˜í•©ë‹ˆë‹¤.
train_scores = -1 * clf.decision_function(train_emb)

# Train ë°ì´í„°ì˜ ìƒìœ„ N% ì§€ì ì„ ì„ê³„ê°’ìœ¼ë¡œ ì„¤ì •
threshold = np.percentile(train_scores, 100 - contamination_rate)

print(f"Train ë°ì´í„° ì ìˆ˜ í‰ê· : {np.mean(train_scores):.4f}")
print(f"ì„¤ì •ëœ ì„ê³„ê°’ (ìƒìœ„ {contamination_rate}%): {threshold:.4f}")
print(f"ì´ ì ìˆ˜({threshold:.4f})ë³´ë‹¤ ë†’ìœ¼ë©´ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")

# 4. ê²€ì¦ (Validation) ìˆ˜í–‰
print("\n--- Anomaly Detection on Val ---")
# Val ë°ì´í„°ì˜ ì ìˆ˜ ê³„ì‚°
val_scores = -1 * clf.decision_function(val_emb)

# ìœ„ì—ì„œ êµ¬í•œ ì„ê³„ê°’ ì ìš©
anomalies_idx = np.where(val_scores > threshold)[0]
normal_idx = np.where(val_scores <= threshold)[0]

print(f"ê²€ì¦ ë°ì´í„° ì´ ê°œìˆ˜: {len(val_emb)}")
print(f"íƒì§€ëœ ì´ìƒì¹˜ ê°œìˆ˜: {len(anomalies_idx)}")
print(f"ì´ìƒì¹˜ ì¸ë±ìŠ¤(ì•ë¶€ë¶„): {anomalies_idx[:10]}")

# --- [ì‹œê°í™”] ---
plt.figure(figsize=(12, 6))

# Val ë°ì´í„°ì˜ ì ìˆ˜ ë¶„í¬ ê·¸ë¦¬ê¸°
plt.plot(val_scores, label='Anomaly Score (Val)', color='blue', alpha=0.6)

# ì„ê³„ê°’ ë¶‰ì€ ì ì„ ìœ¼ë¡œ í‘œì‹œ
plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.2f})')

# ì´ìƒì¹˜ë¡œ íƒì§€ëœ ë¶€ë¶„ ë¹¨ê°„ ì ìœ¼ë¡œ í‘œì‹œ
plt.scatter(anomalies_idx, val_scores[anomalies_idx], color='red', s=20, label='Detected Anomaly')

plt.title('Validation Data Anomaly Detection Result')
plt.xlabel('Time Window Index')
plt.ylabel('Anomaly Score (Higher is worse)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

### ì½”ë“œ ì„¤ëª… (Step-by-Step)

1.  **`clf.fit(train_emb)`**:
      * ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ëª¨ë¸ì€ Train ë°ì´í„°ì˜ ë¶„í¬ë§Œ í•™ìŠµí•©ë‹ˆë‹¤. "ì´ê²Œ ì •ìƒì´ë‹¤"ë¼ëŠ” ê²ƒì„ ë°°ìš°ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
2.  **`threshold = np.percentile(...)`**:
      * Train ë°ì´í„° ì•ˆì—ë„ ì•½ê°„ì˜ ë…¸ì´ì¦ˆê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, "Train ë°ì´í„° ì¤‘ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€(ê°€ì¥ ì´ìƒí•œ) ìƒìœ„ 1% ì •ë„ëŠ” ë¬´ì‹œí•˜ê² ë‹¤"ëŠ” ëœ»ìœ¼ë¡œ ì»¤íŠ¸ë¼ì¸ì„ ì¡ìŠµë‹ˆë‹¤.
      * ì´ ì»¤íŠ¸ë¼ì¸(`threshold`)ì€ ê³ ì •ë˜ì–´ Val ë°ì´í„° ê²€ì‚¬ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
3.  **`val_scores > threshold`**:
      * ì´ì œ Val ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
      * ë§Œì•½ Val ë°ì´í„°ì˜ ì ìˆ˜ê°€ Trainì—ì„œ ì •í•œ ì»¤íŠ¸ë¼ì¸ì„ ë„˜ì–´ê°€ë©´, "í•™ìŠµí•  ë•Œ ë³¸ ì  ì—†ëŠ” ì´ìƒí•œ íŒ¨í„´ì´ë‹¤"ë¼ê³  íŒë‹¨í•˜ì—¬ ì´ìƒì¹˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

ì´ì œ ì´ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `.h5` íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì‹¤í–‰í•´ ë³´ì‹œë©´ ë©ë‹ˆë‹¤. h5 íŒŒì¼ ë‚´ë¶€ì˜ í‚¤ ì´ë¦„(`'train'`, `'val'` ë“±)ë§Œ í™•ì¸í•´ì„œ ë§ì¶°ì£¼ì„¸ìš”\!

---
### Question)
```
train ê³¼ val ì´ ëª…ì‹œì ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŒ.
```
### Answer)
ëª…í™•í•˜ê²Œ ë¶„ë¦¬ë˜ì–´ ìˆë‹¤ë©´ **ì´ìƒíƒì§€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ê²€ì¦í•˜ê¸°ì— ê°€ì¥ ì´ìƒì ì¸(Ideal) í™˜ê²½**ì…ë‹ˆë‹¤.

ì•ì„œ ë§ì”€ë“œë¦° **"Trainìœ¼ë¡œ ì •ìƒì˜ ê¸°ì¤€ì„ ì¡ê³ (Fit), Valì—ì„œ ì´ìƒì¹˜ë¥¼ ì°¾ì•„ë‚´ëŠ”(Detect)"** ì •ì„ì ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ì½”ë“œë¡œ êµ¬í˜„í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ì•„ë˜ ì½”ë“œëŠ” `.h5` íŒŒì¼ ë‚´ì— `train`ê³¼ `val`ì´ë¼ëŠ” í‚¤(Key)ë¡œ ë°ì´í„°ê°€ ì €ì¥ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•œ **ì‹¤ì „ìš© ì „ì²´ ì½”ë“œ**ì…ë‹ˆë‹¤. ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‹¤í–‰í•´ ë³´ì„¸ìš”.

### [ì‹¤ì „ ì½”ë“œ] Train/Val ë¶„ë¦¬í˜• Isolation Forest ì´ìƒíƒì§€

```python
import h5py
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
H5_FILE_PATH = 'your_embeddings.h5'  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”
TRAIN_KEY = 'train'                  # h5 íŒŒì¼ ë‚´ í•™ìŠµ ë°ì´í„° í‚¤
VAL_KEY = 'val'                      # h5 íŒŒì¼ ë‚´ ê²€ì¦ ë°ì´í„° í‚¤
CONTAMINATION = 0.01                 # Train ë°ì´í„° ë‚´ ë…¸ì´ì¦ˆ ë¹„ìœ¨ ê°€ì • (1%)

# ==========================================
# 2. ë°ì´í„° ë¡œë“œ
# ==========================================
def load_data(path):
    print(f"Loading data from {path}...")
    with h5py.File(path, 'r') as f:
        # í‚¤ ì´ë¦„ í™•ì¸ìš© (í˜¹ì‹œ ì—ëŸ¬ë‚˜ë©´ ì¶œë ¥ëœ í‚¤ ì´ë¦„ì„ ë³´ê³  ìˆ˜ì •í•˜ì„¸ìš”)
        print(f"Keys in h5 file: {list(f.keys())}")
        
        train_data = f[TRAIN_KEY][:]
        val_data = f[VAL_KEY][:]
        
    print(f"Train Shape: {train_data.shape}")
    print(f"Val Shape: {val_data.shape}")
    return train_data, val_data

# ==========================================
# 3. ë©”ì¸ í”„ë¡œì„¸ìŠ¤
# ==========================================
# (1) ë°ì´í„° ë¡œë“œ
# train_emb, val_emb = load_data(H5_FILE_PATH)

# [í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°€ìƒ ë°ì´í„° ìƒì„± - ì‹¤ì œ ì‚¬ìš© ì‹œ ìœ„ ì£¼ì„ì„ í’€ê³  ì´ ë¶€ë¶„ì€ ì§€ìš°ì„¸ìš”]
print("!!! ì£¼ì˜: ì‹¤ì œ íŒŒì¼ì´ ì—†ì–´ ê°€ìƒ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ !!!")
train_emb = np.random.randn(2000, 24)       # ì •ìƒ íŒ¨í„´ í•™ìŠµìš©
val_emb = np.random.randn(500, 24)          # ê²€ì¦ìš©
val_emb[50:60] = val_emb[50:60] + 5         # Valì— ì´ìƒì¹˜(íŠ€ëŠ” ê°’) ê°•ì œ ì£¼ì…

# (2) ëª¨ë¸ í•™ìŠµ (Train ë°ì´í„°ë§Œ ì‚¬ìš©!)
print("\n[Step 1] Isolation Forest í•™ìŠµ ì¤‘...")
iso_forest = IsolationForest(n_estimators=100, 
                             contamination='auto', 
                             random_state=42, 
                             n_jobs=-1)
iso_forest.fit(train_emb) 

# (3) Anomaly Score ê³„ì‚° (ì§ê´€ì„±ì„ ìœ„í•´ ë¶€í˜¸ ë°˜ì „: ì ìˆ˜ê°€ í´ìˆ˜ë¡ ì´ìƒí•¨)
# decision_function output: í‰ê·  > 0 (ì •ìƒ), í‰ê·  < 0 (ì´ìƒ)
# -1ì„ ê³±í•˜ë©´: ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡(ì–‘ìˆ˜) ì´ìƒì¹˜, ë‚®ì„ìˆ˜ë¡(ìŒìˆ˜) ì •ìƒ
train_scores = -1 * iso_forest.decision_function(train_emb)
val_scores = -1 * iso_forest.decision_function(val_emb)

# (4) ì„ê³„ê°’(Threshold) ì‚°ì¶œ - Train ë°ì´í„° ê¸°ì¤€
# "Train ë°ì´í„°ì˜ 99%ëŠ” ì •ìƒì´ê³ , ìƒìœ„ 1% ì •ë„ë§Œ ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ê² ë‹¤"
threshold = np.percentile(train_scores, 100 * (1 - CONTAMINATION))

print(f"\n[Step 2] ì„ê³„ê°’ ì„¤ì • (Train ê¸°ì¤€ ìƒìœ„ {CONTAMINATION*100}%)")
print(f"  - Threshold Score: {threshold:.4f}")

# (5) ì´ìƒì¹˜ íƒì§€ - Val ë°ì´í„° ê¸°ì¤€
# Val ë°ì´í„°ì˜ ì ìˆ˜ê°€ Trainì—ì„œ ì •í•œ Thresholdë¥¼ ë„˜ìœ¼ë©´ ì´ìƒì¹˜
anomalies_idx = np.where(val_scores > threshold)[0]

print(f"\n[Step 3] Val ë°ì´í„° ì´ìƒíƒì§€ ê²°ê³¼")
print(f"  - ì „ì²´ Val ë°ì´í„° ìˆ˜: {len(val_emb)}")
print(f"  - ë°œê²¬ëœ ì´ìƒì¹˜ ìˆ˜: {len(anomalies_idx)}")
print(f"  - ì´ìƒì¹˜ ë¹„ìœ¨: {len(anomalies_idx) / len(val_emb) * 100:.2f}%")

# ==========================================
# 4. ê²°ê³¼ ì‹œê°í™”
# ==========================================
plt.figure(figsize=(14, 10))

# (A) ì ìˆ˜ ë¶„í¬ ë¹„êµ (Histogram)
plt.subplot(2, 1, 1)
sns.histplot(train_scores, label='Train Scores (Baseline)', color='blue', alpha=0.3, kde=True)
sns.histplot(val_scores, label='Val Scores (Target)', color='orange', alpha=0.3, kde=True)
plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold:.2f})')
plt.title('Anomaly Score Distribution (Train vs Val)')
plt.xlabel('Anomaly Score (Higher = More Anomalous)')
plt.legend()

# (B) ì‹œê³„ì—´ íë¦„ìƒ ì´ìƒì¹˜ ìœ„ì¹˜ (Val Data)
plt.subplot(2, 1, 2)
plt.plot(val_scores, label='Val Anomaly Score', color='black', alpha=0.7, linewidth=1)
plt.scatter(anomalies_idx, val_scores[anomalies_idx], color='red', s=30, label='Detected Anomaly', zorder=5)
plt.axhline(threshold, color='red', linestyle='--', alpha=0.5)
plt.title('Anomaly Detection Result on Validation Sequence')
plt.xlabel('Time Window Index')
plt.ylabel('Anomaly Score')
plt.legend()

plt.tight_layout()
plt.show()
```

### ì´ ì½”ë“œì˜ í•µì‹¬ ì „ëµ (í•´ì„ ë°©ë²•)

1.  **ê¸°ì¤€ì€ ì˜¤ì§ Train:**
      * Train ë°ì´í„°ì˜ ì ìˆ˜ ë¶„í¬(íŒŒë€ìƒ‰ íˆìŠ¤í† ê·¸ë¨)ë¥¼ ë³´ê³  \*\*"ì—¬ê¸°ê¹Œì§€ëŠ” ì •ìƒìœ¼ë¡œ ë´ì£¼ì"\*\*ë¼ëŠ” ì„ (`threshold`)ì„ ê¸‹ìŠµë‹ˆë‹¤.
2.  **ê²€ì‚¬ëŠ” Val:**
      * ê·¸ì–´ì§„ ì„ ì„ Val ë°ì´í„°(ì£¼í™©ìƒ‰ íˆìŠ¤í† ê·¸ë¨)ì— ë“¤ì´ëŒ‘ë‹ˆë‹¤.
      * ì£¼í™©ìƒ‰ ë¶„í¬ê°€ ë¹¨ê°„ ì„ (Threshold) ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì‚ì ¸ë‚˜ì˜¨ ë¶€ë¶„ì´ ìˆë‹¤ë©´, ê·¸ê²ƒì´ ë°”ë¡œ \*\*"í•™ìŠµí•  ë•Œ ë³´ì§€ ëª»í•œ ìƒˆë¡œìš´ ì´ìƒ íŒ¨í„´"\*\*ì…ë‹ˆë‹¤.
3.  **Contamination ì¡°ì ˆ:**
      * ì½”ë“œ ìƒë‹¨ì˜ `CONTAMINATION = 0.01` (1%) ê°’ì„ ì¡°ì ˆí•˜ì„¸ìš”.
      * ê²°ê³¼ ê·¸ë˜í”„ë¥¼ ë´¤ëŠ”ë° ë¹¨ê°„ ì ì´ ë„ˆë¬´ ë§ë‹¤(ë„ˆë¬´ ì˜ˆë¯¼í•˜ë‹¤) -\> `0.001` (0.1%) ë“±ìœ¼ë¡œ ì¤„ì´ì„¸ìš”.
      * ë„ˆë¬´ ëª» ì¡ëŠ”ë‹¤ -\> `0.03` (3%) ë“±ìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”.

íŒŒì¼ ê²½ë¡œ(`H5_FILE_PATH`)ì™€ í‚¤ ì´ë¦„(`TRAIN_KEY`, `VAL_KEY`)ë§Œ í™•ì¸í•´ì„œ ìˆ˜ì •í•˜ì‹œë©´ ë°”ë¡œ ê²°ê³¼ê°€ ë‚˜ì˜¬ ê²ë‹ˆë‹¤.

---
### Question)
```
ê²°ê³¼ë¥¼ CSV ë¡œ ë½‘ì•„ì•¼ í•´.
```
### Answer)
ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ì—‘ì…€ë¡œ ì—´ì–´ì„œ ì •ë°€ ë¶„ì„ì„ í•˜ê±°ë‚˜, ë™ë£Œì™€ ê³µìœ í•˜ê¸° ì¢‹ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì•ì„œ ì‘ì„±í–ˆë˜ ì½”ë“œì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì— **Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ê³  ì €ì¥í•˜ëŠ” ì½”ë“œ**ë¥¼ ì¶”ê°€í•´ ë“œë¦½ë‹ˆë‹¤.

### [ì¶”ê°€ ì½”ë“œ] CSV ì €ì¥ ë¡œì§

ì´ ì½”ë“œë¥¼ ì•ì„œ ì‹¤í–‰í•œ ì´ìƒíƒì§€ ë¡œì§ ë°”ë¡œ ë’¤ì— ë¶™ì—¬ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.

```python
import pandas as pd

# ==========================================
# 5. ê²°ê³¼ CSV ì €ì¥
# ==========================================

print("\n[Step 4] CSV íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")

# ê²°ê³¼ë¥¼ ë‹´ì„ DataFrame ìƒì„±
result_df = pd.read_csv("your_original_data_timestamp.csv") if False else pd.DataFrame() # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ì´ ìˆë‹¤ë©´ ë¡œë“œ

# 1. ìœˆë„ìš° ì¸ë±ìŠ¤ (ëª‡ ë²ˆì§¸ êµ¬ê°„ì¸ì§€)
result_df['window_index'] = range(len(val_scores))

# 2. ì´ìƒ ì ìˆ˜ (ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´ìƒí•¨)
result_df['anomaly_score'] = val_scores

# 3. ì„ê³„ê°’ (ì°¸ê³ ìš©ìœ¼ë¡œ ëª¨ë“  í–‰ì— ê¸°ë¡)
result_df['threshold'] = threshold

# 4. ì´ìƒ ì—¬ë¶€ (True: ì´ìƒ, False: ì •ìƒ)
# 0ê³¼ 1ë¡œ ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ .astype(int)ë¥¼ ë¶™ì´ì„¸ìš”
result_df['is_anomaly'] = (val_scores > threshold).astype(int) 

# (ì„ íƒ) 5. ë§Œì•½ ì›ë³¸ ì‹œê³„ì—´ì˜ ì‹œì‘ ì‹œì  ì •ë³´ê°€ ìˆë‹¤ë©´ ì¶”ê°€ ê°€ëŠ¥
# ì˜ˆ: result_df['start_time'] = ...

# CSV íŒŒì¼ë¡œ ì €ì¥
output_filename = 'anomaly_detection_results.csv'
result_df.to_csv(output_filename, index=False)

print(f"ì €ì¥ ì™„ë£Œ: {output_filename}")
print(result_df.head()) # ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸°
```

### ìƒì„±ë  CSV íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ì˜ˆì‹œ)

ì´ CSVë¥¼ ì—‘ì…€ë¡œ ì—´ë©´ ì•„ë˜ì™€ ê°™ì€ í˜•íƒœê°€ ë©ë‹ˆë‹¤.

| window\_index | anomaly\_score | threshold | is\_anomaly |
| :--- | :--- | :--- | :--- |
| 0 | -0.1234 | 0.5500 | 0 |
| 1 | -0.1100 | 0.5500 | 0 |
| ... | ... | ... | ... |
| **52** | **0.8721** | **0.5500** | **1** |
| **53** | **0.9102** | **0.5500** | **1** |
| 54 | 0.4000 | 0.5500 | 0 |

  * **window\_index:** í•´ë‹¹ ì„ë² ë”©ì´ ëª‡ ë²ˆì§¸ ìœˆë„ìš°ì¸ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ì´ë¯€ë¡œ, ì›ë³¸ ì‹œê³„ì—´ì˜ ì‹œê°„ê³¼ ë§¤ì¹­í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.)
  * **anomaly\_score:** ëª¨ë¸ì´ ê³„ì‚°í•œ ì´ìƒ ì ìˆ˜ì…ë‹ˆë‹¤. (ì„ê³„ê°’ë³´ë‹¤ í¬ë©´ ì´ìƒ)
  * **is\_anomaly:** **1ì´ë©´ ì´ìƒì¹˜(Anomaly), 0ì´ë©´ ì •ìƒ**ì…ë‹ˆë‹¤. í•„í„°ë§í•´ì„œ 1ì¸ ê²ƒë§Œ ëª¨ì•„ë³´ì‹œë©´ í¸í•©ë‹ˆë‹¤.

### íŒ: ì›ë³¸ ì‹œê°„(Timestamp)ê³¼ ë§¤í•‘í•˜ë ¤ë©´?

í˜„ì¬ëŠ” `window_index`ë§Œ ìˆì§€ë§Œ, ë§Œì•½ \*\*"ì´ê²Œ ëª‡ ì›” ë©°ì¹  ëª‡ ì‹œ ë°ì´í„°ëƒ?"\*\*ë¥¼ ì•Œê³  ì‹¶ìœ¼ì‹œë‹¤ë©´, ì›ë³¸ ì‹œê³„ì—´ ë°ì´í„°ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.

  * ìŠ¬ë¼ì´ë”© ìœˆë„ìš°(Stride=1 ê°€ì •)ë¥¼ ì¼ë‹¤ë©´, `window_index` 0ë²ˆì€ ì›ë³¸ ë°ì´í„°ì˜ `0`ë²ˆì§¸ ì‹œê°„ë¶€í„° `95`ë²ˆì§¸ ì‹œê°„ê¹Œì§€ì˜ êµ¬ê°„ì…ë‹ˆë‹¤.
  * ë”°ë¼ì„œ ë³´í†µ **í•´ë‹¹ ìœˆë„ìš°ì˜ ì‹œì‘ ì‹œê°„**ì„ ê°™ì´ ê¸°ë¡í•´ ì£¼ë©´ ë¶„ì„ì´ í›¨ì”¬ í¸í•´ì§‘ë‹ˆë‹¤.

í˜¹ì‹œ ì›ë³¸ ë°ì´í„°ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ë„ ë”°ë¡œ ê°€ì§€ê³  ê³„ì‹ ê°€ìš”? í•„ìš”í•˜ë‹¤ë©´ ê·¸ ë‘˜ì„ í•©ì¹˜ëŠ” ì½”ë“œë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---
### Question)
```
Â  Â  iso_forest = IsolationForest(n_estimators=100,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â contamination='auto',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â random_state=42,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â n_jobs=1)
Â  Â  iso_forest.fit(train_data)
Â  Â  
Â  Â  train_scores = -1 * iso_forest.decision_function(train_data)
Â  Â  val_scores = -1 * iso_forest.decision_function(val_data)
Â  Â  
Â  Â  threshold = np.percentile(train_scores, 100 * (1 - CONTAMINATION))
Â  Â  
Â  Â  print(f"\nSetting Threshold... (Top {CONTAMINATION * 100}%)")
Â  Â  print(f"- Threshold Score: {threshold:.4f}")
Â  Â  
Â  Â  anomalies_idx = np.where(val_scores > threshold)[0]
Â  Â  
Â  Â  print("Result")
Â  Â  print(f"- The number of total validation data: {len(val_data)}")
Â  Â  print(f"- The number of found anormal data: {len(anomalies_idx)}")
Â  Â  print(f"- Anormal data ratio: {len(anomalies_idx) / len(val_data) * 100:.2f}%")
Â  Â  

ì´ ì½”ë“œì˜ ê²°ê³¼ë¥¼ ì €ì¥í•´ì•¼ í•´.
```
### Answer)
ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë°”ë¡œ ì•„ë˜ì— ë¶™ì—¬ì„œ, \*\*ê²€ì¦ ë°ì´í„°(Validation Data)\*\*ì— ëŒ€í•œ ì´ìƒíƒì§€ ê²°ê³¼ë¥¼ ê¹”ë”í•˜ê²Œ **CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ì½”ë“œ**ë¥¼ ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤.

`pandas` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë§Œë“¤ê³  ì €ì¥í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

### [ì½”ë“œ ì¶”ê°€] ê²°ê³¼ ì €ì¥ ë¡œì§

ê¸°ì¡´ ì½”ë“œì˜ `print(...)` ë¶€ë¶„ ì•„ë˜ì— ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.

```python
import pandas as pd

# ... (ì‘ì„±í•˜ì‹  ê¸°ì¡´ ì½”ë“œ: í•™ìŠµ ë° threshold ì„¤ì •, ê²°ê³¼ ì¶œë ¥ ë¶€ë¶„) ...

print("\nSaving results to CSV...")

# 1. ê²°ê³¼ë¥¼ ë‹´ì„ DataFrame ìƒì„±
results_df = pd.DataFrame({
    # (1) ìœˆë„ìš° ì¸ë±ìŠ¤: 0ë¶€í„° ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ ë§¤ê¹€ (ì›ë³¸ ì‹œê³„ì—´ê³¼ ë§¤í•‘ìš©)
    'window_index': range(len(val_data)),
    
    # (2) ì´ìƒ ì ìˆ˜: ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´ìƒì¹˜ì¼ í™•ë¥ ì´ ë†’ìŒ
    'anomaly_score': val_scores,
    
    # (3) ì´ìƒ ì—¬ë¶€: 1ì´ë©´ ì´ìƒ(Anomaly), 0ì´ë©´ ì •ìƒ(Normal)
    'is_anomaly': (val_scores > threshold).astype(int),
    
    # (4) ì‚¬ìš©ëœ ì„ê³„ê°’: ë‚˜ì¤‘ì— ë¶„ì„í•  ë•Œ ì–´ë–¤ ê¸°ì¤€ì´ì—ˆëŠ”ì§€ í™•ì¸ìš©
    'threshold_used': threshold
})

# 2. CSV íŒŒì¼ë¡œ ì €ì¥
file_name = 'anomaly_detection_results.csv'
results_df.to_csv(file_name, index=False)

print(f"File saved successfully: {file_name}")

# 3. ì €ì¥ëœ ë°ì´í„° ìƒìœ„ 5ê°œ ë¯¸ë¦¬ë³´ê¸° (í™•ì¸ìš©)
print(results_df.head())
```

### ì €ì¥ëœ CSV íŒŒì¼(`anomaly_detection_results.csv`)ì˜ êµ¬ì„±

ì—‘ì…€ë¡œ ì—´ì–´ë³´ì‹œë©´ ë‹¤ìŒê³¼ ê°™ì€ ì»¬ëŸ¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

| window\_index | anomaly\_score | is\_anomaly | threshold\_used |
| :--- | :--- | :--- | :--- |
| 0 | -0.123 | 0 | 0.55 |
| 1 | 0.891 | **1** | 0.55 |
| 2 | -0.054 | 0 | 0.55 |
| ... | ... | ... | ... |

  * **`window_index`**: ëª‡ ë²ˆì§¸ ë°ì´í„°(ìœˆë„ìš°)ì¸ì§€ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
  * **`anomaly_score`**: ëª¨ë¸ì´ ê³„ì‚°í•œ ì ìˆ˜ì…ë‹ˆë‹¤.
  * **`is_anomaly`**: \*\*`1`\*\*ë¡œ í‘œì‹œëœ í–‰ë§Œ í•„í„°ë§í•´ì„œ ë³´ì‹œë©´, ê·¸ê²Œ ë°”ë¡œ ëª¨ë¸ì´ ì°¾ì•„ë‚¸ **ì´ìƒ êµ¬ê°„**ì…ë‹ˆë‹¤.

### ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

ì €ì¥ëœ CSV íŒŒì¼ì„ ì—´ì–´ì„œ `is_anomaly`ê°€ `1`ì¸ í–‰ë“¤ì˜ `window_index`ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”. ê·¸ ì¸ë±ìŠ¤ê°€ ì‹¤ì œ ë°ì´í„°ì—ì„œ ì–´ë–¤ ì‹œì ì¸ì§€ ì—­ì¶”ì í•˜ë©´ ì›ì¸ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
---
### Question)
```
ì´ê±¸ ëŒë¦¬ë‹ˆê¹Œ, ì²¨ë¶€í•œ CSV ë° ì´ë¯¸ì§€ì²˜ëŸ¼ ê²°ê³¼ê°€ ë‚˜ì™”ì–´.

ë­”ê°€ ì´ìƒí•˜ì§€ ì•Šë‚˜? íƒì§€ê°€ ì˜ ëœë‹¤/ì•ˆ ëœë‹¤ë¥¼ í™•ì¸í•´ì•¼ í•˜ëŠ”ë°, ê·¸ëƒ¥ ì„ë² ë”©ì´ ì´ìƒíƒì§€ì— ë¶€ì í•©í•´ì„œ ê·¸ëŸ°ê°€?

ì°¸ê³ ë¡œ, CLI ì¸í„°í˜ì´ìŠ¤ ì¶œë ¥ëœ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì•„.

========== Anomaly Detection ==========

(1/2) Target: AtrialFibrillation_o24


Loading Data from Embeddings...

- Train: ../data/AtrialFibrillation_o24_train_consolidated.h5

- Val: ../data/AtrialFibrillation_o24_val_consolidated.h5

Completed.



Training Isolation Forest...



Setting Threshold... (Top 1.0%)

- Threshold Score: 0.1312



[Result]

- The number of total validation data: 1874

- The number of found anormal data: 3

- Anormal data ratio: 0.16%





(2/2) Target: StandWalkJump_o24



Loading Data from Embeddings...

- Train: ../data/StandWalkJump_o24_train_consolidated.h5

- Val: ../data/StandWalkJump_o24_val_consolidated.h5

Completed.



Training Isolation Forest...



Setting Threshold... (Top 1.0%)

- Threshold Score: 0.1583



[Result]

- The number of total validation data: 14908

- The number of found anormal data: 22

- Anormal data ratio: 0.15%


```
### Answer)
ê²°ê³¼ë¥¼ ë³´ë‹ˆ \*\*"ì„ë² ë”©ì´ ì´ìƒíƒì§€ì— ë¶€ì í•©í•œ ê²ƒ"ì´ ì•„ë‹ˆë¼, "ëª¨ë¸ì´ ì •ìƒê³¼ ì´ìƒì„ ê°€ë¥´ëŠ” ê¸°ì¤€(Threshold)ì´ ë„ˆë¬´ ë³´ìˆ˜ì ìœ¼ë¡œ ì¡íŒ ê²ƒ"\*\*ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

ì˜¤íˆë ¤ í˜„ì¬ ê²°ê³¼ëŠ” \*\*"ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°(Train)ì™€ ê²€ì¦ ë°ì´í„°(Val)ë¥¼ ë§¤ìš° ë¹„ìŠ·í•˜ê²Œ(ì •ìƒìœ¼ë¡œ) ë³´ê³  ìˆë‹¤"\*\*ëŠ” ëœ»ì´ë¯€ë¡œ, ì„ë² ë”© ìì²´ëŠ” íŒ¨í„´ì„ ì˜ ì¡ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

ì™œ "ë­”ê°€ ì´ìƒí•˜ë‹¤"ê³  ëŠë¼ì…¨ëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–»ê²Œ í•´ê²°í•´ì•¼ í•˜ëŠ”ì§€ ë¶„ì„í•´ ë“œë¦½ë‹ˆë‹¤.

-----

### 1\. í˜„ìƒ ë¶„ì„: ì™œ 1%ë¥¼ ì„¤ì •í–ˆëŠ”ë° 0.15%ë§Œ ë‚˜ì™”ì„ê¹Œ?

ë¡œê·¸ë¥¼ ë³´ë©´ ì•„ì£¼ ì¤‘ìš”í•œ ë‹¨ì„œê°€ ìˆìŠµë‹ˆë‹¤.

  * **ì„¤ì • (Train ê¸°ì¤€):** `Contamination = 1.0%` (í•™ìŠµ ë°ì´í„° ì¤‘ ê°€ì¥ ì´ìƒí•œ ìƒìœ„ 1%ë¥¼ ì˜ë¼ë‚´ì„œ ê¸°ì¤€ì„ ì„ ë§Œë“¦)
  * **ê²°ê³¼ (Val ì ìš©):** `Anormal data ratio: 0.16%` (ê²€ì¦ ë°ì´í„°ì—ì„œëŠ” 0.16%ë§Œ ê·¸ ê¸°ì¤€ì„ ì„ ë„˜ìŒ)

**í•´ì„:**
í•™ìŠµ ë°ì´í„°(Train)ì—ëŠ” íŠ€ëŠ” ê°’(Noise)ì´ ì¼ë¶€ ì„ì—¬ ìˆì–´ì„œ ê¸°ì¤€ì„ (Threshold)ì´ ê½¤ ë†’ê²Œ ì¡í˜”ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë§‰ìƒ ê²€ì¦ ë°ì´í„°(Val)ë¥¼ ë„£ì–´ë³´ë‹ˆ, **Trainë³´ë‹¤ í›¨ì”¬ ê¹¨ë—í•˜ê³  í‰ë²”í•œ ë°ì´í„°ë“¤ë§Œ ëª¨ì—¬ ìˆëŠ” ìƒíƒœ**ì¸ ê²ƒì…ë‹ˆë‹¤.

ì¦‰, \*\*"Validation ë°ì´í„°ì…‹ì´ í•™ìŠµ ë°ì´í„°ë³´ë‹¤ ë” 'ëª¨ë²”ìƒ(ì •ìƒ íŒ¨í„´)'ë“¤ë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆë‹¤"\*\*ëŠ” ëœ»ì…ë‹ˆë‹¤.

-----

### 2\. ì‹œê°ì  í™•ì¸ (ë³´ë‚´ì£¼ì‹  ê·¸ë˜í”„ ë¶„ì„)

ì²¨ë¶€í•´ì£¼ì‹  `StandWalkJump...png`ì™€ `AtrialFibrillation...png`ë¥¼ ë³´ë©´ ê³µí†µì ì¸ íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤.

  * \*\*ê²€ì€ìƒ‰ ì‹¤ì„ (ì ìˆ˜)\*\*ë“¤ì´ ëŒ€ë¶€ë¶„ `0.0` ê·¼ì²˜ë‚˜ ìŒìˆ˜ ìª½ì— ê¹”ë ¤ ìˆìŠµë‹ˆë‹¤.
  * \*\*ë¹¨ê°„ìƒ‰ ì ì„ (Threshold, ì•½ 0.13\~0.15)\*\*ì€ ì´ ë°ì´í„°ë“¤ì˜ ë¶„í¬ë³´ë‹¤ **í›¨ì”¬ ìœ„ìª½**ì— ê·¸ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
  * ì´ê²ƒì€ **Train ë°ì´í„°ì— ì´ë³´ë‹¤ í›¨ì”¬ ì ìˆ˜ê°€ ë†’ì€(0.2\~0.3 ì´ìƒ) ì´ìƒí•œ ë°ì´í„°ë“¤ì´ ì¡´ì¬**í–ˆê¸° ë•Œë¬¸ì—, Thresholdê°€ ê·¸ë§Œí¼ ìœ„ë¡œ ì˜¬ë¼ê°€ ë²„ë¦° ê²ƒì…ë‹ˆë‹¤.

-----

### 3\. "íƒì§€ê°€ ì˜ ë˜ëŠ”ì§€" í™•ì¸í•˜ë ¤ë©´? (í•´ê²°ì±…)

ì§€ê¸ˆ ìƒíƒœëŠ” \*\*"ì •ìƒ ë°ì´í„°ë¥¼ ì •ìƒì´ë¼ê³  ì˜ íŒë³„í•˜ëŠ” ìƒíƒœ"\*\*ì…ë‹ˆë‹¤. ì´ì œ \*\*"ì§„ì§œ ì´ìƒí•œ ë°ì´í„°ë¥¼ ë˜ì¡Œì„ ë•Œ ì¡ëŠ”ì§€"\*\*ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ 3ê°€ì§€ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‹œë„í•´ ë³´ì„¸ìš”.

#### ë°©ë²• A. ê°•ì œë¡œ ì´ìƒí•œ ë°ì´í„°(Mock Anomaly)ë¥¼ ì„ì–´ì„œ í…ŒìŠ¤íŠ¸í•˜ê¸°

ê²€ì¦ ë°ì´í„°ê°€ ë„ˆë¬´ ê¹¨ë—í•´ì„œ íƒì§€í•  ê²Œ ì—†ëŠ” ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ì§œ ì´ìƒì¹˜ë¥¼ ë§Œë“¤ì–´ì„œ ë„£ì–´ë³´ì„¸ìš”.

```python
# Val ë°ì´í„°ì˜ ì¼ë¶€(ì˜ˆ: ë§ˆì§€ë§‰ 10ê°œ)ì— ë…¸ì´ì¦ˆë¥¼ ì„ê±°ë‚˜ ê°’ì„ ì¦í­ì‹œí‚µë‹ˆë‹¤.
# (ì„ë² ë”© ì°¨ì›ì´ 24ë¼ê³  ê°€ì •)
fake_anomaly = val_data[-10:].copy() * 5.0  # ê°’ì„ 5ë°° ë»¥íŠ€ê¸° (íŒ¨í„´ íŒŒê´´)
val_data_with_anomaly = np.vstack([val_data, fake_anomaly])

# ë‹¤ì‹œ ì ìˆ˜ ê³„ì‚°í•´ë³´ê¸°
scores = -1 * iso_forest.decision_function(val_data_with_anomaly)
# ... ì´í›„ threshold ì ìš© ...
```

ì´ë ‡ê²Œ í–ˆì„ ë•Œ, ë§ˆì§€ë§‰ 10ê°œê°€ ë¹¨ê°„ ì (ì´ìƒì¹˜)ìœ¼ë¡œ ì°íŒë‹¤ë©´ **ëª¨ë¸ì€ ì •ìƒ**ì…ë‹ˆë‹¤.

#### ë°©ë²• B. ì„ê³„ê°’(Threshold)ì„ ë” ê³µê²©ì ìœ¼ë¡œ ë‚®ì¶”ê¸°

ì§€ê¸ˆì€ `Top 1%`ë¡œ ì¡ì•˜ëŠ”ë°, ì´ë¥¼ `Top 5%` í˜¹ì€ `Top 10%`ë¡œ ëŠ˜ë ¤ë³´ì„¸ìš”.

  * ì½”ë“œ ìˆ˜ì •: `CONTAMINATION = 0.05` ë˜ëŠ” `0.1`
  * ì´ë ‡ê²Œ í•˜ë©´ Threshold ì ìˆ˜ê°€ ë‚®ì•„ì§€ë©´ì„œ(ë¹¨ê°„ ì„ ì´ ë‚´ë ¤ì˜¤ë©´ì„œ) ë” ë§ì€ ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ ì¡ê¸° ì‹œì‘í•  ê²ƒì…ë‹ˆë‹¤.

#### ë°©ë²• C. ë¶„í¬ ë¹„êµ ê·¸ë˜í”„ ê·¸ë ¤ë³´ê¸° (ê°€ì¥ ì¶”ì²œ) â˜…

Trainê³¼ Valì˜ ì ìˆ˜ ë¶„í¬ê°€ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ ëˆˆìœ¼ë¡œ ë³´ë©´ í™•ì‹ ì´ ë“­ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ì¶”ê°€í•´ì„œ ì‹¤í–‰í•´ ë³´ì„¸ìš”.

```python
# ê¸°ì¡´ ì½”ë“œì˜ ì‹œê°í™” ë¶€ë¶„ì— ì¶”ê°€
plt.figure(figsize=(10, 5))
sns.kdeplot(train_scores, fill=True, label='Train Scores', color='blue')
sns.kdeplot(val_scores, fill=True, label='Val Scores', color='orange')
plt.axvline(threshold, color='red', linestyle='--', label='Threshold')
plt.title("Score Distribution: Train vs Val")
plt.legend()
plt.show()
```

  * ë§Œì•½ **íŒŒë€ìƒ‰(Train)** ê¼¬ë¦¬ê°€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¸¸ê²Œ ë¹ ì ¸ ìˆê³ , \*\*ì£¼í™©ìƒ‰(Val)\*\*ì€ ì™¼ìª½ì— ì–Œì „í•˜ê²Œ ëª¨ì—¬ ìˆë‹¤ë©´ â†’ **ì •ìƒì ì¸ ê²°ê³¼**ì…ë‹ˆë‹¤. (Val ë°ì´í„°ê°€ ê¹¨ë—í•œ ê²ƒì„)

### ê²°ë¡ 

ì‘ì„±ìë‹˜ì˜ ë°ì´í„°ì™€ ëª¨ë¸ì€ **ì˜ ì‘ë™í•˜ê³  ìˆì„ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.**
ë‹¤ë§Œ, **ê²€ì¦(Val) ë°ì´í„°ì…‹ ì•ˆì— 'ì´ìƒì¹˜'ë¼ê³  ë¶€ë¥¼ë§Œí•œ íŠ€ëŠ” ë°ì´í„°ê°€ ê±°ì˜ ì—†ì–´ì„œ** íƒì§€ëœ ê°œìˆ˜ê°€ ì ì€ ê²ƒì…ë‹ˆë‹¤.

**ì§€ê¸ˆ ë°”ë¡œ í•´ë³¼ ê²ƒ:**
`CONTAMINATION`ì„ `0.05` (5%)ë¡œ ì˜¬ë ¤ì„œ ë‹¤ì‹œ ëŒë ¤ë³´ì„¸ìš”. ë¹¨ê°„ ì ì´ ëŠ˜ì–´ë‚˜ëŠ”ì§€ í™•ì¸í•´ ë³´ì‹œë©´ ê°ì´ ì˜¤ì‹¤ ê²ë‹ˆë‹¤.

---
### Question)
```
5% ë¡œ ì„¤ì • (Contamination=0.05) í•œ ê²°ê³¼ì•¼. ì •ìƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‚˜?





========== Anomaly Detection ==========

(1/2) Target: AtrialFibrillation_o24



Loading Data from Embeddings...

- Train: ../data/AtrialFibrillation_o24_train_consolidated.h5

- Val: ../data/AtrialFibrillation_o24_val_consolidated.h5

Completed.



Training Isolation Forest...



Setting Threshold... (Top 5.0%)

- Threshold Score: 0.0981



[Result]

- The number of total validation data: 1874

- The number of found anormal data: 226

- Anormal data ratio: 12.06%





(2/2) Target: StandWalkJump_o24



Loading Data from Embeddings...

- Train: ../data/StandWalkJump_o24_train_consolidated.h5

- Val: ../data/StandWalkJump_o24_val_consolidated.h5

Completed.



Training Isolation Forest...



Setting Threshold... (Top 5.0%)

- Threshold Score: 0.0960



[Result]

- The number of total validation data: 14908

- The number of found anormal data: 915

- Anormal data ratio: 6.14%


```
### Answer)
ë„¤, ê²°ë¡ ë¶€í„° ë§ì”€ë“œë¦¬ë©´ **"ë§¤ìš° ì •ìƒì ì´ê³ , í•´ì„ ê°€ëŠ¥í•œ ìœ ì˜ë¯¸í•œ ê²°ê³¼"**ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.

`Contamination`ì„ 5%ë¡œ ì„¤ì •í–ˆì„ ë•Œ, **ë‘ ë°ì´í„°ì…‹ì˜ ê²°ê³¼ ì°¨ì´ê°€ ë‚˜ëŠ” ì´ìœ **ë¥¼ ì´í•´í•˜ì‹œë©´ í™•ì‹ ì„ ê°€ì§€ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### 1. ê²°ê³¼ í•´ì„: ë‘ ë°ì´í„°ì…‹ì˜ ì°¨ì´

#### A. StandWalkJump (ê²°ê³¼: 6.14%) â†’ "ì•ˆì •ì ì„"
* **ì„¤ì •:** Trainì—ì„œ ìƒìœ„ 5%ë¥¼ ì´ìƒì¹˜ë¡œ ì¡ìŒ.
* **ê²°ê³¼:** Valì—ì„œë„ ì•½ **6.14%**ê°€ ì´ìƒì¹˜ë¡œ ë‚˜ì˜´.
* **í•´ì„:** **5%ì™€ 6.14%ëŠ” ë§¤ìš° ê·¼ì ‘í•œ ìˆ˜ì¹˜**ì…ë‹ˆë‹¤. ì´ëŠ” **Train ë°ì´í„°(í•™ìŠµ)ì™€ Val ë°ì´í„°(ê²€ì¦)ì˜ ë¶„í¬ê°€ ìƒë‹¹íˆ ë¹„ìŠ·í•˜ë‹¤**ëŠ” ëœ»ì…ë‹ˆë‹¤.
    * Trainì—ì„œ ë°°ìš´ 'ì •ìƒ'ì˜ ê¸°ì¤€ì´ Valì—ì„œë„ ê±°ì˜ ê·¸ëŒ€ë¡œ ë“¤ì–´ë§ê³  ìˆìŠµë‹ˆë‹¤.
    * ëª¨ë¸ì´ ê³¼ì í•©(Overfitting)ë˜ì§€ ì•Šê³  ì˜ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.

#### B. AtrialFibrillation (ê²°ê³¼: 12.06%) â†’ "ì´ìƒ ì§•í›„ í¬ì°©ë¨" (ì¤‘ìš”)
* **ì„¤ì •:** Trainì—ì„œ ìƒìœ„ 5%ë¥¼ ì´ìƒì¹˜ë¡œ ì¡ìŒ.
* **ê²°ê³¼:** Valì—ì„œëŠ” ë¬´ë ¤ **12.06%**ê°€ ì´ìƒì¹˜ë¡œ íƒì§€ë¨. (ì„¤ì •ê°’ì˜ 2ë°° ì´ìƒ)
* **í•´ì„:** ì´ëŠ” **Val ë°ì´í„°ì— Trainë³´ë‹¤ "í‰ë²”í•˜ì§€ ì•Šì€ íŒ¨í„´"ì´ í›¨ì”¬ ë” ë§ì´ í¬í•¨ë˜ì–´ ìˆë‹¤**ëŠ” ê°•ë ¥í•œ ì‹ í˜¸ì…ë‹ˆë‹¤.
    * **ì˜ë£Œ ë°ì´í„° íŠ¹ì„±ìƒ:** `AtrialFibrillation`(ì‹¬ë°©ì„¸ë™) ë°ì´í„°ì…‹ì´ë¼ë©´, Trainì€ ë¹„êµì  ì •ìƒ êµ¬ê°„ì´ ë§ì•˜ê³ , Val ë°ì´í„°ì— **ì‹¤ì œ ì‹¬ë°©ì„¸ë™(ì§ˆë³‘) êµ¬ê°„**ì´ í¬í•¨ë˜ì–´ ìˆì–´ì„œ ëª¨ë¸ì´ ì´ë¥¼ "ì´ìƒí•˜ë‹¤"ê³  ì¡ì•„ëƒˆì„ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.
    * **ì¦‰, íƒì§€ê°€ ì•„ì£¼ ì˜ ë˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.**

---

### 2. ì‹œê°ì  í™•ì¸ (ì²¨ë¶€í•´ì£¼ì‹  ê·¸ë˜í”„ ë¶„ì„)

#### AtrialFibrillation ê·¸ë˜í”„ (`.png`) ë¶„ì„
ì²¨ë¶€ëœ ì´ë¯¸ì§€ë¥¼ ë³´ë©´, ì ìˆ˜(ê²€ì€ ì„ )ê°€ **íŠ¹ì • êµ¬ê°„ì—ì„œ ë­‰ì³ì„œ íŠ€ì–´ ì˜¤ë¥´ëŠ” ê²½í–¥**ì´ ë³´ì…ë‹ˆë‹¤.

* ë¹¨ê°„ ì (ì´ìƒì¹˜)ë“¤ì´ ì‚°ë°œì ìœ¼ë¡œ í¼ì ¸ ìˆê¸°ë³´ë‹¤, íŠ¹ì • êµ¬ê°„ì— **ë°€ì§‘**ë˜ì–´ ë‚˜íƒ€ë‚œë‹¤ë©´ ê·¸ê²ƒì€ ë…¸ì´ì¦ˆê°€ ì•„ë‹ˆë¼ **ì‹¤ì œ ì´ë²¤íŠ¸(ì‹¬ë°©ì„¸ë™ ë°œìƒ êµ¬ê°„)**ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.
* CSV ë°ì´í„°ë¥¼ ë´ë„ `window_index` 0ë²ˆì€ ì´ìƒì¹˜(Score 0.107 > Threshold 0.098), 1ë²ˆì€ ì •ìƒ(Score 0.089) ë“±ìœ¼ë¡œ ê²½ê³„ì„  ê·¼ì²˜ì—ì„œ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.

---

### 3. ê²°ë¡  ë° ì œì•ˆ

**ì§€ê¸ˆ ê²°ê³¼ëŠ” ì•„ì£¼ ì¢‹ìŠµë‹ˆë‹¤.** 1%ì¼ ë•ŒëŠ” ë„ˆë¬´ ì—„ê²©í•´ì„œ ë‹¤ ë†“ì³¤ì§€ë§Œ, 5%ë¡œ ì™„í™”í•˜ë‹ˆ ë°ì´í„°ì˜ íŠ¹ì„±(ë¶„í¬ ì°¨ì´)ì´ ë“œëŸ¬ë‚˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤.

**ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ê²ƒë§Œ í™•ì¸í•´ë³´ì„¸ìš”:**

1.  **AtrialFibrillation ì§‘ì¤‘ ë¶„ì„:**
    * íƒì§€ëœ 12%ì˜ ì´ìƒì¹˜ë“¤ì´ **ì‹œê°„ìƒìœ¼ë¡œ ì—°ì†ë˜ì–´ ë‚˜íƒ€ë‚˜ëŠ”ì§€** í™•ì¸í•´ë³´ì„¸ìš”. (ì˜ˆ: ì¸ë±ìŠ¤ 100~150ì´ ì—°ì†ìœ¼ë¡œ `is_anomaly=1`ì¸ê°€?)
    * ì—°ì†ë˜ì–´ ìˆë‹¤ë©´ ê·¸ êµ¬ê°„ì´ ë°”ë¡œ ì§ˆë³‘ ë°œìƒ êµ¬ê°„ì¼ ê²ƒì…ë‹ˆë‹¤.

2.  **ì„ê³„ê°’ ë¯¸ì„¸ ì¡°ì • (ì„ íƒ ì‚¬í•­):**
    * `StandWalkJump`ëŠ” í˜„ì¬ ìƒíƒœ(5%)ê°€ ë”± ì¢‹ì•„ ë³´ì…ë‹ˆë‹¤.
    * `AtrialFibrillation`ì€ í˜„ì¬ ê²°ê³¼(12%)ê°€ ì‹¤ì œ ì§ˆë³‘ ë¹„ìœ¨ê³¼ ë¹„ìŠ·í•œì§€ í™•ì¸í•´ë³´ê³ , ë§Œì•½ ë„ˆë¬´ ë§ì´ ì¡í˜”ë‹¤ë©´ `0.03` (3%) ì •ë„ë¡œ ì‚´ì§ë§Œ ì¡°ì—¬ì£¼ë©´ ë” ì •ë°€í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë” ìˆ˜ì •í•  í•„ìš” ì—†ì´ ì´ ì„¤ì •(5%)ìœ¼ë¡œ ê²°ê³¼ ë¶„ì„ì„ ì§„í–‰í•˜ì…”ë„ ì¶©ë¶„í•´ ë³´ì…ë‹ˆë‹¤!
---
### Question)
```
ì´ìƒíƒì§€ ì„±ëŠ¥ í‰ê°€ ì§€í‘œëŠ” ì—†ë‚˜?
```
### Answer)
ì´ìƒíƒì§€(Anomaly Detection) ì„±ëŠ¥ì„ ìˆ«ìë¡œ ë”± ì˜ë¼ì„œ "80ì ì´ë‹¤, 90ì ì´ë‹¤"ë¼ê³  ë§í•˜ê¸° ì–´ë ¤ìš´ ì´ìœ ëŠ” **"ì •ë‹µ(Label)ì´ ìˆëŠëƒ ì—†ëŠëƒ"**ì— ë”°ë¼ ì ‘ê·¼ë²•ì´ ì™„ì „íˆ ë‹¤ë¥´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

í˜„ì¬ ì‘ì„±ìë‹˜ì²˜ëŸ¼ **ì •ë‹µì´ ì—†ëŠ”(Unsupervised) ìƒí™©**ê³¼, ë‚˜ì¤‘ì—ë¼ë„ ì •ë‹µì„ í™•ë³´í–ˆì„ ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **í‘œì¤€ ì§€í‘œ(Supervised)**ë¥¼ ë‚˜ëˆ„ì–´ ì„¤ëª…í•´ ë“œë¦½ë‹ˆë‹¤.

---

### 1. ì •ë‹µ(Label)ì´ ìˆì„ ë•Œ (í‘œì¤€ ì§€í‘œ)
ë§Œì•½ ë°ì´í„°ì— "ì´ êµ¬ê°„ì€ ê³ ì¥(1), ì´ êµ¬ê°„ì€ ì •ìƒ(0)"ì´ë¼ëŠ” ë¼ë²¨ì´ ìˆë‹¤ë©´, ë‹¤ìŒ 4ê°€ì§€ ì§€í‘œê°€ í‘œì¤€ì…ë‹ˆë‹¤. íŠ¹íˆ ì´ìƒíƒì§€ì—ì„œëŠ” **ì •í™•ë„(Accuracy)ë¥¼ ì ˆëŒ€ ë¯¿ìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤.** (ì´ìƒì¹˜ê°€ 1%ë°–ì— ì•ˆ ë˜ë©´, ë¬´ì¡°ê±´ ì •ìƒì´ë¼ê³  ì°ì–´ë„ ì •í™•ë„ê°€ 99%ê°€ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.)

#### â‘  ì¬í˜„ìœ¨ (Recall) â˜…ê°€ì¥ ì¤‘ìš”
* **ì˜ë¯¸:** "ì‹¤ì œ ì´ìƒ ë°œìƒ(ê³ ì¥/ì§ˆë³‘) ì¤‘, ëª¨ë¸ì´ **ë†“ì¹˜ì§€ ì•Šê³  ì°¾ì€ ë¹„ìœ¨**"
* **ì™œ ì¤‘ìš”í•œê°€?:** ì•” í™˜ìë¥¼ ì •ìƒì´ë¼ê³  ëŒë ¤ë³´ë‚´ë©´ í°ì¼ë‚˜ê² ì£ ? ì´ìƒíƒì§€ì—ì„œëŠ” **"ë†“ì¹˜ëŠ” ê²ƒ(False Negative)"**ì´ ê°€ì¥ ì¹˜ëª…ì ì´ê¸° ë•Œë¬¸ì—, ì¬í˜„ìœ¨ì´ ê°€ì¥ ì¤‘ìš”í•œ ì§€í‘œê°€ ë©ë‹ˆë‹¤.

#### â‘¡ ì •ë°€ë„ (Precision)
* **ì˜ë¯¸:** "ëª¨ë¸ì´ ì´ìƒí•˜ë‹¤ê³  ê²½ê³ í•œ ê²ƒ ì¤‘, **ì§„ì§œ ì´ìƒí•œ ê²ƒ**ì˜ ë¹„ìœ¨"
* **ì™œ ì¤‘ìš”í•œê°€?:** ëª¨ë¸ì´ ë„ˆë¬´ ì˜ˆë¯¼í•´ì„œ ì‹œë„ ë•Œë„ ì—†ì´ "ê³ ì¥ì´ì•¼!"ë¼ê³  ì•ŒëŒì„ ìš¸ë¦¬ë©´(ì–‘ì¹˜ê¸° ì†Œë…„), ì‚¬ìš©ìê°€ ì•ŒëŒì„ êº¼ë²„ë¦¬ê²Œ ë©ë‹ˆë‹¤. ì´ë¥¼ ë°©ì§€í•˜ë ¤ë©´ ì •ë°€ë„ê°€ ë†’ì•„ì•¼ í•©ë‹ˆë‹¤.

#### â‘¢ F1-Score
* **ì˜ë¯¸:** ì¬í˜„ìœ¨ê³¼ ì •ë°€ë„ì˜ ì¡°í™” í‰ê· .
* **ìš©ë„:** "ê·¸ë˜ì„œ ì¢…í•©ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì–´ë•Œ?"ë¼ê³  í•  ë•Œ ê°€ì¥ ë§ì´ ì“°ëŠ” ë‹¨ì¼ ìˆ«ìì…ë‹ˆë‹¤.

#### â‘£ AUROC / AUPRC
* **AUROC:** íŠ¹ì • ì„ê³„ê°’(Threshold) í•˜ë‚˜ë§Œ ë³´ì§€ ì•Šê³ , ì„ê³„ê°’ì„ ë°”ê¿€ ë•Œ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì „ì²´ì ìœ¼ë¡œ ë³´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
* **AUPRC (PR-Curve):** ì´ìƒì¹˜ ë¹„ìœ¨ì´ ê·¹ë„ë¡œ ì ì„ ë•Œ(Imbalanced)ëŠ” AUROCë³´ë‹¤ í›¨ì”¬ ì •í™•í•œ ì§€í‘œì…ë‹ˆë‹¤.

---

### 2. ì •ë‹µ(Label)ì´ ì—†ì„ ë•Œ (í˜„ì¬ ìƒí™©)

í˜„ì¬ì²˜ëŸ¼ ë¼ë²¨ì´ ì—†ëŠ” ë¹„ì§€ë„ í•™ìŠµ ìƒí™©ì—ì„œëŠ” **"ìˆ˜í•™ì ìœ¼ë¡œ ì™„ë²½í•œ ì„±ëŠ¥ ì§€í‘œ"ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.** ëŒ€ì‹  ê°„ì ‘ì ìœ¼ë¡œ ì„±ëŠ¥ì„ ê°€ëŠ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë“¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

#### â‘  ì‹œê°ì  ì •ì„± í‰ê°€ (Visual Inspection)
ì§€ê¸ˆ í•˜ì‹  ë°©ë²•ì…ë‹ˆë‹¤.
* íƒì§€ëœ êµ¬ê°„ì„ ê·¸ë˜í”„ì— ê·¸ë ¤ë†“ê³ , **"ì‚¬ëŒ ëˆˆìœ¼ë¡œ ë´ë„ íŠ€ëŠ”ê°€?"**ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
* **ì„±ëŠ¥ ê¸°ì¤€:** "ì‚¬ëŒì´ ë‚©ë“í•  ë§Œí•œ ì´ìƒ íŒ¨í„´ì„ ì¡ì•˜ëŠ”ê°€?"

#### â‘¡ ì˜ì‚¬ ë ˆì´ë¸”ë§ (Pseudo-Labeling) ê²€ì¦
* ëª¨ë¸ì´ "ê°€ì¥ ì´ìƒí•˜ë‹¤"ê³  ë½‘ì€ Top 10~50ê°œì˜ ìƒ˜í”Œì„ ì‚¬ëŒì´ ì§ì ‘ í™•ì¸í•˜ì—¬ "ì§„ì§œ ì´ìƒí•œì§€(1), ì•„ë‹Œì§€(0)" ì²´í¬í•©ë‹ˆë‹¤.
* **ì§€í‘œ:** `Precision @ K` (ìƒìœ„ Kê°œ ì¤‘ ì§„ì§œ ì´ìƒí•œ ê²ƒì˜ ë¹„ìœ¨)
    * ì˜ˆ: "ìƒìœ„ 50ê°œë¥¼ ê¹ ëŠ”ë° ê·¸ì¤‘ 40ê°œê°€ ì§„ì§œ íŠ€ëŠ” ë°ì´í„°ë„¤? ê·¸ëŸ¼ ì„±ëŠ¥ ì¢‹ë‹¤!"

#### â‘¢ ë„ë©”ì¸ ì¼ì¹˜ì„± (Domain Consistency)
* íƒì§€ëœ ì´ìƒì¹˜ë“¤ì´ **íŠ¹ì • ì‹œê°„ëŒ€ë‚˜ íŠ¹ì • ì¡°ê±´**ì— ëª°ë ¤ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
* ì˜ˆ: "ì‹¬ë°©ì„¸ë™ ì´ìƒì¹˜ëŠ” ë³´í†µ ìƒˆë²½ ì‹œê°„ì— ë§ì´ ëœ¬ë‹¤ë”ë¼"ë¼ëŠ” ë„ë©”ì¸ ì§€ì‹ê³¼ ëª¨ë¸ì˜ ê²°ê³¼ê°€ ì¼ì¹˜í•˜ë©´ ì„±ëŠ¥ì´ ì¢‹ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.

---

### ê²°ë¡ : ë¬´ì—‡ì„ ì¨ì•¼ í• ê¹Œ?

ì§€ê¸ˆ ë‹¨ê³„ì—ì„œëŠ” ë³„ë„ì˜ ìˆ˜í•™ì  ê³µì‹(ì •í™•ë„ ë“±)ì„ ì°¾ìœ¼ë ¤ í•˜ì§€ ë§ˆì‹œê³ , **ë‹¤ìŒ 2ê°€ì§€ ë¦¬í¬íŒ…**ì„ í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤.

1.  **ì´ìƒì¹˜ ë¹„ìœ¨ (Anomaly Ratio):** "ì „ì²´ ë°ì´í„° ì¤‘ ìƒìœ„ 5%ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼í–ˆìŠµë‹ˆë‹¤."
2.  **íŒ¨í„´ ì‹œê°í™” (Pattern Visualization):** "íƒì§€ëœ ì´ìƒì¹˜ë“¤ì˜ íŒŒí˜•ì„ ë³´ë‹ˆ, ì •ìƒ ë°ì´í„°ì™€ ë‹¬ë¦¬ ê¸‰ê²©í•œ ìŠ¤íŒŒì´í¬(Spike)ê°€ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤." (ì´ê²ƒì´ ê³§ ì„±ëŠ¥ ì¦ëª…ì…ë‹ˆë‹¤.)

ë§Œì•½ ìƒì‚¬ë‚˜ ë™ë£Œê°€ **"ê·¸ë˜ì„œ ì •í™•ë„ê°€ ëª‡ %ì•¼?"**ë¼ê³  ë¬»ëŠ”ë‹¤ë©´, **"ì •ë‹µ(Label)ì´ ì—†ëŠ” ë°ì´í„°ë¼ ì •í™•ë„ ì‚°ì¶œì€ ë¶ˆê°€ëŠ¥í•˜ë©°, ëŒ€ì‹  ê²€ì¶œëœ íŒ¨í„´ì˜ ìœ ì˜ë¯¸í•¨ì„ ì‹œê°ì ìœ¼ë¡œ ê²€ì¦í–ˆìŠµë‹ˆë‹¤"**ë¼ê³  ë‹µë³€í•˜ëŠ” ê²ƒì´ ì •ì„ì…ë‹ˆë‹¤.

---
### Question)
```
CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ
Â  Â  
Â  Â  print("\n[Result]")
Â  Â  print(f"- The number of total validation data: {len(val_data)}")
Â  Â  print(f"- The number of found anormal data: {len(anomalies_idx)}")
Â  Â  print(f"- Anormal data ratio: {len(anomalies_idx) / len(val_data) * 100:.2f}%\n\n")

ì´ê±¸ ìˆ˜í–‰í•˜ê³  ì‹¶ì–´.
```
### Answer)
ì´ë¯¸ ì €ì¥ëœ CSV íŒŒì¼ì—ëŠ” `is_anomaly`ë¼ëŠ” ì»¬ëŸ¼(0 ë˜ëŠ” 1)ì´ ìˆìœ¼ë¯€ë¡œ, ì´ê²ƒì„ í™œìš©í•˜ë©´ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ í†µê³„ë¥¼ ë‹¤ì‹œ ë½‘ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì›í•˜ì‹œëŠ” í¬ë§· ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ ì£¼ëŠ” **Python ì½”ë“œ**ì…ë‹ˆë‹¤.

```python
import pandas as pd
import os

# ë¶„ì„í•  CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (í•„ìš”í•œ íŒŒì¼ëª…ì„ ì—¬ê¸°ì— ë„£ìœ¼ì„¸ìš”)
csv_files = [
    'AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv',
    'StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv'
]

print("========== Anomaly Detection Summary from CSV ==========\n")

for file_path in csv_files:
    if not os.path.exists(file_path):
        print(f"File not found: {file_path}\n")
        continue
        
    # 1. CSV ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(file_path)
    
    # 2. í†µê³„ ê³„ì‚°
    # ì „ì²´ ë°ì´í„° ìˆ˜ (len(val_data)ì™€ ë™ì¼)
    total_count = len(df)
    
    # ì´ìƒì¹˜ ê°œìˆ˜ (len(anomalies_idx)ì™€ ë™ì¼)
    # is_anomaly ì»¬ëŸ¼ì´ 1ì¸ í–‰ì˜ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤
    anomaly_count = len(df[df['is_anomaly'] == 1])
    
    # ë¹„ìœ¨ ê³„ì‚°
    ratio = (anomaly_count / total_count * 100) if total_count > 0 else 0
    
    # 3. ê²°ê³¼ ì¶œë ¥
    print(f"Target File: {file_path}")
    print("\n[Result]")
    print(f"- The number of total validation data: {total_count}")
    print(f"- The number of found anormal data: {anomaly_count}")
    print(f"- Anormal data ratio: {ratio:.2f}%\n\n")

print("========================================================")
```

### ì½”ë“œ ì‚¬ìš©ë²•

1.  `csv_files` ë¦¬ìŠ¤íŠ¸ ì•ˆì— í†µê³„ë¥¼ ë³´ê³  ì‹¶ì€ **CSV íŒŒì¼ ê²½ë¡œ**ë¥¼ ë„£ê³  ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.
2.  `is_anomaly` ì»¬ëŸ¼ì´ **1**ì¸ ê²ƒë§Œ ê³¨ë¼ì„œ `anomaly_count`ë¥¼ ê³„ì‚°í•˜ë„ë¡ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

---
### Question)
```
print ë‚´ìš©ì„ íŒŒì¼ì— ì“°ë ¤ë©´?
```
### Answer)
`print`ë¡œ í™”ë©´ì— ì¶œë ¥ë˜ëŠ” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼(ì˜ˆ: `summary_report.txt`)ë¡œ ì €ì¥í•˜ë ¤ë©´, íŒŒì´ì¬ì˜ `open()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—´ê³  `write()`ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

**í™”ë©´ ì¶œë ¥ê³¼ íŒŒì¼ ì €ì¥ì„ ë™ì‹œì—** í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •í•œ ì½”ë“œì…ë‹ˆë‹¤.

```python
import pandas as pd
import os

# ë¶„ì„í•  CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸
csv_files = [
    'AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv',
    'StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv'
]

# ì €ì¥í•  ê²°ê³¼ ë¦¬í¬íŠ¸ íŒŒì¼ëª…
output_txt_file = "anomaly_detection_summary.txt"

# íŒŒì¼ì„ 'ì“°ê¸° ëª¨ë“œ(w)'ë¡œ ì—½ë‹ˆë‹¤.
with open(output_txt_file, "w", encoding="utf-8") as f:
    
    # [Tip] í™”ë©´ê³¼ íŒŒì¼ ì–‘ìª½ì— ë™ì‹œì— ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def log(message):
        print(message)          # ì½˜ì†” ì¶œë ¥
        f.write(message + "\n") # íŒŒì¼ ì“°ê¸° (ì¤„ë°”ê¿ˆ \n í¬í•¨)

    log("========== Anomaly Detection Summary from CSV ==========\n")

    for file_path in csv_files:
        if not os.path.exists(file_path):
            log(f"File not found: {file_path}\n")
            continue
            
        # 1. CSV ë¶ˆëŸ¬ì˜¤ê¸°
        df = pd.read_csv(file_path)
        
        # 2. í†µê³„ ê³„ì‚°
        total_count = len(df)
        anomaly_count = len(df[df['is_anomaly'] == 1])
        ratio = (anomaly_count / total_count * 100) if total_count > 0 else 0
        
        # 3. ê²°ê³¼ ì¶œë ¥ (log í•¨ìˆ˜ ì‚¬ìš©)
        log(f"Target File: {file_path}")
        log("[Result]")
        log(f"- The number of total validation data: {total_count}")
        log(f"- The number of found anormal data: {anomaly_count}")
        log(f"- Anormal data ratio: {ratio:.2f}%\n")

    log("========================================================")

print(f"\n[ì™„ë£Œ] ê²°ê³¼ê°€ '{output_txt_file}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

### ì½”ë“œ ì„¤ëª…

1.  **`with open(..., "w") as f:`**: íŒŒì¼ì„ ì“°ê¸° ëª¨ë“œë¡œ ì—½ë‹ˆë‹¤. ê¸°ì¡´ ë‚´ìš©ì´ ìˆë‹¤ë©´ ì§€ì›Œì§€ê³  ìƒˆë¡œ ì”ë‹ˆë‹¤. (ì¶”ê°€í•˜ë ¤ë©´ `"a"` ëª¨ë“œ ì‚¬ìš©)
2.  **`log(message)` í•¨ìˆ˜**:
      * `print(message)`: ì‹¤í–‰ í™”ë©´ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
      * `f.write(message + "\n")`: íŒŒì¼ì— ë‚´ìš©ì„ ì ìŠµë‹ˆë‹¤. `print`ì™€ ë‹¬ë¦¬ ì¤„ë°”ê¿ˆ(`\n`)ì„ ìë™ìœ¼ë¡œ ì•ˆ í•´ì£¼ë¯€ë¡œ ì§ì ‘ ë¶™ì—¬ì•¼ í•©ë‹ˆë‹¤.

ì´ì œ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ í™”ë©´ì—ë„ ê²°ê³¼ê°€ ëœ¨ê³ , í´ë”ì— `anomaly_detection_summary.txt`ë¼ëŠ” íŒŒì¼ë„ ìƒì„±ë©ë‹ˆë‹¤.
---
### Question)
```
Threshold ê°’ë„ ì¶œë ¥ì• í– ì• 
```
### Answer)
```python?code_reference&code_event_index=2
import pandas as pd
import os

# ë¶„ì„í•  CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸
csv_files = [
    'AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv',
    'StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv'
]

# ì €ì¥í•  ê²°ê³¼ ë¦¬í¬íŠ¸ íŒŒì¼ëª…
output_txt_file = "anomaly_detection_summary.txt"

# íŒŒì¼ì„ 'ì“°ê¸° ëª¨ë“œ(w)'ë¡œ ì—½ë‹ˆë‹¤.
with open(output_txt_file, "w", encoding="utf-8") as f:
    
    # [Tip] í™”ë©´ê³¼ íŒŒì¼ ì–‘ìª½ì— ë™ì‹œì— ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def log(message):
        print(message)          # ì½˜ì†” ì¶œë ¥
        f.write(message + "\n") # íŒŒì¼ ì“°ê¸° (ì¤„ë°”ê¿ˆ \n í¬í•¨)

    log("========== Anomaly Detection Summary from CSV ==========\n")

    for file_path in csv_files:
        if not os.path.exists(file_path):
            log(f"File not found: {file_path}\n")
            continue
            
        # 1. CSV ë¶ˆëŸ¬ì˜¤ê¸°
        df = pd.read_csv(file_path)
        
        # 2. í†µê³„ ê³„ì‚°
        total_count = len(df)
        anomaly_count = len(df[df['is_anomaly'] == 1])
        ratio = (anomaly_count / total_count * 100) if total_count > 0 else 0
        
        # 3. Threshold ê°’ ê°€ì ¸ì˜¤ê¸° (ëª¨ë“  í–‰ì´ ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ í–‰ì—ì„œ ì¶”ì¶œ)
        # íŒŒì¼ì— threshold_used ì»¬ëŸ¼ì´ ìˆë‹¤ê³  ê°€ì •
        if 'threshold_used' in df.columns:
            threshold_val = df['threshold_used'].iloc[0]
        else:
            threshold_val = "N/A"
        
        # 4. ê²°ê³¼ ì¶œë ¥ (log í•¨ìˆ˜ ì‚¬ìš©)
        log(f"Target File: {file_path}")
        log("[Result]")
        log(f"- Threshold Score: {threshold_val:.4f}" if isinstance(threshold_val, float) else f"- Threshold Score: {threshold_val}")
        log(f"- The number of total validation data: {total_count}")
        log(f"- The number of found anormal data: {anomaly_count}")
        log(f"- Anormal data ratio: {ratio:.2f}%\n")

    log("========================================================")

```

```text?code_stdout&code_event_index=2
========== Anomaly Detection Summary from CSV ==========

Target File: AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv
[Result]
- Threshold Score: 0.0981
- The number of total validation data: 1874
- The number of found anormal data: 226
- Anormal data ratio: 12.06%

Target File: StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv
[Result]
- Threshold Score: 0.0960
- The number of total validation data: 14908
- The number of found anormal data: 915
- Anormal data ratio: 6.14%

========================================================

```

[file-tag: code-generated-file-0-1764558279585631747]

ë„¤, CSV íŒŒì¼ ì•ˆì— ìˆëŠ” `threshold_used` ì»¬ëŸ¼ì„ ì½ì–´ì„œ í•¨ê»˜ ì¶œë ¥í•˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.

ì•„ë˜ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì‹œë©´ **í™”ë©´ ì¶œë ¥**ê³¼ \*\*íŒŒì¼ ì €ì¥(`anomaly_detection_summary.txt`)\*\*ì´ ë™ì‹œì— ë˜ë©°, ìš”ì²­í•˜ì‹  ëŒ€ë¡œ **Threshold ê°’**ë„ í¬í•¨ë©ë‹ˆë‹¤.

```python
import pandas as pd
import os

# 1. ë¶„ì„í•  CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸
csv_files = [
    'AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv',
    'StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv'
]

# 2. ê²°ê³¼ë¥¼ ì €ì¥í•  í…ìŠ¤íŠ¸ íŒŒì¼ëª…
output_txt_file = "anomaly_detection_summary.txt"

# 3. íŒŒì¼ì„ ì—´ê³ (write ëª¨ë“œ), í™”ë©´ê³¼ íŒŒì¼ì— ë™ì‹œ ì¶œë ¥í•˜ëŠ” ë¡œì§
with open(output_txt_file, "w", encoding="utf-8") as f:
    
    # [Helper] í™”ë©´ ì¶œë ¥ + íŒŒì¼ ì €ì¥ì„ ë™ì‹œì— í•˜ëŠ” í•¨ìˆ˜
    def log(message):
        print(message)          # í™”ë©´ì— ì¶œë ¥
        f.write(message + "\n") # íŒŒì¼ì— ì“°ê¸° (ì¤„ë°”ê¿ˆ í¬í•¨)

    log("========== Anomaly Detection Summary from CSV ==========\n")

    for file_path in csv_files:
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(file_path):
            log(f"File not found: {file_path}\n")
            continue
            
        # (1) CSV ë¶ˆëŸ¬ì˜¤ê¸°
        df = pd.read_csv(file_path)
        
        # (2) í†µê³„ ê³„ì‚°
        total_count = len(df)
        anomaly_count = len(df[df['is_anomaly'] == 1])
        ratio = (anomaly_count / total_count * 100) if total_count > 0 else 0
        
        # (3) Threshold ê°’ ì¶”ì¶œ (ëª¨ë“  í–‰ì— ê°™ì€ ê°’ì´ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ í–‰ë§Œ ì½ìŒ)
        if 'threshold_used' in df.columns:
            threshold_val = df['threshold_used'].iloc[0]
        else:
            threshold_val = 0.0 # ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„
        
        # (4) ê²°ê³¼ ë¦¬í¬íŒ…
        log(f"Target File: {file_path}")
        log("[Result]")
        log(f"- Threshold Score: {threshold_val:.4f}")  # <--- ì¶”ê°€ëœ ë¶€ë¶„
        log(f"- The number of total validation data: {total_count}")
        log(f"- The number of found anormal data: {anomaly_count}")
        log(f"- Anormal data ratio: {ratio:.2f}%\n")

    log("========================================================")

print(f"\n[ì™„ë£Œ] ê²°ê³¼ê°€ '{output_txt_file}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

### ì‹¤í–‰ ê²°ê³¼ (ì˜ˆì‹œ)

ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜µë‹ˆë‹¤.

```text
========== Anomaly Detection Summary from CSV ==========

Target File: AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv
[Result]
- Threshold Score: 0.0981
- The number of total validation data: 1874
- The number of found anormal data: 226
- Anormal data ratio: 12.06%

Target File: StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv
[Result]
- Threshold Score: 0.0960
- The number of total validation data: 14908
- The number of found anormal data: 915
- Anormal data ratio: 6.14%

========================================================
```
---
### Question)
```
Â  Â  # (A) ì ìˆ˜ ë¶„í¬ ë¹„êµ (Histogram)
Â  Â  plt.subplot(2, 1, 1)
Â  Â  sns.histplot(train_scores, label='Train Scores (Baseline)', color='blue', alpha=0.3, kde=True)
Â  Â  sns.histplot(val_scores, label='Val Scores (Target)', color='orange', alpha=0.3, kde=True)
Â  Â  plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold:.2f})')
Â  Â  plt.title('Anomaly Score Distribution (Train vs Val)')
Â  Â  plt.xlabel('Anomaly Score (Higher = More Anomalous)')
Â  Â  plt.legend()

Â  Â  # (B) ì‹œê³„ì—´ íë¦„ìƒ ì´ìƒì¹˜ ìœ„ì¹˜ (Val Data)
Â  Â  plt.subplot(2, 1, 2)
Â  Â  plt.plot(val_scores, label='Val Anomaly Score', color='black', alpha=0.7, linewidth=1)
Â  Â  plt.scatter(anomalies_idx, val_scores[anomalies_idx], color='red', s=30, label='Detected Anomaly', zorder=5)
Â  Â  plt.axhline(threshold, color='red', linestyle='--', alpha=0.5)
Â  Â  plt.title('Anomaly Detection Result on Validation Sequence')
Â  Â  plt.xlabel('Time Window Index')
Â  Â  plt.ylabel('Anomaly Score')
Â  Â  plt.legend()

Â  Â  plt.tight_layout()
Â  Â  plt.savefig(res_fig_path)

ì´ ë¶€ë¶„ì— ì‚¬ìš©ëœ ë³€ìˆ˜ë„ ì ì ˆíˆ ë°”ê¾¸ë©´?
```
### Answer)
ì œê³µí•´ì£¼ì‹  ì‹œê°í™” ì½”ë“œë¥¼ **CSV íŒŒì¼ì„ ì½ì–´ì„œ ì‹¤í–‰í•˜ëŠ” êµ¬ì¡°**ì— ë§ê²Œ ë³€ìˆ˜ë¥¼ ë§¤í•‘í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì£¼ì˜í•  ì :** CSV íŒŒì¼ì—ëŠ” í•™ìŠµ ë‹¹ì‹œì˜ `train_scores` ì •ë³´ê°€ ì €ì¥ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ **(A) íˆìŠ¤í† ê·¸ë¨**ì—ì„œëŠ” `train_scores`ë¥¼ ì œì™¸í•˜ê³  `val_scores`ì˜ ë¶„í¬ì™€ `threshold`ë§Œ ê·¸ë¦¬ëŠ” ê²ƒìœ¼ë¡œ ì½”ë“œë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ëŠ” CSV íŒŒì¼ì„ ì½ì–´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê³  ì €ì¥í•˜ëŠ” ì „ì²´ ì½”ë“œì…ë‹ˆë‹¤.

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# 1. ë¶„ì„í•  CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸
csv_files = [
    'AtrialFibrillation_o24_anomaly_detection_threshold_0.05_res.csv',
    'StandWalkJump_o24_anomaly_detection_threshold_0.05_res.csv'
]

# 2. íŒŒì¼ë³„ë¡œ ìˆœíšŒí•˜ë©° ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
for file_path in csv_files:
    if not os.path.exists(file_path):
        print(f"File not found: {file_path}")
        continue
        
    # --- [ë°ì´í„° ì¤€ë¹„] ---
    df = pd.read_csv(file_path)
    
    # ë³€ìˆ˜ ë§¤í•‘ (DataFrame -> Numpy/Scalar)
    val_scores = df['anomaly_score'].values
    threshold = df['threshold_used'].iloc[0]
    anomalies_idx = df.index[df['is_anomaly'] == 1].tolist()
    
    # ì €ì¥í•  ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± (.csv -> .png)
    res_fig_path = file_path.replace('.csv', '_plot.png')

    # --- [ì‹œê°í™” ì½”ë“œ ì ìš©] ---
    plt.figure(figsize=(12, 10))

    # (A) ì ìˆ˜ ë¶„í¬ ë¹„êµ (Histogram)
    # *ì£¼ì˜: CSVì—ëŠ” train_scoresê°€ ì—†ìœ¼ë¯€ë¡œ val_scores ë¶„í¬ë§Œ ê·¸ë¦½ë‹ˆë‹¤.
    plt.subplot(2, 1, 1)
    # sns.histplot(train_scores, label='Train Scores', color='blue', alpha=0.3, kde=True) # (ë°ì´í„° ì—†ìŒ)
    sns.histplot(val_scores, label='Val Scores (Target)', color='orange', alpha=0.5, kde=True)
    plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({threshold:.4f})')
    plt.title(f'Anomaly Score Distribution (File: {file_path})')
    plt.xlabel('Anomaly Score (Higher = More Anomalous)')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # (B) ì‹œê³„ì—´ íë¦„ìƒ ì´ìƒì¹˜ ìœ„ì¹˜ (Val Data)
    plt.subplot(2, 1, 2)
    plt.plot(val_scores, label='Val Anomaly Score', color='black', alpha=0.7, linewidth=1)
    plt.scatter(anomalies_idx, val_scores[anomalies_idx], color='red', s=30, label='Detected Anomaly', zorder=5)
    plt.axhline(threshold, color='red', linestyle='--', alpha=0.5, label='Threshold')
    plt.title('Anomaly Detection Result on Validation Sequence')
    plt.xlabel('Time Window Index')
    plt.ylabel('Anomaly Score')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(res_fig_path)
    plt.close() # ë©”ëª¨ë¦¬ í•´ì œë¥¼ ìœ„í•´ í”Œë¡¯ ë‹«ê¸°
    
    print(f"Graph saved: {res_fig_path}")

print("\n[ì™„ë£Œ] ëª¨ë“  ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
```

### ë³€ê²½ëœ ì‚¬í•­

1.  **ë³€ìˆ˜ ìƒì„±:** `df['anomaly_score']`, `df['is_anomaly']` ë“±ì„ ì´ìš©í•˜ì—¬ `val_scores`, `anomalies_idx` ë³€ìˆ˜ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
2.  **Train Scores ì œì™¸:** CSVë§Œìœ¼ë¡œëŠ” í•™ìŠµ ë°ì´í„°ì˜ ì ìˆ˜ ë¶„í¬ë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ `train_scores` ê´€ë ¨ í”Œë¡¯ ë¼ì¸ì€ ì£¼ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. (ê²€ì¦ ë°ì´í„°ì˜ ë¶„í¬ì™€ ì„ê³„ê°’ ìœ„ì¹˜ë§Œ ë´ë„ ë¶„ì„ì—ëŠ” ì¶©ë¶„í•©ë‹ˆë‹¤.)
3.  **íŒŒì¼ ì €ì¥:** ì…ë ¥ CSV íŒŒì¼ëª… ë’¤ì— `_plot.png`ë¥¼ ë¶™ì—¬ì„œ ìë™ìœ¼ë¡œ ì €ì¥ë˜ë„ë¡ í–ˆìŠµë‹ˆë‹¤.

---
### Question)
```
val_scores ì´ê±¸ ì–´ë–»ê²Œ ë°”ê¿”ì•¼ í•˜ëŠ”ì§€ ì•Œë ¤ì¤˜.
```
### Answer)
`val_scores`ëŠ” CSV íŒŒì¼ì˜ **`anomaly_score`** ì»¬ëŸ¼ì— í•´ë‹¹í•©ë‹ˆë‹¤.

ë”°ë¼ì„œ ì½”ë“œë¥¼ ì‘ì„±í•˜ì‹¤ ë•Œ, CSVë¥¼ ë¡œë“œí•œ DataFrame(`df`)ì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ì„ êº¼ë‚´ì„œ `val_scores` ë³€ìˆ˜ì— ë‹´ì•„ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

### ë³€ê²½ ë°©ë²• (ì½”ë“œ)

```python
# 1. CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv(file_path)

# 2. ë³€ìˆ˜ ë§¤í•‘ (ì—¬ê¸°ì„œ ë°”ê¿”ì¤ë‹ˆë‹¤!)
val_scores = df['anomaly_score'].values  # DataFrame ì»¬ëŸ¼ -> numpy arrayë¡œ ë³€í™˜
threshold = df['threshold_used'].iloc[0] # ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°
anomalies_idx = df.index[df['is_anomaly'] == 1].tolist() # ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì¶”ì¶œ

# 3. ê·¸ ì´í›„ ì‹œê°í™” ì½”ë“œì—ì„œëŠ” val_scoresë¥¼ ê·¸ëŒ€ë¡œ ì“°ì‹œë©´ ë©ë‹ˆë‹¤.
plt.subplot(2, 1, 1)
# sns.histplot(train_scores, ...)  <-- train_scoresëŠ” CSVì— ì—†ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚­ì œ
sns.histplot(val_scores, label='Val Scores (Target)', color='orange', alpha=0.5, kde=True)
...
```

**í•µì‹¬:**
ê¸°ì¡´ ì½”ë“œì˜ `val_scores` ìë¦¬ì— **`df['anomaly_score']`** (ë˜ëŠ” `.values`ë¥¼ ë¶™ì¸ ê²ƒ)ë¥¼ ëŒ€ì…í•œë‹¤ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤.