## 시계열 데이터 임베딩 성능 평가 지표
1. 내재적 평가
2. 외재적 평가
3. 일반화/효율성 평가
4. 강건성 평가
 
----
### 1. 내재적 평가 - 임베딩이 데이터를 잘 표현하는 정도
- 시계열의 특정 패턴을 하나의 단어로 취급하여, 패턴의 관계를 평가함.
- 최종적으로는, 실제 적용하려는 과제 (외재적 평가)의 성능으로 임베딩 가치를 판단하는 것이 중요함.
#### 1. 시계열 패턴 유사도 평가
- 유사한 시계열 패턴이 임베딩 공간에서 얼마나 가까운지 평가
- 원본 데이터셋에서 패턴A와 패턴B를 추출한 뒤,
1. 전통적인 시계열 유사도 측정 알고리즘 (DTW) 등을 사용하여 패턴A와 패턴B의 유사도를 계산, 정답 점수로 활용
2. 패턴A와 패턴B를 모델에 입력하여 얻은 임베딩 벡터의 코사인 유사도 계산
3. 스피어만 상관계수 등을 사용하여 1번의 DTW 점수와 2번의 코사인 유사도 점수를 비교, 상관계수 계산. (상관성이 높을수록 시계열 패턴의 유사도를 잘 표현함.)

#### 2. 이상치 탐지
- 비정상적이거나 희귀한 패턴이 임베딩 공간에서 멀리 떨어져 있는지 평가
- 원본 데이터셋에 대한 라벨링 필요 (정상 / Outlier)
1. 정상 패턴 데이터를 임베딩하여 벡터 공간에 표현, 중심점 계산 (평균벡터 계산)
2. 비정상 패턴 데이터를 임베딩하여 벡터 공간에 표현, 중심점 계산 (평균벡터 계산)
3. 모든 정상/이상치 데이터에 대하여, 데이터가 1~2 과정에서의 평균벡터(중심점)와 얼마나 멀리 떨어져 있는지 계산. 유클리드 거리나 코사인 거리를 활용.
- 주요 성능 지표: AUC, F1-Score

----
### 2. 외재적 평가 - 임베딩이 문제 해결에 유용한 정도
- DownStream Task의 성능으로 임베딩 성능 측정
1. DownStream Task 선택
2. 모델에 임베딩 적용 - DownStream Task 모델에 평가하고자 하는 임베딩 벡터를 투입
3. 해당 모델의 성능을 평가 - DownStream Task Type에 따라 적절한 평가 방법을 선택 // Task별로 정형화된 평가 방법을 사용
- 시간/비용적 문제로, 여러 임베딩 모델에 대한 내재적 평가를 통해 1차로 추려내고, 추려진 모델에 대해서만 외재적 평가 수행

----
### 3. 일반화/효율성 평가 - 새로운 데이터, 적은 데이터를 대상으로 잘 작동하는 정도
- 일반화 평가 - 처음 보는 데이터에 대하여, 모델이 얼마나 일관된 성능을 보이는가
- 효율성 평가 - 라벨링된 데이터가 적음에도 불구하고, 얼마나 빠르게 쓸만한 성능을 내는가
- 평가에 사용되는 데이터셋의 구성을 바꿔 실험하는 항목 - 성능 지표는 DownStream Task의 평가 지표를 그대로 적용. (ex. AUC, 정확도 등..)
#### 일반화 성능 평가 - K-겹 교차 검증
1. 데이터 분할 - 라벨링된 데이터셋 전체를 K개의 그룹으로 분할 (보통 K = 5 or 10)
2. 반복 학습 및 평가
- 첫 번째 그룹을 평가용으로, 나머지 K-1개의 그룹을 학습용으로 사용하여 모델 학습 & 성능 측정
- 두 번째 그룹을 평가용으로, 나머지 K-1개의 그룹을 학습용으로 사용하여 모델 학습 & 성능 측정
- K번째 그룹을 평가용으로, 나머지 K-1개의 그룹을 학습용으로 사용하여 모델 학습 & 성능 측정 (이 과정을 K번 반복)
3. 최종 성능: K번 측정된 성능 점수의 평균과 표준편차를 계산 (평균점수 = 일반화된 성능)
4. 학습 데이터에서의 성능과 평가 데이터에서의 성능 차이가 크면 OverFitting, 작으면 일반화 성능 우수한 것으로 간주할 수 있음.
  
#### 효율성 평가 - Few-Shot 학습
- Shot: 클래스(분류 대상) 당 학습 데이터 개수
- 클래스에 속하는 학습 데이터 수가 아주 적을 때를 기준으로 학습 및 성능 평가
1. 초소형 학습Set 구성 - 클래스별로 몇 개의 데이터(ex. 5)만 추출하여 학습 데이터셋 구성. (5-shot training) 
2. 모델 학습 - 초소형 데이터셋으로 DownStream Task모델 학습.
3. 성능 평가 - 별도로 마련된 대량의 Test 데이터셋으로 성능 측정
4. 심화 평가 - 0-Shot 학습 // 학습 데이터를 전혀 확인하지 않은 상태에서 Test 데이터셋으로 성능 측정.

----
### 4. 강건성 평가 - 불완전하거나, 노이즈가 있는 데이터에 잘 대응하는 정도
- 원본 데이터셋을 의도적으로 불완전하게 만들거나 노이즈를 추가한 경우, 얼마나 적은 폭으로 성능이 감소하는지 측정
- 평가에 사용되는 데이터셋의 구성을 바꿔 실험하는 항목 - 성능 지표는 DownStream Task의 평가 지표를 그대로 적용. (ex. AUC, 정확도 등..)
  
1. 기준 성능 측정 - 원본 데이터셋을 사용할 때를 학습하고, 성능 측정
2. 손상된 데이터셋 생성 - 노이즈(가우시안, 스피이크/이상치) 추가 + 데이터 고의로 파괴시키기 (불완전하게)
3. 손상된 데이터로 성능 재측정 - "추가적인 학습 없이" 손상된 데이터로 예측 수행 + 성능 측정
4. 성능 하락폭 비교 - 1에서 얻은 결과와 3에서 얻은 결과로부터 성능 하락폭 계산.